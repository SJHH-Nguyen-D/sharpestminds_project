{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_sharpestminds_.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcWib3nKlYsz",
        "colab_type": "text"
      },
      "source": [
        "# Employee Performance Data Modelling and Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLYxlS0_b0Ur",
        "colab_type": "text"
      },
      "source": [
        "## About\n",
        "We try to predict employee performance scores based 300+ employee demographic characteristics. The dataset in question was acquired as part of a homework assignment and comprises of 20,000 employees and 379 employee characteristics, 1 target variable (employee performance score).\n",
        "\n",
        "This note book details the loading, preprocessing, sampling, feature selection, modeling and write up of the pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV4K3c0-X3_Y",
        "colab_type": "text"
      },
      "source": [
        "Setting up the notebook settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGO5nOCvWoqD",
        "colab_type": "code",
        "outputId": "9bb1e1ef-899c-4b28-e169-2612ccf3b436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "!--NotebookApp.iopub_data_rate_limit=1e11"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: --: invalid option\n",
            "Usage:\t/bin/bash [GNU long option] [option] ...\n",
            "\t/bin/bash [GNU long option] [option] script-file ...\n",
            "GNU long options:\n",
            "\t--debug\n",
            "\t--debugger\n",
            "\t--dump-po-strings\n",
            "\t--dump-strings\n",
            "\t--help\n",
            "\t--init-file\n",
            "\t--login\n",
            "\t--noediting\n",
            "\t--noprofile\n",
            "\t--norc\n",
            "\t--posix\n",
            "\t--rcfile\n",
            "\t--restricted\n",
            "\t--verbose\n",
            "\t--version\n",
            "Shell options:\n",
            "\t-ilrsD or -c command or -O shopt_option\t\t(invocation only)\n",
            "\t-abefhkmnptuvxBCHP or -o option\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky7WF9AuBvkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLtSU5oT9EDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install jupyter_contrib_nbextensions\n",
        "# !pip install -U ipykernel\n",
        "# !pip install jupyterthemes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AW_r0tMklda",
        "colab_type": "text"
      },
      "source": [
        "# Project Flow Overview\n",
        "\n",
        "1. Load Data\n",
        "2. Cursory Description of Data\n",
        "3. EDA\n",
        "4. Feature Selection/ Extraction\n",
        "5. Modelling\n",
        "6. Prediction\n",
        "7. Optimization\n",
        "8. Modelling\n",
        "9. End Point\n",
        "10. Conclusion and Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZdh_qvRlDW0",
        "colab_type": "text"
      },
      "source": [
        "# 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9aXoJbOJdwo",
        "colab_type": "code",
        "outputId": "fde4e734-2f34-4294-e813-8a69d44d7583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp1Y4_ViMIGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get colmumn names for main dataset with key from other dataset\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.options.display.max_seq_items = 2000\n",
        "import numpy as np\n",
        "\n",
        "col_names = pd.read_csv(\"/content/drive/My Drive/sharpestminds_dataset/CodeBook-SELECT.csv\")\n",
        "col_names = col_names.loc[:, \"VarName\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-aic2XAMYZ4",
        "colab_type": "code",
        "outputId": "f568ec77-d5c5-4706-b1f2-e6dde59a3c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 933
        }
      },
      "source": [
        "# load in the actual dataset\n",
        "df = pd.read_csv(\"/content/drive/My Drive/sharpestminds_dataset/hw5-trainingset-cl3770.csv\", header=\"infer\")\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cntryid</th>\n",
              "      <th>cntryid_e</th>\n",
              "      <th>age_r</th>\n",
              "      <th>gender_r</th>\n",
              "      <th>computerexperience</th>\n",
              "      <th>nativespeaker</th>\n",
              "      <th>edlevel3</th>\n",
              "      <th>monthlyincpr</th>\n",
              "      <th>yearlyincpr</th>\n",
              "      <th>lng_home</th>\n",
              "      <th>cnt_h</th>\n",
              "      <th>cnt_brth</th>\n",
              "      <th>reg_tl2</th>\n",
              "      <th>lng_bq</th>\n",
              "      <th>lng_ci</th>\n",
              "      <th>yrsqual</th>\n",
              "      <th>yrsqual_t</th>\n",
              "      <th>yrsget</th>\n",
              "      <th>vet</th>\n",
              "      <th>ctryqual</th>\n",
              "      <th>birthrgn</th>\n",
              "      <th>nativelang</th>\n",
              "      <th>ctryrgn</th>\n",
              "      <th>imyrs</th>\n",
              "      <th>imyrs_c</th>\n",
              "      <th>imyrcat</th>\n",
              "      <th>ageg5lfs</th>\n",
              "      <th>ageg10lfs</th>\n",
              "      <th>ageg10lfs_t</th>\n",
              "      <th>edcat8</th>\n",
              "      <th>edcat7</th>\n",
              "      <th>edcat6</th>\n",
              "      <th>leaver1624</th>\n",
              "      <th>leavedu</th>\n",
              "      <th>fe12</th>\n",
              "      <th>aetpop</th>\n",
              "      <th>faet12</th>\n",
              "      <th>faet12jr</th>\n",
              "      <th>faet12njr</th>\n",
              "      <th>nfe12</th>\n",
              "      <th>...</th>\n",
              "      <th>v253</th>\n",
              "      <th>v132</th>\n",
              "      <th>v284</th>\n",
              "      <th>v267</th>\n",
              "      <th>v260</th>\n",
              "      <th>v26</th>\n",
              "      <th>v171</th>\n",
              "      <th>v14</th>\n",
              "      <th>v7</th>\n",
              "      <th>v240</th>\n",
              "      <th>v186</th>\n",
              "      <th>v162</th>\n",
              "      <th>v149</th>\n",
              "      <th>v228</th>\n",
              "      <th>v28</th>\n",
              "      <th>v237</th>\n",
              "      <th>v280</th>\n",
              "      <th>v175</th>\n",
              "      <th>v288</th>\n",
              "      <th>v15</th>\n",
              "      <th>v208</th>\n",
              "      <th>v43</th>\n",
              "      <th>v27</th>\n",
              "      <th>v114</th>\n",
              "      <th>v191</th>\n",
              "      <th>v170</th>\n",
              "      <th>v65</th>\n",
              "      <th>v57</th>\n",
              "      <th>v177</th>\n",
              "      <th>v69</th>\n",
              "      <th>v85</th>\n",
              "      <th>v50</th>\n",
              "      <th>v89</th>\n",
              "      <th>v127</th>\n",
              "      <th>v239</th>\n",
              "      <th>v224</th>\n",
              "      <th>v71</th>\n",
              "      <th>v105</th>\n",
              "      <th>row</th>\n",
              "      <th>uni</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Canada</td>\n",
              "      <td>Canada (English)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Medium</td>\n",
              "      <td>50 to less than 75</td>\n",
              "      <td>50 to less than 75</td>\n",
              "      <td>999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>99999</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test language same as native language</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Non-immigrants</td>\n",
              "      <td>Aged 25-29</td>\n",
              "      <td>25-34</td>\n",
              "      <td>25-34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Participated in FE</td>\n",
              "      <td>AET population</td>\n",
              "      <td>Participated in formal AET</td>\n",
              "      <td>Participated in formal AET for JR reasons</td>\n",
              "      <td>Did not participate in FE for NJR reasons</td>\n",
              "      <td>Did not participate in NFE</td>\n",
              "      <td>...</td>\n",
              "      <td>Never</td>\n",
              "      <td>Every day</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>Never</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Never</td>\n",
              "      <td>Never</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Every day</td>\n",
              "      <td>Every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Never</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>Never</td>\n",
              "      <td>Never</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To some extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>Never</td>\n",
              "      <td>Disagree</td>\n",
              "      <td>Neither agree nor disagree</td>\n",
              "      <td>Agree</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>9996.0</td>\n",
              "      <td>9999</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>80219</td>\n",
              "      <td>cl3770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>England (UK)</td>\n",
              "      <td>60.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>High</td>\n",
              "      <td>75 to less than 90</td>\n",
              "      <td>75 to less than 90</td>\n",
              "      <td>eng</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United Kingdom of Great Britain and Northern I...</td>\n",
              "      <td>UKJ</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>Test language same as native language</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Non-immigrants</td>\n",
              "      <td>Aged 60-65</td>\n",
              "      <td>55 plus</td>\n",
              "      <td>55 plus</td>\n",
              "      <td>Tertiary – professional degree (ISCED 5B)</td>\n",
              "      <td>Tertiary – professional degree (ISCED 5B)</td>\n",
              "      <td>Tertiary – professional degree (ISCED 5B)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>Did not participate in FE</td>\n",
              "      <td>AET population</td>\n",
              "      <td>Did not participate in formal AET</td>\n",
              "      <td>Did not participate in formal AET for JR reasons</td>\n",
              "      <td>Did not participate in FE for NJR reasons</td>\n",
              "      <td>Participated in NFE</td>\n",
              "      <td>...</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>Every day</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>Rarely</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>Every day</td>\n",
              "      <td>Every day</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Every day</td>\n",
              "      <td>Every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>Never</td>\n",
              "      <td>Agree</td>\n",
              "      <td>Strongly agree</td>\n",
              "      <td>Agree</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3118.0</td>\n",
              "      <td>9996.0</td>\n",
              "      <td>2520</td>\n",
              "      <td>9996.0</td>\n",
              "      <td>44314</td>\n",
              "      <td>cl3770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>England (UK)</td>\n",
              "      <td>31.0</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>High</td>\n",
              "      <td>75 to less than 90</td>\n",
              "      <td>75 to less than 90</td>\n",
              "      <td>eng</td>\n",
              "      <td>NaN</td>\n",
              "      <td>United Kingdom of Great Britain and Northern I...</td>\n",
              "      <td>UKI</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>Test language same as native language</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Non-immigrants</td>\n",
              "      <td>Aged 30-34</td>\n",
              "      <td>25-34</td>\n",
              "      <td>25-34</td>\n",
              "      <td>Tertiary - bachelor/master/research degree (IS...</td>\n",
              "      <td>Tertiary - bachelor/master/research degree (IS...</td>\n",
              "      <td>Tertiary - bachelor/master/research degree (IS...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Participated in FE</td>\n",
              "      <td>AET population</td>\n",
              "      <td>Participated in formal AET</td>\n",
              "      <td>Participated in formal AET for JR reasons</td>\n",
              "      <td>Did not participate in FE for NJR reasons</td>\n",
              "      <td>Participated in NFE</td>\n",
              "      <td>...</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>Rarely</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Never</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>Never</td>\n",
              "      <td>Never</td>\n",
              "      <td>To some extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>Disagree</td>\n",
              "      <td>Strongly agree</td>\n",
              "      <td>Agree</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2421.0</td>\n",
              "      <td>9996.0</td>\n",
              "      <td>3510</td>\n",
              "      <td>9996.0</td>\n",
              "      <td>91755</td>\n",
              "      <td>cl3770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Norway</td>\n",
              "      <td>Norway</td>\n",
              "      <td>33.0</td>\n",
              "      <td>Female</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>High</td>\n",
              "      <td>25 to less than 50</td>\n",
              "      <td>25 to less than 50</td>\n",
              "      <td>rus</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>99999</td>\n",
              "      <td>eng</td>\n",
              "      <td>nor</td>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>Central Asia</td>\n",
              "      <td>Test language not same as native language</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0-5 years</td>\n",
              "      <td>In host country 5 or fewer years</td>\n",
              "      <td>Aged 30-34</td>\n",
              "      <td>25-34</td>\n",
              "      <td>25-34</td>\n",
              "      <td>Tertiary – master degree (ISCED 5A)</td>\n",
              "      <td>Tertiary – master/research degree (ISCED 5A/6)</td>\n",
              "      <td>Tertiary – master/research degree (ISCED 5A/6)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31.0</td>\n",
              "      <td>Did not participate in FE</td>\n",
              "      <td>AET population</td>\n",
              "      <td>Did not participate in formal AET</td>\n",
              "      <td>Did not participate in formal AET for JR reasons</td>\n",
              "      <td>Did not participate in FE for NJR reasons</td>\n",
              "      <td>Participated in NFE</td>\n",
              "      <td>...</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>Every day</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Every day</td>\n",
              "      <td>Never</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Every day</td>\n",
              "      <td>Every day</td>\n",
              "      <td>Every day</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>To some extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To some extent</td>\n",
              "      <td>To some extent</td>\n",
              "      <td>To some extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>Less than once a month</td>\n",
              "      <td>Neither agree nor disagree</td>\n",
              "      <td>Disagree</td>\n",
              "      <td>Agree</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>334.0</td>\n",
              "      <td>9996.0</td>\n",
              "      <td>82</td>\n",
              "      <td>9996.0</td>\n",
              "      <td>188729</td>\n",
              "      <td>cl3770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>United States</td>\n",
              "      <td>United States</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>Yes</td>\n",
              "      <td>No</td>\n",
              "      <td>Medium</td>\n",
              "      <td>10 to less than 25</td>\n",
              "      <td>10 to less than 25</td>\n",
              "      <td>999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>eng</td>\n",
              "      <td>eng</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Test language not same as native language</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11-15 years</td>\n",
              "      <td>In host country more than 5 years</td>\n",
              "      <td>Aged 20-24</td>\n",
              "      <td>24 or less</td>\n",
              "      <td>24 or less</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>Completed ISCED 3 or is still in education, ag...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Participated in FE</td>\n",
              "      <td>Excluded from AET population</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Did not participate in NFE</td>\n",
              "      <td>...</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>Every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Less than once a week but at least once a month</td>\n",
              "      <td>Never</td>\n",
              "      <td>Never</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Yes</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Never</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>At least once a week but not every day</td>\n",
              "      <td>Never</td>\n",
              "      <td>Never</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a high extent</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>To a very high extent</td>\n",
              "      <td>Never</td>\n",
              "      <td>Strongly disagree</td>\n",
              "      <td>Strongly agree</td>\n",
              "      <td>Strongly agree</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9999.0</td>\n",
              "      <td>9996.0</td>\n",
              "      <td>9999</td>\n",
              "      <td>9996.0</td>\n",
              "      <td>38262</td>\n",
              "      <td>cl3770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 380 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          cntryid         cntryid_e  age_r  ...    v105     row     uni\n",
              "0          Canada  Canada (English)    NaN  ...  9999.0   80219  cl3770\n",
              "1  United Kingdom      England (UK)   60.0  ...  9996.0   44314  cl3770\n",
              "2  United Kingdom      England (UK)   31.0  ...  9996.0   91755  cl3770\n",
              "3          Norway            Norway   33.0  ...  9996.0  188729  cl3770\n",
              "4   United States     United States    NaN  ...  9996.0   38262  cl3770\n",
              "\n",
              "[5 rows x 380 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmvh5FescYh3",
        "colab_type": "text"
      },
      "source": [
        "### The dataset is a 93Mb csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyIvEzFWcORw",
        "colab_type": "code",
        "outputId": "64e44a55-fd7c-4784-8ef0-6c3e182545e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!du -hs \"/content/drive/My Drive/sharpestminds_dataset/hw5-trainingset-cl3770.csv\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93M\t/content/drive/My Drive/sharpestminds_dataset/hw5-trainingset-cl3770.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVhwlVnWciux",
        "colab_type": "code",
        "outputId": "ff3e6a08-7246-4de7-a9bb-3333101da972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "# we have a lot of data here\n",
        "print(\"{} features, {} observations\".format(df.shape[1], df.shape[0]))\n",
        "\n",
        "# we also have a lot of non-numeric data as well\n",
        "print(df.info(memory_usage='deep'))\n",
        "\n",
        "print(df.describe())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "380 features, 20000 observations\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20000 entries, 0 to 19999\n",
            "Columns: 380 entries, cntryid to uni\n",
            "dtypes: float64(80), int64(5), object(295)\n",
            "memory usage: 357.9 MB\n",
            "None\n",
            "              age_r       yrsqual  ...          v105            row\n",
            "count  12118.000000  17417.000000  ...  19979.000000   20000.000000\n",
            "mean      39.339412     14.573549  ...   9833.138696   96825.751700\n",
            "std       11.004673      2.703482  ...   1009.110938   57590.955791\n",
            "min       16.000000      5.000000  ...     31.000000      98.000000\n",
            "25%       31.000000     12.000000  ...   9996.000000   46369.000000\n",
            "50%       38.000000     15.000000  ...   9996.000000   94729.000000\n",
            "75%       48.000000     16.000000  ...   9996.000000  147668.500000\n",
            "max       65.000000     22.000000  ...   9999.000000  197786.000000\n",
            "\n",
            "[8 rows x 85 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c99SaK94lqzu",
        "colab_type": "text"
      },
      "source": [
        "# 3. EDA - Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbBmc5nQ4kYu",
        "colab_type": "text"
      },
      "source": [
        "### We print out the the counts of observations with missing values in this dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eqs2evmNAQN",
        "colab_type": "code",
        "outputId": "5bb9876f-32ee-4857-8ecc-30672c86696d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# There are a lot of missing values in this dataset\n",
        "print(df.isnull().sum().sort_values(ascending=False)[df.isnull().sum() > 1000][:25])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "v262    20000\n",
            "v44     19997\n",
            "v76     19993\n",
            "v144    19992\n",
            "v199    19991\n",
            "v159    19985\n",
            "v10     19981\n",
            "v172    19977\n",
            "v110    19956\n",
            "v160    19955\n",
            "v100    19955\n",
            "v109    19954\n",
            "v75     19938\n",
            "v211    19938\n",
            "v215    19936\n",
            "v163    19935\n",
            "v220    19927\n",
            "v254    19923\n",
            "v38     19910\n",
            "v129    19910\n",
            "v266    19907\n",
            "v89     19864\n",
            "v127    19828\n",
            "v117    19793\n",
            "v287    19792\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShC2uYLM23_d",
        "colab_type": "text"
      },
      "source": [
        "# Dropping Redundant Features\n",
        "\n",
        "Based on the codebook and the naming conventions for this dataset, we will explore and determine which features could be dropped due to overlapping measures. Sometimes this is done as a result of differences in coding schemes or categorical aggregations of the result. We will do some investigation on these features, their level of correlation and multicollinearity with the target variable and decide which features we can drop during the preprocessing step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9r_3DuvqrZc",
        "colab_type": "code",
        "outputId": "2e029240-b546-48c7-e3e9-a12005702d9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# look at these features individually and drop stepwise after analysis\n",
        "\n",
        "import re\n",
        "\n",
        "pattern_earnhr = re.compile('\\Aearnhr')\n",
        "earnhr = [col for col in df.columns if re.match(pattern_earnhr, col) != None]\n",
        "print(earnhr)\n",
        "\n",
        "pattern_earnm = re.compile('\\Aearnm')\n",
        "earnm = [col for col in df.columns if re.match(pattern_earnm, col) != None]\n",
        "print(earnm)\n",
        "\n",
        "pattern_fn = re.compile('\\Afn')\n",
        "fn = [col for col in df.columns if re.match(pattern_fn, col) != None]\n",
        "print(fn)\n",
        "\n",
        "pattern_ed = re.compile('\\Aed')\n",
        "ed = [col for col in df.columns if re.match(pattern_ed, col) != None]\n",
        "print(ed)\n",
        "\n",
        "pattern_fae = re.compile('\\Afae')\n",
        "fae = [col for col in df.columns if re.match(pattern_fae, col) != None]\n",
        "print(fae)\n",
        "\n",
        "pattern_ict = re.compile('\\Aict')\n",
        "ict = [col for col in df.columns if re.match(pattern_ict, col) != None]\n",
        "print(ict)\n",
        "\n",
        "pattern_nfe12 = re.compile('\\Anfe12')\n",
        "nfe12 = [col for col in df.columns if re.match(pattern_nfe12, col) != None]\n",
        "print(nfe12)\n",
        "\n",
        "pattern_nfehrs = re.compile('\\Anfehrs')\n",
        "nfehrs = [col for col in df.columns if re.match(pattern_nfehrs, col) != None]\n",
        "print(nfehrs)\n",
        "\n",
        "pattern_writ = re.compile('\\Awrit')\n",
        "writ = [col for col in df.columns if re.match(pattern_writ, col) != None]\n",
        "print(writ)\n",
        "\n",
        "pattern_yrs = re.compile('\\Ayrs')\n",
        "yrs = [col for col in df.columns if re.match(pattern_yrs, col) != None]\n",
        "print(yrs)\n",
        "\n",
        "pattern_isco = re.compile('\\Aisco')\n",
        "isco = [col for col in df.columns if re.match(pattern_isco, col) != None]\n",
        "print(isco)\n",
        "\n",
        "pattern_isic = re.compile('\\Aisic')\n",
        "isic = [col for col in df.columns if re.match(pattern_isic, col) != None]\n",
        "print(isic)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['earnhr', 'earnhrppp', 'earnhrbonus', 'earnhrbonusppp', 'earnhrdcl', 'earnhrbonusdcl']\n",
            "['earnmth', 'earnmthppp', 'earnmthselfppp', 'earnmthbonus', 'earnmthall', 'earnmthallppp', 'earnmthbonusppp', 'earnmthalldcl']\n",
            "['fnfaet12', 'fnfe12jr', 'fnfaet12jr', 'fnfaet12njr']\n",
            "['edlevel3', 'edcat8', 'edcat7', 'edcat6', 'edwork']\n",
            "['faet12', 'faet12jr', 'faet12njr']\n",
            "['icthome', 'icthome_wle_ca', 'ictwork', 'ictwork_wle_ca']\n",
            "['nfe12', 'nfe12jr', 'nfe12njr']\n",
            "['nfehrsnjr', 'nfehrsjr', 'nfehrs']\n",
            "['writhome', 'writhome_wle_ca', 'writwork', 'writwork_wle_ca']\n",
            "['yrsqual', 'yrsqual_t', 'yrsget']\n",
            "['iscoskil4', 'isco1c', 'isco2c', 'isco1l', 'isco2l']\n",
            "['isic1l', 'isic2l', 'isic1c', 'isic2c']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg2IWfw_ynli",
        "colab_type": "text"
      },
      "source": [
        "### Earnhr Features\n",
        "\n",
        "Earnings on an hourly basis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O22qJMWHxrGr",
        "colab_type": "code",
        "outputId": "a0c06490-9089-4f07-dce1-713e365ac6df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# earnhr features\n",
        "earnhr_df = df[earnhr + ['earnflag']]\n",
        "print(\"Percent of missing data by Hourly Earnings\")\n",
        "print((earnhr_df.isnull().sum()/earnhr_df.shape[0] * 100).sort_values(ascending=False))\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Hourly Earnings\n",
            "earnhrbonusppp    58.395\n",
            "earnhrbonus       58.395\n",
            "earnhrppp         58.160\n",
            "earnhr            58.160\n",
            "earnhrbonusdcl    27.050\n",
            "earnhrdcl         26.815\n",
            "earnflag          21.070\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y90n36IR7oXk",
        "colab_type": "code",
        "outputId": "be833253-5632-4997-e386-7cee375b8d39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "earnhr_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>earnhr</th>\n",
              "      <th>earnhrppp</th>\n",
              "      <th>earnhrbonus</th>\n",
              "      <th>earnhrbonusppp</th>\n",
              "      <th>earnhrdcl</th>\n",
              "      <th>earnhrbonusdcl</th>\n",
              "      <th>earnflag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7th decile</td>\n",
              "      <td>7th decile</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reported directly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reported directly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Reported directly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lowest decile</td>\n",
              "      <td>Lowest decile</td>\n",
              "      <td>Reported directly</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   earnhr  earnhrppp  ...  earnhrbonusdcl           earnflag\n",
              "0     NaN        NaN  ...      7th decile                NaN\n",
              "1     NaN        NaN  ...             NaN  Reported directly\n",
              "2     NaN        NaN  ...             NaN  Reported directly\n",
              "3     NaN        NaN  ...             NaN  Reported directly\n",
              "4     NaN        NaN  ...   Lowest decile  Reported directly\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n66gKI2AAikk",
        "colab_type": "text"
      },
      "source": [
        "Drop: earnhrbonusppp, earnhrbonus, earnhrppp, earnhr\n",
        "\n",
        "Keep: earnflag, earnhrdcl, earnhrbonusdcl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PswB1MzfBwdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_earnhr_drop = ['earnhrbonusppp', 'earnhrbonus', 'earnhrppp', 'earnhr']\n",
        "df.drop(features_earnhr_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a89jfh4My2Yz"
      },
      "source": [
        "### Earnm Features\n",
        "\n",
        "Earnings on a monthly basis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b8f95608-3843-4842-fd71-76510fcd46cb",
        "id": "slIOq9ihy2ZA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# earnm features\n",
        "earnm_df = df[earnm + ['earnflag']]\n",
        "print(\"Percent of missing data by Monthly Earnings\")\n",
        "print((earnm_df.isnull().sum()/earnm_df.shape[0] * 100).sort_values(ascending=False))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Monthly Earnings\n",
            "earnmthselfppp     93.370\n",
            "earnmthbonusppp    58.355\n",
            "earnmthbonus       58.355\n",
            "earnmthppp         58.055\n",
            "earnmth            58.055\n",
            "earnmthallppp      51.725\n",
            "earnmthall         51.725\n",
            "earnflag           21.070\n",
            "earnmthalldcl      15.670\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu_-Vl8U1ZMf",
        "colab_type": "code",
        "outputId": "28a5addf-211d-4e69-a635-ceea7ae12f39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "earnm_df.head(5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>earnmth</th>\n",
              "      <th>earnmthppp</th>\n",
              "      <th>earnmthselfppp</th>\n",
              "      <th>earnmthbonus</th>\n",
              "      <th>earnmthall</th>\n",
              "      <th>earnmthallppp</th>\n",
              "      <th>earnmthbonusppp</th>\n",
              "      <th>earnmthalldcl</th>\n",
              "      <th>earnflag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6th decile</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4915.959463</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3333.333333</td>\n",
              "      <td>4915.959463</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2nd decile</td>\n",
              "      <td>Reported directly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4485.813010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3041.666667</td>\n",
              "      <td>4485.813010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2nd decile</td>\n",
              "      <td>Reported directly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3153.961720</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28000.000000</td>\n",
              "      <td>3153.961720</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7th decile</td>\n",
              "      <td>Reported directly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9th decile</td>\n",
              "      <td>Reported directly</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   earnmth  earnmthppp  ...  earnmthalldcl           earnflag\n",
              "0      NaN         NaN  ...     6th decile                NaN\n",
              "1      NaN         NaN  ...     2nd decile  Reported directly\n",
              "2      NaN         NaN  ...     2nd decile  Reported directly\n",
              "3      NaN         NaN  ...     7th decile  Reported directly\n",
              "4      NaN         NaN  ...     9th decile  Reported directly\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n166L1z1CNBm",
        "colab_type": "text"
      },
      "source": [
        "Drop: earnmthbonusppp, earnmthselfppp, earnmthbonus, earnmthppp, earnmth, earnmthallppp, earnmthall\n",
        "\n",
        "\n",
        "Keep: earnflag, earnmthalldcl"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm7-lILhDLXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_earnm_drop = ['earnmthbonusppp', 'earnmthselfppp', 'earnmthbonus', 'earnmthppp', 'earnmth', 'earnmthallppp', 'earnmthall']\n",
        "df.drop(features_earnm_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffUWHyLgG6KL",
        "colab_type": "code",
        "outputId": "f1c8e4b7-fa14-4238-d8f1-66b9047c94a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "df.earnmthalldcl.unique()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['6th decile', '2nd decile', '7th decile', '9th decile',\n",
              "       '3rd decile', 'Highest decile', '5th decile', nan, 'Lowest decile',\n",
              "       '8th decile', '4th decile'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwfBHUh-Ew8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ordinalize the string values of this earnmthalldcl\n",
        "\n",
        "df['earnmthalldcl'] = pd.Categorical(df['earnmthalldcl'], \n",
        "                                  categories=['Lowest decile', \n",
        "                                                '2nd decile', \n",
        "                                                '3rd decile', \n",
        "                                                '4th decile', \n",
        "                                                '5th decile', \n",
        "                                                '6th decile', \n",
        "                                                '7th decile',\n",
        "                                                '8th decile', \n",
        "                                                '9th decile', \n",
        "                                                'Highest decile'], \n",
        "                                  ordered=True\n",
        "                                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yFACrRnHpo3",
        "colab_type": "code",
        "outputId": "5d4e1f34-a260-46a8-9451-443e925272bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "df['earnmthalldcl'].head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6th decile\n",
              "1    2nd decile\n",
              "2    2nd decile\n",
              "3    7th decile\n",
              "4    9th decile\n",
              "Name: earnmthalldcl, dtype: category\n",
              "Categories (10, object): [Lowest decile < 2nd decile < 3rd decile < 4th decile ... 7th decile <\n",
              "                          8th decile < 9th decile < Highest decile]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ERdDD5XC0CQ8"
      },
      "source": [
        "### fn Features\n",
        "\n",
        "Formal or information education within the last 12 months"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "70e67e1d-e39a-4b6a-f403-60cf5f331d38",
        "id": "QDBFvozw0Fhh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# fn features\n",
        "fn_df = df[fn + ['fe12']]\n",
        "print(\"Percent of missing data by Formal Education\")\n",
        "print((fn_df.isnull().sum()/fn_df.shape[0] * 100).sort_values(ascending=False))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Formal Education\n",
            "fnfaet12njr    5.200\n",
            "fnfaet12jr     5.200\n",
            "fnfaet12       5.170\n",
            "fnfe12jr       0.435\n",
            "fe12           0.000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4CMfqOH0x2s",
        "colab_type": "code",
        "outputId": "0a504e9f-9edf-4f36-b651-a2f952542c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "fn_df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fnfaet12</th>\n",
              "      <th>fnfe12jr</th>\n",
              "      <th>fnfaet12jr</th>\n",
              "      <th>fnfaet12njr</th>\n",
              "      <th>fe12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Participated in formal and/or non-formal AET</td>\n",
              "      <td>Participated in FE or NFE for JR reasons</td>\n",
              "      <td>Participated in formal or non-formal AET for J...</td>\n",
              "      <td>Did not participate in formal or non-formal AE...</td>\n",
              "      <td>Participated in FE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Participated in formal and/or non-formal AET</td>\n",
              "      <td>Participated in FE or NFE for JR reasons</td>\n",
              "      <td>Participated in formal or non-formal AET for J...</td>\n",
              "      <td>Did not participate in formal or non-formal AE...</td>\n",
              "      <td>Did not participate in FE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Participated in formal and/or non-formal AET</td>\n",
              "      <td>Participated in FE or NFE for JR reasons</td>\n",
              "      <td>Participated in formal or non-formal AET for J...</td>\n",
              "      <td>Did not participate in formal or non-formal AE...</td>\n",
              "      <td>Participated in FE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Participated in formal and/or non-formal AET</td>\n",
              "      <td>Participated in FE or NFE for JR reasons</td>\n",
              "      <td>Participated in formal or non-formal AET for J...</td>\n",
              "      <td>Did not participate in formal or non-formal AE...</td>\n",
              "      <td>Did not participate in FE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>Participated in FE or NFE for JR reasons</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Participated in FE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       fnfaet12  ...                       fe12\n",
              "0  Participated in formal and/or non-formal AET  ...         Participated in FE\n",
              "1  Participated in formal and/or non-formal AET  ...  Did not participate in FE\n",
              "2  Participated in formal and/or non-formal AET  ...         Participated in FE\n",
              "3  Participated in formal and/or non-formal AET  ...  Did not participate in FE\n",
              "4                                           NaN  ...         Participated in FE\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpVfobzVDyxP",
        "colab_type": "text"
      },
      "source": [
        "Drop: fnfaet12njr, fnfaet12jr, fnfaet12, fnfe12jr\n",
        "\n",
        "Keep: fe12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VP6mzWFD8-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_fn_drop = ['fnfaet12njr', 'fnfaet12jr', 'fnfaet12', 'fnfe12jr']\n",
        "df.drop(features_fn_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ODGaaCb20EZ1"
      },
      "source": [
        "### ed Features\n",
        "\n",
        "Highest level of formal education."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "70c5be14-e87a-496d-80d9-793bdd1e24e0",
        "id": "g5xP8ubs0FWq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# ed features\n",
        "ed_df = df[ed]\n",
        "print(\"Percent of missing data by Education\")\n",
        "print((ed_df.isnull().sum()/ed_df.shape[0] * 100).sort_values(ascending=False))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Education\n",
            "edcat8      16.935\n",
            "edlevel3     0.930\n",
            "edcat6       0.060\n",
            "edcat7       0.060\n",
            "edwork       0.005\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqD1HBfz2Z04",
        "colab_type": "code",
        "outputId": "dd593c15-f862-4dca-f1b7-65dc2535bc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        }
      },
      "source": [
        "ed_df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>edlevel3</th>\n",
              "      <th>edcat8</th>\n",
              "      <th>edcat7</th>\n",
              "      <th>edcat6</th>\n",
              "      <th>edwork</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Medium</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>In education and work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>High</td>\n",
              "      <td>Tertiary – professional degree (ISCED 5B)</td>\n",
              "      <td>Tertiary – professional degree (ISCED 5B)</td>\n",
              "      <td>Tertiary – professional degree (ISCED 5B)</td>\n",
              "      <td>In work only</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>High</td>\n",
              "      <td>Tertiary - bachelor/master/research degree (IS...</td>\n",
              "      <td>Tertiary - bachelor/master/research degree (IS...</td>\n",
              "      <td>Tertiary - bachelor/master/research degree (IS...</td>\n",
              "      <td>In education and work</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>High</td>\n",
              "      <td>Tertiary – master degree (ISCED 5A)</td>\n",
              "      <td>Tertiary – master/research degree (ISCED 5A/6)</td>\n",
              "      <td>Tertiary – master/research degree (ISCED 5A/6)</td>\n",
              "      <td>In work only</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Medium</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>Upper secondary (ISCED 3A-B, C long)</td>\n",
              "      <td>In education and work</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  edlevel3  ...                 edwork\n",
              "0   Medium  ...  In education and work\n",
              "1     High  ...           In work only\n",
              "2     High  ...  In education and work\n",
              "3     High  ...           In work only\n",
              "4   Medium  ...  In education and work\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZNkR5yrE90p",
        "colab_type": "text"
      },
      "source": [
        "Drop: edcat8, edwork, edcat6, edlevel3\n",
        "\n",
        "Keep: edcat7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDC4mwYJFbk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_ed_drop = ['edcat8', 'edwork', 'edcat6', 'edlevel3']\n",
        "df.drop(features_ed_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVz0Z3_XIJWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ordinalize the edcat7 categorical feature\n",
        "\n",
        "df['edcat7'] = pd.Categorical(df['edcat7'],\n",
        "                          categories=['Primary or less (ISCED 1 or less)',\n",
        "                                     'Lower secondary (ISCED 2, ISCED 3C short)',\n",
        "                                     'Upper secondary (ISCED 3A-B, C long)',\n",
        "                                     'Post-secondary, non-tertiary (ISCED 4A-B-C)',\n",
        "                                     'Tertiary – bachelor degree (ISCED 5A)',\n",
        "                                     'Tertiary – master/research degree (ISCED 5A/6)\\xa0',\n",
        "                                     'Tertiary - bachelor/master/research degree (ISCED 5A/6)',\n",
        "                                     'Tertiary – professional degree (ISCED 5B)'],\n",
        "                          ordered=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzE7SWbsJaN9",
        "colab_type": "code",
        "outputId": "6a3a1dd8-2735-4bd5-86f1-17bd28d2f4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "df['edcat7'].head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                 Upper secondary (ISCED 3A-B, C long)\n",
              "1            Tertiary – professional degree (ISCED 5B)\n",
              "2    Tertiary - bachelor/master/research degree (IS...\n",
              "3      Tertiary – master/research degree (ISCED 5A/6) \n",
              "4                 Upper secondary (ISCED 3A-B, C long)\n",
              "Name: edcat7, dtype: category\n",
              "Categories (8, object): [Primary or less (ISCED 1 or less) < Lower secondary (ISCED 2, ISCED 3C short) <\n",
              "                         Upper secondary (ISCED 3A-B, C long) < Post-secondary, non-tertiary (ISCED 4A-B-C) <\n",
              "                         Tertiary – bachelor degree (ISCED 5A) < Tertiary – master/research degree (ISCED 5A/6) <\n",
              "                         Tertiary - bachelor/master/research degree (IS... < Tertiary – professional degree (ISCED 5B)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gm4Iv-Ox0E2r"
      },
      "source": [
        "### fae Features\n",
        "\n",
        "Formal AET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "50baa442-2239-4291-a83a-ae0c19cbcc63",
        "id": "_pc1KSBo0FLc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# FAE features\n",
        "fae_df = df[fae]\n",
        "print(\"Percent of missing data by Formal AET\")\n",
        "print((fae_df.isnull().sum()/fae_df.shape[0] * 100).sort_values(ascending=False))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Formal AET\n",
            "faet12njr    5.205\n",
            "faet12jr     5.205\n",
            "faet12       5.170\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccA43DlB4Jwe",
        "colab_type": "code",
        "outputId": "84b90560-4ac6-4a1b-d3f4-2505208fcf90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "fae_df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>faet12</th>\n",
              "      <th>faet12jr</th>\n",
              "      <th>faet12njr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Participated in formal AET</td>\n",
              "      <td>Participated in formal AET for JR reasons</td>\n",
              "      <td>Did not participate in FE for NJR reasons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Did not participate in formal AET</td>\n",
              "      <td>Did not participate in formal AET for JR reasons</td>\n",
              "      <td>Did not participate in FE for NJR reasons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Participated in formal AET</td>\n",
              "      <td>Participated in formal AET for JR reasons</td>\n",
              "      <td>Did not participate in FE for NJR reasons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Did not participate in formal AET</td>\n",
              "      <td>Did not participate in formal AET for JR reasons</td>\n",
              "      <td>Did not participate in FE for NJR reasons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              faet12  ...                                  faet12njr\n",
              "0         Participated in formal AET  ...  Did not participate in FE for NJR reasons\n",
              "1  Did not participate in formal AET  ...  Did not participate in FE for NJR reasons\n",
              "2         Participated in formal AET  ...  Did not participate in FE for NJR reasons\n",
              "3  Did not participate in formal AET  ...  Did not participate in FE for NJR reasons\n",
              "4                                NaN  ...                                        NaN\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UuXtcB3F5ga",
        "colab_type": "text"
      },
      "source": [
        "Drop: faet12njr, faet12hr\n",
        "\n",
        "Keep: faet12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQy8uCrZGAe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_fae_drop = ['faet12njr', 'faet12jr']\n",
        "df.drop(features_fae_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-8XS7uBr0FBS"
      },
      "source": [
        "### ict Features\n",
        "\n",
        "Index of Information, Communication and Technology capabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "cae1b602-6f00-4351-9c80-936a0020dc33",
        "id": "LRHNgd7z0FBW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# earnm features\n",
        "ict_df = df[ict]\n",
        "print(\"Percent of missing data by ICT\")\n",
        "print((ict_df.isnull().sum()/ict_df.shape[0] * 100).sort_values(ascending=False))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by ICT\n",
            "ictwork           7.495\n",
            "icthome           7.180\n",
            "ictwork_wle_ca    6.775\n",
            "icthome_wle_ca    6.770\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puaFf5Si6WK3",
        "colab_type": "code",
        "outputId": "a3ce7554-2a13-4162-8779-7f6054dd4b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "ict_df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>icthome</th>\n",
              "      <th>icthome_wle_ca</th>\n",
              "      <th>ictwork</th>\n",
              "      <th>ictwork_wle_ca</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.261395</td>\n",
              "      <td>More than 40% to 60%</td>\n",
              "      <td>2.624086</td>\n",
              "      <td>More than 60% to 80%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.538845</td>\n",
              "      <td>More than 80%</td>\n",
              "      <td>2.237029</td>\n",
              "      <td>More than 60% to 80%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.624791</td>\n",
              "      <td>More than 60% to 80%</td>\n",
              "      <td>2.067996</td>\n",
              "      <td>More than 40% to 60%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.479338</td>\n",
              "      <td>More than 80%</td>\n",
              "      <td>4.466779</td>\n",
              "      <td>More than 80%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.645463</td>\n",
              "      <td>More than 60% to 80%</td>\n",
              "      <td>0.665753</td>\n",
              "      <td>Lowest to 20%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    icthome        icthome_wle_ca   ictwork        ictwork_wle_ca\n",
              "0  2.261395  More than 40% to 60%  2.624086  More than 60% to 80%\n",
              "1  3.538845         More than 80%  2.237029  More than 60% to 80%\n",
              "2  2.624791  More than 60% to 80%  2.067996  More than 40% to 60%\n",
              "3  3.479338         More than 80%  4.466779         More than 80%\n",
              "4  2.645463  More than 60% to 80%  0.665753         Lowest to 20%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qbo1S7U691C",
        "colab_type": "text"
      },
      "source": [
        "Drop: 'icthome_wle_ca', 'ictwork_wle_ca' \n",
        "\n",
        "Keep: ictwork, icthome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnja-WwkG-yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_ict_drop = [ 'icthome_wle_ca', 'ictwork_wle_ca' ]\n",
        "df.drop(features_ict_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D1o51vYG0FLa"
      },
      "source": [
        "### nfe12 Features\n",
        "\n",
        "Only informal education within the last 12 months"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b791a0f2-1daf-4cf5-9812-9b856f0277ff",
        "id": "O5V5XJYf0E2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# nfe12 features\n",
        "earnm_nfe12 = df[nfe12]\n",
        "print(\"Percent of missing data by Informal Education with the last 12 months\")\n",
        "print((earnm_nfe12.isnull().sum()/earnm_df.shape[0] * 100).sort_values(ascending=False))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Informal Education with the last 12 months\n",
            "nfe12njr    0.42\n",
            "nfe12jr     0.42\n",
            "nfe12       0.42\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MnBjXmW9Gpp",
        "colab_type": "code",
        "outputId": "d92ef4f3-9e06-4810-b9ce-96c896fc0542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "earnm_nfe12.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nfe12</th>\n",
              "      <th>nfe12jr</th>\n",
              "      <th>nfe12njr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Did not participate in NFE</td>\n",
              "      <td>Did not participate in NFE for JR reasons</td>\n",
              "      <td>Did not participate in NFE for NJR reasons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Participated in NFE</td>\n",
              "      <td>Participated in NFE for JR reasons</td>\n",
              "      <td>Did not participate in NFE for NJR reasons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Participated in NFE</td>\n",
              "      <td>Did not participate in NFE for JR reasons</td>\n",
              "      <td>Participated in NFE for NJR reasons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Participated in NFE</td>\n",
              "      <td>Participated in NFE for JR reasons</td>\n",
              "      <td>Did not participate in NFE for NJR reasons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Did not participate in NFE</td>\n",
              "      <td>Did not participate in NFE for JR reasons</td>\n",
              "      <td>Did not participate in NFE for NJR reasons</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        nfe12  ...                                    nfe12njr\n",
              "0  Did not participate in NFE  ...  Did not participate in NFE for NJR reasons\n",
              "1         Participated in NFE  ...  Did not participate in NFE for NJR reasons\n",
              "2         Participated in NFE  ...         Participated in NFE for NJR reasons\n",
              "3         Participated in NFE  ...  Did not participate in NFE for NJR reasons\n",
              "4  Did not participate in NFE  ...  Did not participate in NFE for NJR reasons\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf0VflMEHbw1",
        "colab_type": "text"
      },
      "source": [
        "Drop: nfe12jr, nfe12njr\n",
        "\n",
        "Keep: nfe12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbpPV40XHe4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_nfe12_drop = ['nfe12jr', 'nfe12njr']\n",
        "df.drop(features_nfe12_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FD5bdEmS0FWi"
      },
      "source": [
        "### nfehrs Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "10fc4776-2c49-4238-c4ad-b8e70ff82cf8",
        "id": "cPySrEtU0EaD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# nfehrs features\n",
        "nfehrs_df = df[nfehrs]\n",
        "print(\"Percent of missing data by Informal Education Hours\")\n",
        "print((nfehrs_df.isnull().sum()/nfehrs_df.shape[0] * 100).sort_values(ascending=False))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Informal Education Hours\n",
            "nfehrsjr     51.365\n",
            "nfehrsnjr    51.365\n",
            "nfehrs       39.775\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2x6CTWZ9Xvx",
        "colab_type": "code",
        "outputId": "4adbb347-d6fc-4cec-acc6-449c9e26764f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "nfehrs_df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>nfehrsnjr</th>\n",
              "      <th>nfehrsjr</th>\n",
              "      <th>nfehrs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>320.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   nfehrsnjr  nfehrsjr  nfehrs\n",
              "0        NaN       NaN     NaN\n",
              "1        0.0      40.0    40.0\n",
              "2        NaN       NaN    40.0\n",
              "3        NaN       NaN   320.0\n",
              "4        NaN       NaN     NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K8SozQjHwFv",
        "colab_type": "text"
      },
      "source": [
        "Drop: nfehrsjr, nfehrsnjr\n",
        "\n",
        "Keep: nfehrs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75fuofvhHwRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_nfehrs = ['nfehrsjr', 'nfehrsnjr']\n",
        "df.drop(features_nfehrs, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uxv-ShKO0FhY"
      },
      "source": [
        "### writ Features\n",
        "\n",
        "Writing capabilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2fb56c62-f9f5-44f3-c730-f452839948d0",
        "id": "6pW5XzB00CRF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# writ features\n",
        "writ_df = df[writ]\n",
        "print(\"Percent of missing data by Writing Capabilities\")\n",
        "print((writ_df.isnull().sum()/writ_df.shape[0] * 100).sort_values(ascending=False))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Writing Capabilities\n",
            "writhome           4.705\n",
            "writwork           1.900\n",
            "writwork_wle_ca    0.000\n",
            "writhome_wle_ca    0.000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdDec82M901V",
        "colab_type": "code",
        "outputId": "73fb4567-c684-49cc-8677-3afffb5aa450",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "writ_df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>writhome</th>\n",
              "      <th>writhome_wle_ca</th>\n",
              "      <th>writwork</th>\n",
              "      <th>writwork_wle_ca</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.574343</td>\n",
              "      <td>More than 60% to 80%</td>\n",
              "      <td>3.690521</td>\n",
              "      <td>More than 80%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.116459</td>\n",
              "      <td>More than 80%</td>\n",
              "      <td>3.101801</td>\n",
              "      <td>More than 80%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.979574</td>\n",
              "      <td>More than 80%</td>\n",
              "      <td>2.818857</td>\n",
              "      <td>More than 80%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.036055</td>\n",
              "      <td>More than 80%</td>\n",
              "      <td>3.690521</td>\n",
              "      <td>More than 80%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.675496</td>\n",
              "      <td>More than 60% to 80%</td>\n",
              "      <td>0.056130</td>\n",
              "      <td>Lowest to 20%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   writhome       writhome_wle_ca  writwork writwork_wle_ca\n",
              "0  2.574343  More than 60% to 80%  3.690521   More than 80%\n",
              "1  3.116459         More than 80%  3.101801   More than 80%\n",
              "2  2.979574         More than 80%  2.818857   More than 80%\n",
              "3  3.036055         More than 80%  3.690521   More than 80%\n",
              "4  2.675496  More than 60% to 80%  0.056130   Lowest to 20%"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jPAMbduIyqh",
        "colab_type": "text"
      },
      "source": [
        "Drop: writhome_wle_ca, writwork_wle_ca\n",
        "\n",
        "Keep: writhome, writwork"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwVTnHFEIy1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_writ_drop = [ 'writhome_wle_ca', 'writwork_wle_ca' ]\n",
        "df.drop(features_writ_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuZSWKJD-Gsj",
        "colab_type": "text"
      },
      "source": [
        "## yrs features\n",
        "\n",
        "Imputed years of formal education needed to get the job (self-reported - estimated), Highest level of education obtained imputed into years of education (estimated), Derived variable on total years of schooling during lifetime - top coded at 24 (Trend)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1VsQT4v-E3V",
        "colab_type": "code",
        "outputId": "70d46e2e-34fc-4296-9692-1f23eda669f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# writ features\n",
        "yrs_df = df[yrs]\n",
        "print(\"Percent of missing data by Writing Capabilities\")\n",
        "print((yrs_df.isnull().sum()/yrs_df.shape[0] * 100).sort_values(ascending=False))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Writing Capabilities\n",
            "yrsget       22.005\n",
            "yrsqual_t    13.845\n",
            "yrsqual      12.915\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2iRTfWW-vKD",
        "colab_type": "code",
        "outputId": "fa354463-0527-4b0e-9b83-a4ba03b4af13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "yrs_df.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yrsqual</th>\n",
              "      <th>yrsqual_t</th>\n",
              "      <th>yrsget</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   yrsqual  yrsqual_t  yrsget\n",
              "0     12.0       12.0    14.0\n",
              "1     15.0       15.0     NaN\n",
              "2     16.0       16.0     NaN\n",
              "3     18.0       18.0     NaN\n",
              "4     12.0       12.0    12.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTD4VAmyKjRj",
        "colab_type": "text"
      },
      "source": [
        "Drop: yrsget, yrsqual\n",
        "\n",
        "Keep: yrsqual_t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hRxoeYJKjbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_yrs_drop = ['yrsget', 'yrsqual']\n",
        "df.drop(features_yrs_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_KjX1AK_kss",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## yearlyincpr\n",
        "\n",
        "Yearly income percentile rank category (estimated)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wU88wO-w_NU6",
        "colab_type": "code",
        "outputId": "9805d277-41a8-4033-82fe-1f9730373d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Percent of missing data by Yearly Income PCT rank category\")\n",
        "print((df.yearlyincpr.isnull().sum()/df.yearlyincpr.shape[0]) * 100)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Yearly Income PCT rank category\n",
            "16.195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTa9WUwn_I2e",
        "colab_type": "code",
        "outputId": "9c664b60-b1f2-4aac-9be3-92fa27ede15c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "df.yearlyincpr.value_counts()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50 to less than 75    4221\n",
              "75 to less than 90    3967\n",
              "90 or more            3903\n",
              "25 to less than 50    2747\n",
              "10 to less than 25    1111\n",
              "Less than 10           812\n",
              "Name: yearlyincpr, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc35Vlj9C-Mj",
        "colab_type": "code",
        "outputId": "bf37186f-1562-4865-b045-c279dc49cb5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "df.loc[:10, ['yearlyincpr', 'earnmthalldcl']]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yearlyincpr</th>\n",
              "      <th>earnmthalldcl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>50 to less than 75</td>\n",
              "      <td>6th decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>75 to less than 90</td>\n",
              "      <td>2nd decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>75 to less than 90</td>\n",
              "      <td>2nd decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25 to less than 50</td>\n",
              "      <td>7th decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10 to less than 25</td>\n",
              "      <td>9th decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25 to less than 50</td>\n",
              "      <td>6th decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>50 to less than 75</td>\n",
              "      <td>3rd decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>90 or more</td>\n",
              "      <td>Highest decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>25 to less than 50</td>\n",
              "      <td>5th decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>75 to less than 90</td>\n",
              "      <td>2nd decile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>90 or more</td>\n",
              "      <td>Highest decile</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           yearlyincpr   earnmthalldcl\n",
              "0   50 to less than 75      6th decile\n",
              "1   75 to less than 90      2nd decile\n",
              "2   75 to less than 90      2nd decile\n",
              "3   25 to less than 50      7th decile\n",
              "4   10 to less than 25      9th decile\n",
              "5   25 to less than 50      6th decile\n",
              "6   50 to less than 75      3rd decile\n",
              "7           90 or more  Highest decile\n",
              "8   25 to less than 50      5th decile\n",
              "9   75 to less than 90      2nd decile\n",
              "10          90 or more  Highest decile"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_urVYihLmvc",
        "colab_type": "text"
      },
      "source": [
        "Keep: yearlyincpr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1f_Dr5yCO_E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ordinalize yearlyincpr\n",
        "\n",
        "df.yearlyincpr = pd.Categorical(df['yearlyincpr'], \n",
        "                                categories=[\"Less than 10\", \"10 to less than 25\", \n",
        "                                            \"25 to less than 50\", '50 to less than 75', \n",
        "                                            '75 to less than 90', '90 or more'], \n",
        "                                ordered=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrAIX6ZYUIZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ordinalize iscoskil4\n",
        "\n",
        "df.iscoskil4 = pd.Categorical(df['iscoskil4'], \n",
        "                categories=['Elementary occupations', \n",
        "                            'Skilled occupations',\n",
        "                            'Semi-skilled blue-collar occupations', \n",
        "                            'Semi-skilled white-collar occupations'], \n",
        "                ordered=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eoXUFTh6n0Gj"
      },
      "source": [
        "\n",
        "## ISCO features\n",
        "\n",
        "Occupational classification of respondent's job "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a8ac0dd9-25c8-4e91-d0cf-6625689b6321",
        "id": "6A6jq4gVn0Gv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# isic features\n",
        "isco_df = df[isco]\n",
        "print(\"Percent of missing data by Industry classification\")\n",
        "print(((isco_df.isnull().sum()/isco_df.shape[0]) * 100).sort_values(ascending=False))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Industry classification\n",
            "iscoskil4    1.2\n",
            "isco2l       0.0\n",
            "isco1l       0.0\n",
            "isco2c       0.0\n",
            "isco1c       0.0\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b5bb5730-176f-433e-862d-5d15efea0799",
        "id": "yAe7-DWQn0G-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "isco_df.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iscoskil4</th>\n",
              "      <th>isco1c</th>\n",
              "      <th>isco2c</th>\n",
              "      <th>isco1l</th>\n",
              "      <th>isco2l</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Skilled occupations</td>\n",
              "      <td>3</td>\n",
              "      <td>9999</td>\n",
              "      <td>9996</td>\n",
              "      <td>9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Skilled occupations</td>\n",
              "      <td>3</td>\n",
              "      <td>31</td>\n",
              "      <td>9996</td>\n",
              "      <td>9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Skilled occupations</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>9996</td>\n",
              "      <td>9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Skilled occupations</td>\n",
              "      <td>3</td>\n",
              "      <td>33</td>\n",
              "      <td>9996</td>\n",
              "      <td>9996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Semi-skilled blue-collar occupations</td>\n",
              "      <td>8</td>\n",
              "      <td>83</td>\n",
              "      <td>9996</td>\n",
              "      <td>9996</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              iscoskil4  isco1c  isco2c  isco1l  isco2l\n",
              "0                   Skilled occupations       3    9999    9996    9996\n",
              "1                   Skilled occupations       3      31    9996    9996\n",
              "2                   Skilled occupations       2      24    9996    9996\n",
              "3                   Skilled occupations       3      33    9996    9996\n",
              "4  Semi-skilled blue-collar occupations       8      83    9996    9996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pn8OP1lVn0HI"
      },
      "source": [
        "Drop: isco2l, isco1l, isco1c\n",
        "\n",
        "Keep: isco2c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TwCyu6wyn0HK",
        "colab": {}
      },
      "source": [
        "features_isco_drop = ['isco2l', 'isco1l', 'isco1c']\n",
        "df.drop(features_isco_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nwmFbEJHOL_7"
      },
      "source": [
        "\n",
        "## isic features\n",
        "\n",
        "Industrial classification of respondent's job "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d7b8286f-0cb6-4146-8026-9859b43b635b",
        "id": "NWbDrYkuOL__",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# isic features\n",
        "isic_df = df[isic]\n",
        "print(\"Percent of missing data by Industry classification\")\n",
        "print(((isic_df.isnull().sum()/isic_df.shape[0]) * 100).sort_values(ascending=False))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percent of missing data by Industry classification\n",
            "isic2l    6.08\n",
            "isic2c    0.43\n",
            "isic1c    0.00\n",
            "isic1l    0.00\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ecead599-99fa-4b39-c321-7a7c6dbb9c17",
        "id": "zjKbbdB5OMAJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "isic_df.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isic1l</th>\n",
              "      <th>isic2l</th>\n",
              "      <th>isic1c</th>\n",
              "      <th>isic2c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9999</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M</td>\n",
              "      <td>9999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9996</td>\n",
              "      <td>9996</td>\n",
              "      <td>C</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9996</td>\n",
              "      <td>9996</td>\n",
              "      <td>D</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9996</td>\n",
              "      <td>9996</td>\n",
              "      <td>N</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9996</td>\n",
              "      <td>9996</td>\n",
              "      <td>G</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  isic1l isic2l isic1c isic2c\n",
              "0   9999    NaN      M   9999\n",
              "1   9996   9996      C     25\n",
              "2   9996   9996      D     35\n",
              "3   9996   9996      N     82\n",
              "4   9996   9996      G     45"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWVEEwDjOqQy",
        "colab_type": "text"
      },
      "source": [
        "Drop: isic2l, isic1l, isic2c\n",
        "\n",
        "Keep: isic1c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkxHGNBUO4ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_isic_drop = ['isic2l', 'isic1l', 'isic2c']\n",
        "df.drop(features_isic_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq7-u81IUGU3",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing (Dropping and Replacing) for Missing/Unavailable Value Encodings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYQR39H2CUzu",
        "colab_type": "text"
      },
      "source": [
        "With this particular dataset, some missing or unavailable column values are encoded as a numeric value. Some particular values that were used to encode these values are: 999, 9996, 9997, 9998, 9999, 99999. Let's have a look at them first. Our next step would be to map these values to np.nan for imputation afterwards. We make a list of these notable features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duzUFBFlD4_1",
        "colab_type": "text"
      },
      "source": [
        "Also note that for some features, the integer values or float are actually strings, thus making the feature column itself an object column. What we would want here is to cast these specifically as integers, after having dealt with the letter encodings. Using Int64\n",
        "* ~~v71~~ -> cast letters to np.nan, cast values to np.nan, cast all to Int64\n",
        "* ~~v105~~ -> drop\n",
        "\n",
        "Letter columns that use numeric encodings to indicate missing:\n",
        "* ~~isic1c~~ -> replace num string as np.nan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfOEeaVXC4xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "possible_missing_data_codes = ['999', 9995, '9995', 9996, '9996' ,9997, 9998,'9998', 9999, '9999', '99999']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyRo61874BsA",
        "colab_type": "text"
      },
      "source": [
        "Drop v105 because it is the same as isic features and we already drop those. \n",
        "\n",
        "We then impute the missing/unavailable encoded values in isic1c with np.nan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIa_TpnXTxiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# v105 is to v71 what isic1l is to isic1c; one refers to industry of last job and one refers to industry of current job\n",
        "df.drop(['v71', 'v105'], inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziVlHDOMWmvX",
        "colab_type": "code",
        "outputId": "db789803-59d8-4993-ff7f-3be43a071517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "df.isic1c.unique()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['M', 'C', 'D', 'N', 'G', 'P', 'I', 'O', 'K', 'F', 'A', 'L', 'R',\n",
              "       '9996', 'Q', 'H', 'J', '9999', 'B', '9995', 'T', '9998', 'S', 'E',\n",
              "       '9997'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJXs2B9QTLss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "missing_values_to_replace = ['9995', '9996', '9997', '9998', '9999']\n",
        "\n",
        "df['isic1c'].replace(to_replace=missing_values_to_replace, value=np.nan, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Fu3ndX_8Eb",
        "colab_type": "text"
      },
      "source": [
        "# Drop Missing Data by Axes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoSrbh7Un5wJ",
        "colab_type": "text"
      },
      "source": [
        "## Missing Data Proportion by Columns\n",
        "We will want to drop a number of the columns have have a significant amount of its data missing. Some features have disproportionately more data missing than others and there will be no way to impute those features. In which case dropping those features might be the best course of action to clean up the dataset. Feature column values that have a proportion of their data missing equal to or greater than an arbitrary threshold will have their columns dropped. Afterwards, a row-wise operation of this procedure will be further applied to include cleaner samples in the dataset. \n",
        "________________\n",
        "\n",
        "We will examine to see which features reach this threshold requirement to be dropped before we do any such dropping. \n",
        "____________ \n",
        "\n",
        "Afterwards, we will want to smarly impute the remaining missing data points as much as we can."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-V0WcWv8hOs",
        "colab_type": "code",
        "outputId": "97c5577f-eb9b-49e0-d945-511970f56033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# features by % of missing data\n",
        "dropthreshold = 50\n",
        "\n",
        "pct_missing_list = list([col for col in df.columns if df[col].isnull().sum()/df.shape[0] * 100 >= dropthreshold])\n",
        "pm_list = []\n",
        "\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].isnull().sum()/df.shape[0] * 100 >= dropthreshold:\n",
        "        pm_list.append(df[col].isnull().sum()/df.shape[0] * 100)\n",
        "        \n",
        "dropped_columns_dataframe = pd.DataFrame(pm_list, columns=['% Missing Data'], index=pct_missing_list).sort_values(by='% Missing Data', ascending=False)\n",
        "\n",
        "# get the data points in the dataframe that have >= 50% of their data missing\n",
        "df_col_drop_gtoe_50 = df[pct_missing_list]\n",
        "kept_feat_cols = list(set(df.columns) - set(pct_missing_list))\n",
        "reduced_df = df[kept_feat_cols]\n",
        "\n",
        "print(\"The features with {}% or more of it's data missing will be dropped from the dataset.\".format(dropthreshold))\n",
        "print(\"{} Columns will be dropped, which constitutes a {}% drop in the number of features from the original dataset\".format(\n",
        "    len(df.columns) - len(kept_feat_cols), \n",
        "    ((len(df.columns) - len(kept_feat_cols)) / len(df.columns)) * 100\n",
        ")\n",
        "     )\n",
        "\n",
        "# save the results to csv to look at later\n",
        "dropped_columns_dataframe.to_csv('./features_greater_50_percent_missing_data_by_cols.csv')\n",
        "\n",
        "# write out the dataframe after having dropped the columns\n",
        "reduced_df.to_csv('./reduced_df_gtoe_{}_missing_df.csv'.format(dropthreshold))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The features with 50% or more of it's data missing will be dropped from the dataset.\n",
            "125 Columns will be dropped, which constitutes a 36.65689149560117% drop in the number of features from the original dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "selF5Fh8brN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def report_missing(preproc_data, postproc_data, axis=1, dropthreshold=None):\n",
        "    \"\"\" dataset in dataframe format passed in is before and after dropping feature columns or rows. \"\"\"\n",
        "    print(\"The features with {}% or more of it's data missing will be dropped from the dataset.\".format(dropthreshold))\n",
        "    \n",
        "    if axis == 1:\n",
        "        print(\"{} Columns will be dropped, which constitutes a {}% drop in the number of features from the original dataset\".format(\n",
        "        len(preproc_data.columns) - len(postproc_data.columns), \n",
        "        ((len(preproc_data.columns) - len(postproc_data.columns)) / len(preproc_data.columns)) * 100\n",
        "    )\n",
        "         )\n",
        "    \n",
        "    else:\n",
        "        print(\"{} Data Points will be dropped, which constitutes a {}% drop in the number of data points from the original dataset\".format(\n",
        "        preproc_data.shape[0] - postproc_data.shape[0], \n",
        "        ((preproc_data.shape[0] - postproc_data.shape[0]) / preproc_data.shape[0]) * 100\n",
        "    )\n",
        "         )\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7KwoFyV4DyC",
        "colab_type": "text"
      },
      "source": [
        "## Missing Data Proportion By Row \n",
        "An alternative strategy would be just to drop all of the rows with missing values. This step requires a little more wor as we will have more than 0 data points that have missing values and require imputation of missing values.\n",
        "\n",
        "\n",
        "Lets first drop any data ROWS with 20% or more missing values and see what we end up with.\n",
        "\n",
        "________________\n",
        "\n",
        "\n",
        "Just a refresher on how to how to conditionally select rows from a data frame:\n",
        "\n",
        "To select rows whose column value equals a scalar, some_value, use ==:\n",
        "df.loc[df['column_name'] == some_value]\n",
        "\n",
        "\n",
        "To select rows whose column value is in an iterable, some_values, use isin:\n",
        "df.loc[df['column_name'].isin(some_values)]\n",
        "\n",
        "Combine multiple conditions with &:\n",
        "df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]\n",
        "\n",
        "Conditionally set values\n",
        "df[label] = df.variable.where('label' == 'another_label')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3PETq5SC7wr",
        "colab_type": "code",
        "outputId": "3b29d514-fab8-4222-e94e-eed8df449e99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Data points with percentage of data missing and greater will be dropped from the dataset\n",
        "dropthreshold = 20\n",
        "\n",
        "# get the data points in the dataframe that have >= 30% of their data missing\n",
        "to_drop_df = reduced_df.loc[(reduced_df.isnull().sum(axis=1)/reduced_df.shape[1]*100) >= dropthreshold]\n",
        "row_reduced_df = reduced_df.loc[(\n",
        "    reduced_df.isnull().sum(axis=1) / reduced_df.shape[1]*100 < dropthreshold\n",
        ")]\n",
        "\n",
        "report_missing(reduced_df, row_reduced_df, axis=0, dropthreshold=dropthreshold)\n",
        "\n",
        "# give the new dataframe a better name\n",
        "final_kept_df = row_reduced_df\n",
        "\n",
        "# save the dataframe to disk after the processing\n",
        "final_kept_df.to_csv('./final_kept_df.csv')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The features with 20% or more of it's data missing will be dropped from the dataset.\n",
            "1304 Data Points will be dropped, which constitutes a 6.52% drop in the number of data points from the original dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6RsGfvzzPce",
        "colab_type": "text"
      },
      "source": [
        "## Missing Data by Data Type\n",
        "We can see that there are a considerable amount of missing values for this dataset. We will have to dig in to understand which features would have missing values, and can we come up with a strategy to handle it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAGegy6qZyLH",
        "colab_type": "code",
        "outputId": "ab212a90-bbd6-4dd9-8edf-9fd0dd6eb591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# separate out the numeric and categorical variables to see how much of each are missing\n",
        "def df_by_type_splitter(dataframe):\n",
        "    \"\"\" a larger dataframe into immediately identifiable numeric and other type dataframes\"\"\"\n",
        "    num_df = dataframe._get_numeric_data().copy()\n",
        "    cat_df = dataframe.select_dtypes(exclude = [int, float]).copy()\n",
        "\n",
        "    return num_df, cat_df\n",
        "\n",
        "\n",
        "numeric_df, categorical_df = df_by_type_splitter(row_reduced_df)\n",
        "\n",
        "\n",
        "print(\"Number of Numeric Features: {}\".format(numeric_df.shape[1]))\n",
        "print(\"Number of Categorical Features: {}\".format(categorical_df.shape[1]))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Numeric Features: 31\n",
            "Number of Categorical Features: 185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc54cbPazRx-",
        "colab_type": "text"
      },
      "source": [
        "## Numeric Feature Missing Values\n",
        "\n",
        "It still appears that after dropping the data points and features with a majority of their data points missing, that about a third of the numeric features containg NaN/missing values in more than 20% of their data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83BqJ9XwGdyJ",
        "colab_type": "code",
        "outputId": "a6980621-d787-416e-bc89-6c0478f158ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        }
      },
      "source": [
        "# take a look at the missing values from the numeric features dataframe\n",
        "print(\"Proportionally, numeric features contribute {0:.2f}% of the total features in the dataset\".format(numeric_df.shape[1]/final_kept_df.shape[1]*100))\n",
        "a = pd.Series(numeric_df.isnull().sum().sort_values(ascending=False)/(numeric_df.shape[0]) * 100)\n",
        "print(a[:12])\n",
        "a.plot(kind='bar')\n",
        "\n",
        "# 9 numeric features of 37 with more than 20% of it's data missing\n",
        "print(\"The number of numeric features with more than 20% of its values missing is: {}, which is {}% of all numeric features\".format(9, (9/numeric_df.shape[1]*100)))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportionally, numeric features contribute 14.35% of the total features in the dataset\n",
            "leavedu        44.228712\n",
            "v202           39.120668\n",
            "age_r          38.928113\n",
            "v231           38.350449\n",
            "nfehrs         38.088361\n",
            "v272           37.836970\n",
            "v52            37.601626\n",
            "v33            37.569534\n",
            "v63            36.360719\n",
            "yrsqual_t      13.441378\n",
            "learnatwork     7.980317\n",
            "v135            7.541720\n",
            "dtype: float64\n",
            "The number of numeric features with more than 20% of its values missing is: 9, which is 29.03225806451613% of all numeric features\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFGCAYAAAB60WT1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ufjLzSH34y",
        "colab_type": "text"
      },
      "source": [
        "We are going to explore correlation/collinearity between the numeric features and drop redundant features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN8_YTMoMhfb",
        "colab_type": "code",
        "outputId": "29dafbf7-bc5f-46f9-ab3b-508ad8a03cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# categorical feature with numeric encoding\n",
        "\n",
        "cat_feat_with_num_encoding = ['v224','v239', 'isco2c']\n",
        "for i in cat_feat_with_num_encoding:\n",
        "    print(\"This categorical feature with numeric encodings has {} unique values: {}\".format(i, len(numeric_df[i].unique())))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This categorical feature with numeric encodings has v224 unique values: 27\n",
            "This categorical feature with numeric encodings has v239 unique values: 413\n",
            "This categorical feature with numeric encodings has isco2c unique values: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-w24rJslxoA",
        "colab_type": "text"
      },
      "source": [
        "Although semantically inappropriate, let's, as an exercise, treat these high-category numerically encoded features as numeric features. Depening on the results of our exploration, we may go back to treating these features as categorical variables in the final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsUsMHe6IPht",
        "colab_type": "text"
      },
      "source": [
        "## Pre-Imputer Imputation for numeric features\n",
        "Some further processing can be done before the imputation step such as (dropping,casting, merging, etc). The next few segments of code will go through the next preprocessing steps as outlined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEL-EAuXNRLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we drop 'age_r' as there is another categorical feature containing the same demographic information with more completeness, with the tradeoff of numeric granularity\n",
        "\n",
        "numeric_df.drop(columns='age_r', inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_A3eDpsNoZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we drop 'row' because this is a pretty useless category\n",
        "\n",
        "numeric_df.drop(columns='row', inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMjmxE2kBITx",
        "colab_type": "text"
      },
      "source": [
        "Because v239 has many numeric encodings as a categorical feature, we can initially treat it as a numeric feature and then see whether there is a relationship between it and the response variable: 'job_performance'. We keep the variable if it is a strong predictor of employee job performance; otherwise, we drop the largely-categorized variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF57e0tuILMz",
        "colab_type": "text"
      },
      "source": [
        "As we can gleen from the heatmap below in Seaborn, there is no correlation between the feature v239 (current occupation) and job performance of an employee, if current occuptational coding were treated as a numeric variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukoedFzgIJBK",
        "colab_type": "code",
        "outputId": "29186d96-528f-46d4-efd7-5a6f9f0b3714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "o = pd.DataFrame(numeric_df['v239'].fillna(value=numeric_df['v239'].median()))\n",
        "o['job_performance'] = numeric_df['job_performance']\n",
        "corr = o.corr()\n",
        "sns.heatmap(corr, annot=True)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d7fc71b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV4AAAEFCAYAAACrYo8uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJLuT4IRKl51",
        "colab_type": "text"
      },
      "source": [
        "What happens when we look at v239 as a categorical feature? Well, we don't really get to see much of anything at all from onehot encoding this highly categorized feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crCGh2PkJyk0",
        "colab_type": "code",
        "outputId": "d9e5b886-c666-45be-a5ca-d143449d19a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        }
      },
      "source": [
        "get_dummy_features = pd.get_dummies(o['v239'], drop_first=True)\n",
        "temp_df_dummies = pd.concat([o[['job_performance']], get_dummy_features], axis=1).iloc[4:10]\n",
        "print(temp_df_dummies.head())\n",
        "\n",
        "corr = temp_df_dummies.corr()\n",
        "sns.heatmap(corr, annot=True)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   job_performance  7.0  8.0  12.0  ...  9996.0  9997.0  9998.0  9999.0\n",
            "4      2079.471114    0    0     0  ...       0       0       0       1\n",
            "5      3197.167530    0    0     0  ...       0       0       0       0\n",
            "6      2627.234538    0    0     0  ...       0       0       0       0\n",
            "7      3147.474706    0    0     0  ...       0       0       0       1\n",
            "8      2618.112809    0    0     0  ...       0       0       0       1\n",
            "\n",
            "[5 rows x 412 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d7d34b630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAFHCAYAAADNx2nMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzsnXu8XdO5/r8PcWmp+6WujRZR15TE\n5RxVl+OWqqDVUkVVf6qltKol1YNSp+hFT6ulGopTRSltXEpUqSpBEIkghARRFSTuLZL9/P4YYyUz\nK2vtPdfea2fvtdf7zWd89lpjvnOMMddcme8aY7zjGbJNEARBEAwUFuvrBgRBEARBMwnHFgRBEAwo\nwrEFQRAEA4pwbEEQBMGAIhxbEARBMKAIxxYEQRAMKMKx9QOGDBly0ZAhQ2YOGTLk4b5uywBAwE+B\nqcBEYMs6dmcAzwJvVOV/ALg1n3s7sHavtLJr9gCmkK7jxE7sPgkYGJbfDwb+BUzI6fzea2JDdHU9\nRwKTSG2+E9i46vi6pHt1fC+2sT9Q9vtbYQxQfG6cCjzH/Ps/ovlN7P+EY+sfXEz6jx/0nD2BDXI6\nAjivjt11wNY18n8IXApsDpwGfL8X2tgViwM/J13LxsCBLPygB3gfcCxwT1X+k8DQnI7svWaWpsz1\n/BbYjNTms4EfVx3/MfCn3m1mv6Ds9xdgPxb+YQZwDvPv/43NbmAtJF0kaaakmj/OlfippKmSJkra\nsnDsUElP5HRoM9pTyrFJuquTYztKur4ZjSnZlqUk/VnSBEmfWVT19iZTpky5A5jV1+0YIIwkOSYD\n44AVgDVq2I0Dnq+RvzHwl/z6tlzeomZr0i/2p4B3gCvqtON04Czg34uuad2izPW8Vni9DOn+VdgH\nmAZM7sU29hfKfn+XBY4DvrfomtYpF9P5j/OaDlvSSsApwDak78kpklbsaWNKOTbb/9HTipqBpEHA\nRwBsD7V9ZcnzFu/VhgX9ibVIQ4wVZuS8sjxE+iUMsC+pV7Ryc5pWmjLXsCWwDnBDjfPXAx4E/gp8\ntDca2CBl78lRpN7m2cAxOW9Z4ATgu73ZwH5E2c/qdOBHwFs1jh1NGsa8COixkyiD7a5+nI8ELnVi\nHLCCpDWA3YFbbM+yPRu4hWaMXtnuMpG6uwJ+QBrPnQR8Jh/bEbiD9B9sCmlMf7EuyjqH9OvrVmDV\nnP8h4CbgfuBvwEY5/+Jc5j2kGzUVeJU0fvwhYBfSf+JJ+fhS+bzppF+zDwAHkOZLzgHGA48Cw4Fr\ngCeA7xXa94fchsnAEVXtPoP04BsHrJ7zVweuzfkPAf+R8z8H3Jvb+Utg8RqfxRG5PeO/f+qJ/vjH\nP+6gd9l17d2969q793Uzesw7Dz3gWZ//dF83o6lM2Wh3T9mo9e9Nb7PlsF1te4zTc2Sw7Yc9/7my\nuu3FbS9m+wzbF7nOs/idF5902VR8VuV0RHV5pPndh2vVBVwPbF94fytpXvh44DuF/P8Gjq/X5rKp\nEcf2SZI3XTw/zJ8hdZF3JA2FfDAfuwX4VCdlGTgovz4ZOLdwoRvk19sAf/F8x3Z9xTHk+q7Pr5cm\n/brZML+/FPia5zu2bxXqvR04K78+FvhHbv9SpF9FK+djK+W/7yE58ZUL7f5Efn125WYAVxbqXBxY\nHvgwaQ5niZz/C+CQzj7jZ599NhxbEARl+Yft6bZn2H7H9u1e+LlS7fS67djqlVFM/cmxNRI8sj1w\nue25tl8gDXMMz8futf2U7bnA5dm2Hh3ZGQD8Bthe0rLAfwBXSar0cIrjylflsqsZAkyz/Xh+fwmw\nQ+F49VDlmPx3EjDZ9vO23yaN/a+Tjx0jqdIrW4c0JgxpbqAyl3g/6SYC7EweL86fzaukXuRWwH35\nenYhOf4gCIJmsCbpGbQ98DjpBz8s+NzclwUjJhdk7rvlU895jvnPWEjRxs91kt8jBvW0gEz1FgGN\nbBlg0lzfK7aH1rF5s1utWvi8t/PfjsLryvtBknYE/gvYzvZbkm4n9QoB3nX+SQHMpfPPTsAltkeV\naeSQIUMuX3XVVZk9ezY77LADX/3qV9l///3LnBoEQVDkbFI0pEmjVl+qa9nRsWhalBgDHC3pCtKI\n3Ku2n5d0M/A/hYCR3YBSz83OaMSx/Q34kqRLgJVIPaNvAhsBW0taD3ga+AxwQSflLAZ8ihQZ9Vng\nTtuvSZomaX/bV0kSsLnth7po0xRgsKT1bU8FDib1JLvL8sDs7NQ2ArYtcc6twJeBn+QglWVz3h8l\nnWN7Zo78eZ/tp2texJQpB5LmAYMgCBphOrBp4f3BZU+0m+fYJF1O6jWuImkGKdJxiVSPzyctOxhB\nipF4CzgsH5sl6XTgvlzUabZ7HCFe1rGZFCCxHSlAwqT5q39mB3AfcC6wPilE+tpOynqT5Ai/A8wk\nOUKAg4Dzcv4SJMfXqWOz/W9Jh5GGMAfldvRkQepNwJGSHiU5zXElzjkWuEDS4aSe3Jdt352vY6yk\nxYB3SRFfNR1bEATBIqeJPTbbB3Zx3KRnYK1jF5EC/5qG5o+u1TGQVgYesP2BplQovWF72WaUNcCI\nHV+DICiLelrAO88+VPqZs+Q6W/S4vkVJp8EjktYE7iapMQxIOlsxL+kbkixplfz+oLxqfpKkuyRt\nUafM9STdk1fZXylpyd6+jiAIgobomFs+tRidOrYcUrqh7Z81WnB+sE+oSpv1w97axdRYEChpHdJE\n5jOF7GnAx2xvRlogWW8u8SzgHNvrA7OBw5vZ4CAIgh4zd0751GI0KypyIWxv01tlNxPbd0gaXOPQ\nOcC3gD8WbIvSYuOoIZCbA192JgXGQFqCcCqda74FQRAsUpoZPNLf6DXH1spIGgk8Z/uh5Kdqcji1\nRVlXJi1dqPzMaVTSKQiCoPdZtOH+i5RQ969C0nuBb5NUUerZ7ERybCf0sK4jJI2XNP6CCzpbIREE\nQdBk3FE+tRjRY1uYD5FEZCu9tbWBByRtnZc3bA6MBva0/XKN818mCXwOyr22uivpbV/A/Hm6iIoM\ngmDR0YJBIWUJx1aF7UnAapX3kqYDw2y/JGldknDywQUZr+rzLek25i9CP5TCPF0QBEG/oAWDQsrS\n9kORecX83cAQSTPyQut6nEyaQ/tFjvIcXyjnxrw8AtIQ5XGSpmb7C3up+UEQBN1jAA9FdrlAO1hk\nxI0IgqAsPV4w/fbEm0s/c5bafPeWWqAdQ5FBEARtSO0NUwYGMRQpLS3pXkkPSZos6bs5/+isHDJP\neSTnbyTpbklvSzq+k3JDfSQIgv7LAB6KbHvHRtq+ZmfbW5C2e9hD0rbA30lb2FQLF88ibVvflcxY\nqI8EQdB/6egon1qMtndseTfaN/LbJXKy7QdtT69hP9P2fSTF/poU1EeuzlmXAPs0teFBEAQ9YdFu\nNLpIaXvHBiBp8bzT9UzgFtv39LDIUB8JgqB/E0ORAxvbc/Pu3WuT9orbtKtzmkEojwRB0GcM4KHI\niIosYPuVvLh6D2ChbWwaoJT6SCiPBEHQZ7RgT6wsbd9jk7SqpBXy6/cAuwKP9aTMvFtsRX0EQn0k\nCIL+xgDusbW9YwPWAG6TNBG4jzTHdr2kYyTNIPW2JkoaDSDp/Tn/OOA7Wa1kuXws1EeCIGgNBrBj\nC+WR/kPciCAIytJjJZB/3X5R6WfOe3b8QiiPBEEQBP2cmGMb2EiaLmlSUdhY0g8kPSZpoqRrC/Nw\nu0q6P9vfL2nnOmWuJOkWSU/kvysuymsKgiDolAE8FBmObT472R5qe1h+fwuwqe3NgceBUTn/JeAT\ntjcjBYX8X53yTgRutb0BcGt+HwRB0D+IdWzth+2xhQXW40hBJGRFkn/k/MnAeyQtVaOIkSTFEQjl\nkSAI+hsDuMcWc2wJA2MlGfhlXl9W5AvAlTXO+yTwgO23axxb3fbz+fU/gdWb1togCIKeEhuNDni2\nt70lsCdwlKQdKgcknQTMAS4rniBpE5LQ8Ze6Kjyva1soAimUR4Ig6DOixzawsf1c/jtT0rXA1sAd\nkj4P7AXs4sK6CElrA9cCh9h+sk6xL0haw/bzktYg6VBW1xvKI0EQ9A0tOHdWlrbvsUlaRtL7Kq+B\n3YCHJe0BfAvY2/ZbBfsVgBuAE23/vZOix5CCSyCUR4Ig6G8M4B5b2zs20tzXnZIeAu4FbrB9E3Au\n8D7glrwM4PxsfzSwPnByzp8gaTUASaMlVaIqzwR2lfQEaV+3MxfhNQVBEHROE6MiJe0haUreWHmh\nCHBJ5xSel49LeqVwbG7h2JhmXFooj/Qf4kYEQVCWniuPXHtmeeWRfU+sW5+kxUlLonYlbdF1H3Cg\n7Ufq2H8V+IjtL+T3b9hetpG2d0X02IIgCNqRuXPKp87ZGphq+ynb7wBXkJY71eNA4PImXUVN2sax\nSbpI0kxJDxfy9pc0WVJHYQixU3URSVvl/KmSfpp3y66uS/nY1KxcsmXvX2EQBEEDNG+ObS3g2cL7\nuhsrS/oAsB7wl0L20jk6fJykpqz3bRvHBlxM2metyMPAfsAdVfmdqYucB/w/YIOcqsuEtGygcvyI\nfE4QBEH/wS6dikuTcjqim7UeAFxte24h7wNZ8emzwE8kfainl9Y24f6275A0uCrvUYDqTpftBwtv\ni+oiKwHL2R6Xz7uUpCjyp6rqRgKX5iUC4yStUAn9b94VBUEQ9IAGoh2rliZV8xywTuF9zY2VMwcA\nR1WVXVlu9ZSk24GPAPWWUZWinXps3aWoLrIWqZtdoV6Xu3TXPAiCoE9o3lDkfcAGktaTtCTJeS0U\n3ShpI2BF4O5C3ooVSUJJqwD/CdQMOmmEcGyd0Ii6SDfLD+WRIAj6hiaF+2dN3aOBm4FHgd/Znizp\nNEl7F0wPAK7wgqH4HwbG5+VWtwFn1oumbIS2GYpslDrqIs+RxZAz9brcpbrmoTwSBEGfMXdu1zYl\nsX0jcGNV3slV70+tcd5dwGZNa0gmemw1qKcukufIXpO0bY6GPITaiiJjgENydOS2wKsxvxYEQb8i\nlEdaH0mXk8Z2h0iaIelwSftKmgFsB9wg6eZsXlddBPgKMBqYSprg/FMu/0hJR2abG4Gnss2v8jlB\nEAT9hwHs2EJ5pP8QNyIIgrL0XHlk9HHllUe++OMe17coiTm2IAiCNsQdA/e3dDsNRdZSHjk9K4NM\nkDRW0ppV5wyXNEfSpwp562bbRyU9Ur02LtssJenKrDxyTy2bIAiCPqV5klr9jrZxbNRWHvmB7c1t\nDwWuB+ZF8WRhz7OAsVXnXJrP+zBJI22hfdaAw4HZttcHzsnlBEEQ9B86XD61GG3j2GzfAcyqynut\n8HYZFpzn+irwewqOS9LGwCDbt+Tz3yju1VZgJHBJfn01sEstTckgCII+YwAHj7T9HJukM0hh+68C\nO+W8tYB98/vhBfMNgVckXUMS8vwzaUlA9YKQecojtudIehVYmaRBGQRB0Pe0oMMqS9v02Oph+yTb\n6wCXkcL8AX4CnGAvtOR+EPBR4HiSw/sg8Pnu1h3KI0EQ9BkNiCC3Gm3fYytwGWn92SnAMOCKPHq4\nCjBC0hyS5uME208BSPoDsC1wYVVZFeWRGZIGAcsDL1dXGMojQRD0GQO4x9bWjk3SBrafyG9HAo8B\n2F6vYHMxcL3tP+SAkhUkrWr7RWBnYHyNoseQtru5G/gU8BfHgsEgCPoTTZTU6m+0jWPLyiM7Aqtk\ntZFTSD2xIUAH8DRwZP0SwPZcSccDt+ZgkPtJyiJIOg0Yb3sMqQf3f5KmkgJWDuidqwqCIOgmLRjt\nWJZQHuk/xI0IgqAsPY6yfvP7h5Z+5iwz6pKWiupumx5bEARBUGAA99jaIipS0jqSbstKIZMlHZvz\n98/vOyQNq3HeupLeyMOPlbzpkiZltZJa82tkVf+fZuWRiZK27L2rC4Ig6AZN2o+tP9IuPbY5wDds\nPyDpfcD9km4BHgb2A35Z57wfk9X7q9jJdmdr0vYENshpG+C8/DcIgqB/MCeCR1qavBfa8/n165Ie\nBdaqKIjUEgWRtA8wDXizG1WOBC7NkZDjJK0gaY3Yky0Ign5DDEUOHLIg8UeAezqxWRY4AfhujcMG\nxkq6X9IRdYqYpzySmZHzgiAI+gcDeCiyrRxbdli/B75WpRNZzanAObbfqHFse9tbkoYbj5K0Qw/a\nE8ojQRD0DQNYBLkthiIBJC1BcmqX2b6mC/NtgE9JOhtYAeiQ9G/b59p+DsD2TEnXkhT+76g6v6I8\nUmHtnLcAoTwSBEFf4VAeaW3yYuoLgUdt/7gre9sfLZx7KvCG7XMlLQMslufplgF2A06rUcQY4GhJ\nV5Cc5KsxvxYEQb+iBXtiZWkLxwb8J3AwMEnShJz3bWAp4GfAqsANkibY3r2TclYHrs3BJoOA39q+\nCUDSkQC2zydpTo4ApgJvAYc1/YqCIAh6wgCW1Arlkf5D3IggCMrSYyWQN47bu/QzZ9kfjwnlkSAI\ngqB/4wE8FNkWUZGdKI/8QNJjWR3kWkkrFM7ZXNLd2X6SpKVz/k2SHsr552fF/+r6QnkkCIL+zQCO\nimwLx8Z85ZGNSfunHSVpY+AWYFPbmwOPA6MA8h5qvwGOtL0JaVeAd3NZn7a9BbApaW5u/xr1FZVH\njiApjwRBEPQfOjrKpxajLRyb7edtP5Bfvw5UlEfG2p6TzcaRwvIhRTtOtP1QPudl23Pz68r6t0HA\nktSeG5unPGJ7HGkPtzV649qCIAi6RfTYBg6dKI98gfm6kBsClnSzpAckfauqjJuBmcDrwNU1qllA\neUTSjCeffPIcUpTkRCCGJvuAUaNGsd1227HXXnv1dVOCoFmMIWneVjiVtGZ2Qk4j6p3ouR2lU6vR\nVo6tnvKIpJNIw5WX5axBwPbAQfnvvpJ2qdjnJQFrkJYL7NxVvQceeODKyy233DpUDU2G8siiZb/9\n9mP06NF93YwgaBb7AbXUkc4BhuZ0Y92zo8fW+tRTHpH0eWAv4CDPX/swA7jD9ku23yJ9ORboZdn+\nN/BH0rBjNQsoj+yxxx6DX3rppd+Qhi3HkdRM1rB9ge1htocdcUQ92cmgWQwfPpzll1++r5sRBM1g\nWeA44HvdLqGJjk3SHpKm5IC5E2sc/7ykF/N2XxMkfbFw7FBJT+R0aLevp0BbOLZ6yiOS9gC+Beyd\nHViFm4HNJL03B5J8DHhE0rKVubKc/3HgsRpVjgEOydGR266zzjreaKONJhWOLySKvNs6e/T8QoMu\nmTP7WTznnb5uRo/58oij2GXt3fq6GU1ll7V3G3DX1BsMWnItgNOBH5EEIKo5mjTlcRGwYr1y3OHS\nqTNyZPjPSUFzGwMH5uC8aq60PTSn0fnclYBTSApNWwOnSKrb5rK0hWNjvvLIzoVfDCOAc4H3Abfk\nvPMBbM8m7cV2H2mc+gHbNwDLAGMkTcz5M4HzISmPVNRHSD28p0hzar/aZJNNimPgQRAE3WaLLTYB\n+BBwbY3D5+VjQ0lbdf2obkHN67FtDUy1/ZTtd4ArqD2SVYvdgVtsz8rP3VuAHv/Kb4sF2rbvpPZK\n/brjz7Z/Qwr5L+a9AAyvY39+4bWBR0gOFVKvrlNR5LHP3lT/AoKmMWjFddCgJfu6GT3mvBt/3tdN\naDq3zhjb101oCe6/byzAMGA66Rm+GnA7aVnSCwXTXwHX1yvHc8rPneUtuorzJRdkEXeovU1XrY2V\nP5l3Q3kc+LrtZ+uc2+Mtvtqlx9YX/Jz5E7h/AA4hOddtgVfJG58GQRB0gzWBwaTgtsdJTg1SUFuF\nfVkwYnJBGuixFeMBcmo02u06YHBeM3wLcEmD5zdEWzi2esojhePfkGRJq+T3I7NiyIQctbh9wfYm\nSa9IqvtLSNJSkq7ME6n3LL300pMpDE0CXymYT6hZSNB0jjvuOA444ACmTZvGDjvswFVXXdXXTQqC\nZnM2MIk0x7YT8PW6lh0NpM7pcpuuvBb47fx2NLBV2XO7Q1uIIOeAjzVsPyDpfcD9wD62H5G0DumD\n3gjYyvZLeVnAm7YtaXPgd7Y3ymXtArwX+JLtmguiJH0F2Nz2kZIOAPa1/Zkumjnwb0QQBM2ix6LE\ns/ffsfQzZ8Wrbq9bXw6kexzYheSU7gM+a3tywWaNytZdkvYFTrC9bQ4euZ/5UecPkJ7Dsxq9niJt\n0WOrpzySD59Diox0wf6NQuj/MlXHbiUtzO6Mkczval8N7JIjM4MgCPoHTeqxZfWmo0nR5I+SOgKT\nJZ0mae9sdkweLXsIOAb4fD53FinC876cTuupU4M2CR4pUlQekTQSeM72Q9V+J/+q+D5pYvbjDVYz\nb0LU9hxJrwIrAy/1qPFBEARNopnq/rZvpCoYz/bJhdejyFq8Nc69iLQ0oWm0RY+tQlF5hKQ08m3g\n5Fq2tq/Nw4/7kH5R9EZ7QnkkCII+wXPKp1ajbXps1cojkjYD1gMqvbW1gQckbW37n5XzbN8h6YOS\nVrFdtsdVmRCdkceflwderjbKkUUVjxZzbEEQLDpaTwKyNG3h2Gopj9ieRBpmrNhMB4bl4JH1gSdz\n8MiWJE3IhRxTJ4wBDgXuBj4F/KUwZxcEQdDnOBxby1NRHpkkqRJe/+08LlyLT5Iksd4F/gV8puKY\nJP2NFEG5rKQZwOG2b5Z0GjDe9hiSE/0/SVOBWcABvXZlQRAE3WEAO7a2CPdvEeJGBEFQlh5HWb+4\n68dKP3NWveWvLRXV3S49tiAIgqDAQB6KbIuoyM6URyR9VdJjOf/snLd1QSz5oRz6XyxvcUkP1lMf\nqVYeyUsMgiAI+g2eq9Kp1WiXHtsc4BtF5RFJtwCrkxZTb2H7bUmVYJKHSYEkc7JqyUOSrssLEQGO\nJS1EXK5OfYcDs22vn5VHzgK6Uh4JgiBYZESPrcXpRHnky8CZFQ0z2zPz37cKTmxpCvNfktYmLdju\nbCvmUB4JgqBf4w6VTq1GWzi2IkXlEWBD4KN5uPCvkoYX7LaRNJkkKHpkwdH9hCTB1dnvnQWUR0hq\n/is3+VKCIAi6jTvKp1ajrRxbUXnE9mukodiVSFvJfBP4XaVnZfse25uQ9l8bJWlpSXsBM23f36T2\nhPJIEAR9gq3SqdVolzm2hZRHcvYM4Jq8Ru1eSR3AKsCLlfNsPyrpDWBT0nq4vfPu20sDy0n6je3P\nVVUXyiNBEPRrOua0nsMqS1v02Gopj2T+QNqzCEkbAksCL0laLzskJH2AtCB7uu1Rtte2PZi06Pov\nNZwazFcegVAeCYKgH2KXT61Gu/TYaiqPkBSlL5L0MPAOcGiW0doeODErj3QAX+lKJzKUR4IgaCVa\nMSikLKE80n+IGxEEQVl67JWmD9219DNn8IRbWsoLtkuPLQiCICgwkPs07TLHtrSke7OKyGRJ3835\nR2d1EEtapWB/kKSJkiZJukvSFjm/roJJVX2S9NNc9sS8Q0AQBEG/YSCvY2uXHtvbwM6238jRkXdK\n+hPwd+B64PYq+2nAx2zPlrQnKXJxG+oomNh+pOr8PYENctoGOC//DYIg6Bd0tKBUVlnawrHliMQ3\n8tslcrLtBwGqRUFs31V4O460CSm2nweez69fl1RRMKl2bCOBS3O94yStIGmNfH4QBEGf09GC69PK\n0hZDkTBPuHgCMBO4xfY9JU89HPhTjfIGM1/BpJp5yiOZGTkvCIKgXzCQF2i3jWOzPdf2UFLva2tJ\nm3Z1jqSdSI7thKr8agWTbhHKI0EQ9BUxxzaAsP2KpNuAPUgq/jWRtDlJ6HhP2y8X8mspmFRTUR6p\nsHbOq25LKI8EQdAnRFRkiyNpVUkr5NfvAXYFHuvEfl3gGuBg248X8uspmFQzBjgkR0duC7wa82tB\nEPQnosfW+qwBXCJpcZIz/53t6yUdQ1Lqfz8wUdKNtr8InExS4/9FDiyZY3sYdRRMbN8o6UgA2+cD\nNwIjgKnAW8Bhi+pCgyAIyjC3Y+D2a0J5pP8QNyIIgrL0uBs1cfAnSj9zNp9+XUt129qlxxYEQRAU\nGMjh/uHYgiAI2pBWDOMvy8AdZC3QiaTWZZKmSHpY0kU54rGupFY+dpGkmXlHgHr1haRWEAT9moG8\nbU1bODbmS2ptAQwF9sjRipeR9lrbDHgP8MVsX5HU2gw4nfkh+QAXk5YKdEZRUusIkqRWEARBv2Fu\nx2KlU1dI2iN3EqZKOrHG8eOyxu5ESbfmfS4rx+ZKmpDTmGZcW1s4NidqSWrdmI8ZuJf50ll32Z6d\n7edJauVjd5D2WOuMeZJatsfts88+a7777rtTSVGSC930IGiEUaNGsd1227HXXnv1dVOCvmcMC67H\nPZW0ZnZCTiPqndhhlU6dkaPNf076Qb8xcKCkjavMHgSG2d4cuBo4u3DsX7aH5rR3qavugrZwbNC5\npFYegjwYuKnGqTUltbqgKKm1+LnnnrvyN77xjW+Qb3r+u4DyyK9//esGqwjalf3224/Ro0f3dTOC\nvmc/5mvgFjmHNDI1lLT0qCZuIHXB1sBU20/Zfge4gvTjfn5d9m2238pvF+gs9AZt49i6kNT6BXCH\n7b8Vz6knqdUgWz/zzDP/+tnPfvYcaZfueTfd9gW2h9kedthhsdQtKMfw4cNZfvnl+7oZQd+yLHAc\n8L3uFtCsHhuNa+NWdxaWzj/wx0nap3tXsyBt49gq2H4FqEhqIekUYFXSl2QeBUmtkUVJrZIUJbXW\nmjZt2uLMl9SqddMjuCQIgkY4HfgRSQCimqOBicBFwIr1CmhEBLk4upTTEd1ptKTPAcOAHxSyP5AF\nMD4L/ETSh7pTdpG2cGz1JLUkfRHYHTjQdkfBvqakVgPMk9T64x//uMGgQYPe6URSazHgx7MP+0w3\nqgka5csjjmKXtXfr62b0mDmzn8Vz3unrZjSVXdbebUDcm95mq+G7AXwIuLbG4fPysaGkLbZ+VK+c\njgZScXQpp2JAXSltXEn/BZwE7G377Uq+7efy36dIe2N+pP7Vl6Nd1rHVk9SaAzwN3J2ls66xfRr1\nJbWQdDmwI7CKpBnAKbYvrCep9b//+79cddVVTxbaUn3T3wdsuuKvr+ylSw+KnHfjz/u6CU1h0Irr\noEFL9nUzmsqtM8b2dRNagvvvGwup1zOd9AxfjeQQdgReKJj+irSRck3mNm8d233ABpLWIz3bDiD1\nvuYh6SPAL4E9bM8s5K8IvGXNWaVbAAAgAElEQVT7bUmrkGQLi4El3aItHJvtidT4FWC75vVnvcgv\n1jl2YJ388wuvDRyV3w4CHgfq3fRXgVUISa0gCMqzZv47mOS8dszv1yBvhgzsSyc7mHT0XJULANtz\nJB0N3AwsDlxke7Kk04DxtseQhh6XBa7KnYVncgTkh4FfSuogdTrOtF29cXPDtIVj62PmkMa85910\nYDJwGjCeNGwZBKU57rjjuPfee5k9ezY77LADX/3qV9l///37ullB/+Bs0jCkST26L9UzdJMcG4Dt\nG6mKwLR9cuH1f9U57y7SOuKm0hYiyJKWBu4AliI586ttnyLpQlKXXqRe1ecL692Q9EnSmovhtsdL\nWrnyHrjY9tF16lsJuJL0a2o68OnCurh6DPwbEQRBs+ixV7pl9c+Ufubs+sKVLaW/1RbBI9RXHvm6\n7S3yosFnSD0rACS9DzgWuKdQzr+B/waO76K+E4FbbW8A3Eosyg6CoJ9hVDq1Gm3h2DpRHnkN5m0g\n+h4W7DWdDpxFcmaVct60fWcxrw4jgUvy60uApqzNCIIgaBZzGkitRls4NqivPCLp18A/SZqRP8t5\nWwLr2L6hm9WtXgjv/yewep02zVsbcsEFF9QyCYIg6BUGco+tbYJHbM8Fhub1bNdK2tT2w7YPy8sA\nfgZ8RtIlwI+BzzepXkuqOZad14JUPFrMsQVBsMjoaD1/VZq26bFVqFYeyXlzSVJXnySvKwNulzQd\n2BYYI2lYA9W8IGkNgPx3Zhf2QRAEi5QOVDq1Gm3h2Oooj0yRtH7OE7A38JjtV22vYnuw7cEkwc69\nbY9voMoxwKH59aHAH5t0KUEQBE2hiSLI/Y52GYpcSHkEuAH4m6TlSKGzDwFf7qqg3ItbDlgyC3bu\nZvsRSaOB87MDPBP4naTDScomn+6FawqCIOg2HV2btCxtsY6tRYgbEQRBWXo8PnjVGgeVfubs//xl\nLTUe2S49tiAIgqDAQO6xtcsc29KS7pX0kKTJkr6b8y+WNK2wLfnQnL+RpLslvS3p+KqyLpI0U1Jd\nDTYlfpq3SZ+Ylw8EQRD0GzpUPrUa7dJjqyiPvJF3y75TUmWju2/avrrKfhZwDLUXVl8MnAtc2kl9\newIb5LQNaSuJbbrf/CAIgubSitGOZWmLHls95ZFO7Gfavg94t8axO0iOrzNGApfmescBK1TC/4Mg\nCPoDAzkqsi0cG9RXHgHOyMOF50haqknVldoqPZRHgiDoK2IocgBQS3kEGEWSvFqSpAByAmk7mUXV\nplAeCYKgT5jb1w3oRdqmx1ahqDxi+/k8XPg28Gtg6yZVU2qr9CAIgr5iIPfY2sKx1VEeeawgeyVS\noEjdSMcGGQMckqMjtwVeLYgiB0EQ9DkdDaRWo12GIhdSHrF9vaS/SFqVtNhxAnAkgKT3k3a3Xg7o\nkPQ1YGPbr0m6nLQN+yqSZgCn2L5Q0pEAts8n7SQ7ApgKvAUctgivNQiCoEta0WGVJZRH+g9xI4Ig\nKEuPBwjPX+dzpZ85Rz77m5YakGyXHlsQBEFQoBU3EC1LW8yxVcgh/w9Kuj6/v0zSFEkPZ0WRJXL+\nQXkJwCRJd0naIucPKaiUTJD0Wh6mrK4nlEeCIOjXxDq2gcOxwKOF95eRds7eDHgP8MWcPw34mO3N\ngNPJIfm2p9geansosBVp/uzaGvUUlUeOICmPBEEQ9BsiKnIAIGlt4OPA6Eqe7RtzuL+Be0lh+di+\ny/bsbDaukl/FLsCTtp+ucSyUR4Ig6NcM5KjItnFswE+Ab1HjPuUhyIOBm2qcdzjwpxr5BwCX16kr\nlEeCIOjXDGTH1hbBI5L2Ambavl/SjjVMfgHcYftvVeftRHJs21flL0nacXtUT9oVyiNBEPQVA/mB\n0xaODfhPYG9JI4ClgeUk/cb25ySdAqwKfKl4gqTNScOWe9p+uaq8PYEHbL9Qp75QHgmCoF8zpwXn\nzsrSFkORtkfZXtv2YNIQ4l+yU/sisDtwoO15PW5J6wLXAAfbfrxGkQdSfxgSQnkkCIJ+zkCOimyX\nHls9zgeeBu5OqlpcY/s04GRgZeAXOX+O7WEAkpYhSXJV9/BCeSQIgpahoyVdVjlCeaT/EDciCIKy\n9Hgg8fQPHFT6mfPfT1/WUgOXbTEUGQRBECxIM4ciJe2RxS6mSjqxxvGlJF2Zj98jaXDh2KicP0XS\n7j2+MNrIsUmanpVEJkgan/P2lzRZUoekYQXbwZL+VVAYOb9w7AxJz0p6o1Y9Bbum36wgCIJm0axw\n/ywu/3NSUN3GwIGSNq4yOxyYbXt94BzgrHzuxqS4h02APUjTP4v39NrabY5tJ9svFd4/DOwH/LKG\n7ZNZYaSa64BzgSfqVVJ1s9YE/ixpw7zZaRAEQZ8zR02b/dgamGr7KQBJV5BEKh4p2IwETs2vrwbO\nzduFjQSuyHtiTpM0NZd3d08a1DY9tlrYftT2lAbPGVciwnHezbI9jRRE0qxNTIMgCHpMI0ORRTGJ\nnI4oFFVGkGKeje05wKukAL1SYhaN0k6OzcBYSfdX3ZR6rJcFk/8q6aMN1hXKI0EQ9GsaGYq0fYHt\nYYXUrx9Y7TQUub3t5yStBtwi6THbd9SxfR5Y1/bLkrYC/iBpE9uvNbNBoTwSBEFf0cRw/zKCFBWb\nGZIGAcsDL5c8t2Hapsdm+7n8dyZJkb/u0GAeQnw5v74feBLYsIHqFrhZBx544BZvvvnmj0hDkgtF\nDJF37g6CdmXUqFFst9127LXXXn3dlFZjDClWoMKppOfPhJxG1DuxiVGR9wEbSFovyw0ekNtV3c5D\n8+tPkUQynPMPyFGT65F2RLm36yo7py0cm6RlJL2v8hrYjQW/DNX2q1YicyR9kPRhP9VAlfNu1mqr\nrfah73//+1v861//2oUcMZT/FvltA2UHwYBjv/32Y/To0V0bBkX2A2pFZ58DDM3pxnonz8GlU2fk\nObOjgZtJ24L9zvZkSadJ2jubXQisnINDjiP/wLc9GfgdKdDkJuCoZgTZtctQ5OrAtVlFZBDwW9s3\nSdoX+BlJK/IGSRNs7w7sAJwm6V3SEPORtmcBSDob+CzwXkkzgNG2T803cJjtk/NN/R3wyCabbDJo\niSWWmLjyyitPzW2pFTHU1CHOIGg1hg8fzowZM/q6Ga3EsiQHcQTJMTRMM+c+bN9IlRO1fXLh9b+B\n/eucewZwRhOb0x6OLYehblEj/1pqbBRq+/fA7+uU9S3S9jfV+WModL8LN+tTpPUZFWYA21Sf/8Lp\nP2f1/z6qq0sJesiXRxzF4xOf4NYZY/u6KT1ioFxHkTmzn+3aKGDQkmsx553nTgd+RJLsq+Zo4BBg\nPPANYHYNm5bcjqYsbTEU2Qq8+tvr+roJQdDneM47fd2Efs8WW2wC8CFq/CgHzsvHhpKC4H5Urxw3\n8K/VaBvHVkd55HRJE3PeWElr5vyNJN0t6W1JxxfKWEfSbZIeyYolx9apS5J+KmnqzjvvfOasWbOK\nc2o1o342fLTWHqdBsznvxp8PiF7OQLmOIoNWXAcNWrKvm9Hvuf++sQDDgOnAnaTAttvz4ReAuaQO\n2a/oJEhuIG802jaOLbOT7aEVpX7gB7Y3zwoj15NU/QFmAccAP6w6fw7wDdsbA9sCR9WQjoEkLbMB\nsMGECRMOfeutt7YE1gPqRQxt0NMLC4KgrVgTGEzaBPlxYMecv0bBZl86CZLrwKVTq9Fujm0Bqtal\nLUOeT7U90/Z9wLtV9s/bfiC/fp0UAVRrlfxI4FLbnjVr1t+PPfbYl959990/Z/vfAZOB00i7cEMa\nEw+CtuW4447jgAMOYNq0aeywww5cddVVfd2kVuVsYBIwEdgJ+Ho9w7m4dGo12iJ4JFNRHjHwy8rK\neUlnkCZaXyV9EUqR1ak/AtxT4/ACyiPXXHPNlCWXXPIE2+MLNidnBZTxAL/85S854ogygihBMPD4\n8Y9/3NdNaFWmA5sW3h9c9sRWHGIsSzs5tprKI7ZPAk6SNIrUczqlq4IkLUuKmvxaT9RIQnkkCIK+\nohWDQsrSNkORJZRHLgM+2VU5kpYgObXLbF9Tx6xXZGKCIAiaRQSPtDj1lEckFYM2RgKPdVGOSCvo\nH7Xd2djJGOCQHB25LfBqiR0BgiAIFhkDOdy/XYYi6ymP/F7SENKPkqfJmo2S3k+a+1oO6JD0NZIM\n1uakMexJkibksr9t+0ZJRwLYPp+0An8ESRvyLeCwRXOZQRAE5WjFnlhZlHQog35A3IggCMqinhbw\nuQ/sV/qZ85unr+lxfYuSdumxBUEQBAVacX1aWdpljm1IVheppNckfU3S/llBpEPSsIL9yllh5A1J\n51aV9ZmsVjJZ0lmd1DlK0lRJUyTt3pvXFwRB0Cgxx9bi2J5C0k4jb0fzHCky8r2krR9+WXXKv4H/\nJq0PmbdGRNLKwA+ArWy/KOkSSbvYvrV4clYjOQDYhKQQ8GdJGzZjO4YgCIJmMJDn2Nqix1bFLsCT\ntp+2/Wh2egtg+03bd5IcXJEPAk/YfjG//zO1lwiMBK7IG5ZOIwWR1NVsC4IgWNSEpNbA4gDg8m6e\nOxUYImlw3t58HxZcr1ZhAeUR0lY1C0lvSTpC0nhJ4y+44ILqw0EQBL1GSGoNEPK25XsDo7pzvu3Z\nkr4MXEnqyd9F2iKiW4TySBAEfcVAjohvK8dGUt1/wPYL3S3A9nXAdZB6XKQtIqoJ5ZEgCPo1rTjE\nWJZ2G4o8kO4PQwKQtSaRtCLwFWB0DbMxwAGSlpK0Hmlbmnt7Um8QBEEzGciSWm3TY8tSWrsCXyrk\n7Qv8DFgVuEHSBNu752PTScojS0raB9jN9iPA/0raIhdxmu3Hs/3ewDDbJ9ueLOl3wCOkPdyOiojI\nIAj6E60Yxl+WUB7pP8SNCIKgLD1WAhmx7ojSz5wbn7kxlEeCIAiC/s3cAdypaYs5tk6UR07PKiIT\nJI2VtGa230jS3ZLelnR8VVkXSZopqe6W61nV/6dZeWSipC17+xqDIAgaYSArj7SFY7M9xfZQ20OB\nrUiK+9cCP7C9ec6/Hjg5nzILOAb4YY3iLgb26KLKPUkBIxsARwDn9fgigiAImkgs0B5YFJVHirtf\nL0Oe57I90/Z9wLvVJ9u+g+T4OmMkcKkT44AVJK3RnOYHQRD0HNulU6vRjo5tAeURSWdIehY4iPk9\ntp4SyiNBEPRrBnKPra2CR2opj9g+CThJ0ijgaOCURdWeUB4JgqCvmOtWXKFWjnbrsXWmPHIZtQWN\nu0MojwRB0K9xA6nVaDfHtoDyiKQNCsdGAo81qZ4xwCE5OnJb4FXbzzep7CAIgh6zqIYiJa0k6RZJ\nT+S/K9awGZoj0SfnSPLPFI5dLGlaIap9aJd1tuLEYHfIyiPPAB+0/WrO+z0whKQa8zRwpO3nJL0f\nGE9SHukA3gA2tv2apMuBHYFVgBeAU2xfKOlIANvnSxJwLil68i3gMNvju2hie9yIIAiaQY8XTG+3\n1k6lnzl3P3dbt+uTdDYwy/aZkk4EVrR9QpXNhoBtP5GXXd0PfNj2K5IuBq63fXXpOtvFsbUAcSOC\nIChLjx3btmvuWPqZM+4ft/fEsU0BdrT9fI4Ov932kC7OeQj4VHZ0F9OgY2u3ocggCIKARRoVuXph\nKuafwOqdGUvaGlgSeLKQfUYeojxH0lJdVdgWjq0T5ZFTJT1XyB+R7XeVdL+kSfnvzoWybpL0UB4L\nPl/S4jXqC+WRIAj6NR3uKJ2KS5NyOqJYlqQ/S3q4RhpZtHMaIqzrKXOP7v9I0zeVsM1RwEbAcGAl\n4IQ6p88vp92GIrMjeg7YBjgMeMP2D6tsPgK8YPsfkjYFbra9Vj62XJ5rE3A1cJXtK6rOHwF8FRiR\n6/lf29t00bT2uhFBEPSEHg9FbrnG9qWfOQ88f2evD0VKWg64HfifesOOknYEjre9V2d1tkWPrYp5\nyiP1DGw/aPsf+e1k4D2V7m9BrWQQqbtc68sRyiNBEPRrFqHyyBjg0Pz6UOCP1QZ5jfG1pOfm1VXH\n1sh/BewD1NXprdCOjm0B5RHg6DxceFGtMFTS2rYHbL9dyZB0MzATeJ3Ua6smlEeCIOjXLMI5tjOB\nXSU9AfxXfo+kYZIqGzV/GtgB+HyNsP7LJE0CJpGi0b/XVYVtNRSZfxX8A9jE9guSVgdeIvW6TgfW\nsP2Fgv0mpF8bu9l+sqqspUmLus+3fUvVseuBM23fmd/fCpzQRch/+9yIIAh6So+HIjd//3alnzkT\n/3l3S+3H1m49tgWUR2y/YHtunqT8FbB1xVDS2qSu8SHVTi2f+29Sl3pk9TFCeSQIgn5Oh106tRrt\n5tiqlUeK8177ksduJa0A3ACcaPvvBftlC+O9g4CPU1utJJRHgiDo18x1R+nUarSNCHJWHtkV+FIh\n++w8jmtgeuHY0cD6wMmSKor/u5G6/2NyIMliwG3A+bn8ecojwI2kiMipZOWRXruwIAiCbtCKG4iW\npa3m2Po5cSOCIChLj+e8Nlx1WOlnzuMvjm+pOba26bEFQRAE8xnIPba2mWOT9PWsFvKwpMslLS3p\n6KwOYkmrFGy/WQg5fVjSXEkr5WMXSZopqe5ailAeCYKgvxPBIy2OpLWAY4BhtjcFFietZ/s7aV3F\nAou1bf/A9lDbQ0lyLn+1PSsfvpik2t8ZewIb5HQEcF6TLiUIgqApdHhu6dRqtNNQ5CCSgsi7wHuB\nf9h+ECAtaK/LApGUtu+QNLiLuuYpjwDjJK0gaY2IjAyCoL/QhIXX/Za26LHZfg74IWk/tudJ4fdj\nuzpP0ntJvbPfN1hlKI8EQdCvWYSSWouctuixZamskcB6wCvAVZI+Z/s3XZz6CeDvhWHIpmL7AqDi\n0Vrv2xMEQcsSPbbW57+AabZftP0ucA3wHyXOq9aVLEsojwRB0K8ZyD22dnFszwDbSnpvVojeBXi0\nsxMkLQ98jBpK1CUI5ZEgCPo1ERXZ4ti+h6TC/wBJIXox4AJJx0iaQepRTSwoTUOS2Bpr+81iWZIu\nB+4GhkiaIenwnH9kRX2EpDzyFEl55FfAV3rv6oIgCBqnkY1GW41QHuk/xI0IgqAsPVYCWXX5IaWf\nOS++OiWUR4IgCIL+zUDu1LTFUCSApGOzishkSV/LeadnZZAJksZKWjPnH5TzJ0m6S9IWhXJCeSQI\ngpYn5thaHEmbAv+PtN/aFsBektYHfmB786wwcj1QUfKfBnzM9makDUiLi8wuJpRHgiBocSIqsvX5\nMHCP7bdszwH+Cuxn+7WCzTLkeS7bd9menfPHkYJLyMfuALpa1zZPecT2OGCFqr3fgiAI+pQOXDq1\nGu3i2B4GPipp5awmMoK8zkzSGZKeBQ5ifo+tyOHAnxqsL5RHgiDo18zt6CidWo22CB6x/aiks4Cx\nwJvABGBuPnYScJKkUaQNRk+pnCdpJ5Jj276X2hXKI0EQ9Amxbc0AwPaFtreyvQMwG3i8yuQy4JOV\nN5I2B0YDI22/3GB1CyiPSFr75ZdfPpK0rm0iEMEkQRA0zKhRo9huu+0YMmRI3eC1skTwyABA0mr5\n77rAfsBvJW1QMBkJPFawuQY42Ha1AyzDAsoj+++/PyuttNJaRDBJEAQ9YL/99mP06NFdG5ZgIAeP\ntMVQZOb3klYG3gWOsv2KpAslDQE6SHuyVZRDTgZWBn6Rt7SZY3sYzFMe2RFYJauWnGL7worqiO3z\nScojI0g9tLfOPvvsh0nKJyYFo6wArEHaaSAIgqAUw4cPZ8aMGU0payAPRbaNY7P90Rp5n6xj+0Xg\ni3WOHVgn//zCawNHFQ5fT+1gknBsQRD0CR0tGBRSlrYZiuzvbDV8t75uQlswaMm1BsRnPVCuo8hW\nw3fjuuu73Cax7Zkz+9mujUrgBlLL0cg4a6SG0lG2J+T0K9sHFo5Nsb1Glf2X33jjjVdsT7c9w/Y7\ntm+vUe7gF1988bkybQCOKNvesrZ9WWYndgt91gXbmp+17X/Ynv7666/P7uyztv3wIryeut+Zl19+\n+Z+dXUflO/P0009P6eo64nr6/3e9M9sNN9xw8IYbbrjQ9UcqfHZ93YA2SR+3/Sfbsr2t7Xtr3gwY\nn18P9oL/cYsPgK9fd911s0rd3PnlNc22L8ssafdx23+SNL6zz7qSNtxww4mdfda2r+ij61ngOzNx\n4sQ3uyhvsO2HC2XWvY64nv7/Xe/MNhxb1ymGIhcNnW1jM6HE+WeTttuZCOx01FFHNWcsYmByI/DU\n008/vSlN+KyBrze9heVY4Dtz1FFHPV041krXUWGgXU+fMGTIkHnbZg0ZMmTGkCFDDu/rNvVH2iZ4\npI+pDiYpMrRG3nRg08L7g4sHn3nmmfHNadaAxMBR66677jbOkawFFvqsH3/88XeAot3B1TZ9xALf\nmb/97W/Fe97Zd6Zi11+uo8JAu54+YcqUKTWD14IFiR5b/6Ksrlaz7VqlzLie/l1mXE/flBlUERuN\nBkEQBAOK6LEFQRAEA4pwbEEQBMGAIhxbEARBMKCIqMg+REmI8iDgg7ZPy+LL77d9bx83rV8haSUA\n23U3eM2f5dbM3/fuOeBe15hElrR60c72Cz0pr5F2NmLXqG0ZeqPuBuy6/NzL2jV4v5v63aiyL/Pd\nbNp1B+WI4JE+RNJ5JAHmnW1/WNKKwFjbw7tR1iDS3nH7Amvm7OeAPwIX2n63EbtGbbN9Q86gs4dC\ndvJnA7sArwAClgP+Apxoe3rBdjfgF8ATuU5Iu56vD3zF9thsNxQ4H1i+yu6VbPdAI+U10s4Gr6ds\nmcsDo4B9gNVIIfUzSffnTNuv9GLdjZRZ9nPvjfvT1O9Gg59RU687aIC+XiHezgl4IP99sJD3UJXN\nIOBLwE2kxakTSTt6HwksUbC7nLQdzrak/xRr59fnAVc2atcN291Ii2//RNrHbnRu81Rgt4LdusAV\nwIukh81U0sP4CmBwwe5u4DPA4oW8xYEDgHFVdT9aPLeQvx7waOH9BGCbGnbbFj/3suU10s4Gr6ds\nmTcDJ5B6+ZW89+e8sb1cdyNllv3ce+P+NPW70eBn1NTrjlQ+9XkD2jkB9+T/EBUHtyoFJ5fzyjqs\nxzup5/FG7bphW/YBUvah8EQndT9R/R4YVMNuSWBqyTKnNlpeI+1s9HpKlllLR3GhY71Ud7PK7PX7\n08zvRhM/o27VHalcijm2vuWnwLXAapLOAD4FfKfKZivbG1blzQDGSSpugjpL0v7A7213AEhaDNif\ntGN4o3aN2g7K7armOWCJwvtVbF9ZNLA9F7hC0umF7Psl/QK4hPlb/qwDHAo8WFXHRcB9kq6osj0A\nuLBg9ydJNwCXVtkdQupdNlpeI+1s5HrK2j4t6VvAJc7zMXme5vMsuE1Sb9TdSJllP/feuD/N/m40\ncu3Nvu6gJDHH1sdI2og0Vi/gVtuPVh0fB/yI2s7lONvb5LzBwFnAzsx3OisAt5HG/ac1YtcN21HA\np0lDitUPkN/Z/n62uwKYRe2Hwiq2P53tliTN741k/pzdDOA60vze21Wf04erbJ8Dxth+pMpuzzp2\nN3azvFLtbOR6GihzReDEbLdatnuBtIP7Wc5zl71Ud6P3p+zn3tT704htA3U38nk29bqDcoRj60Mk\nbQtMtv16fr8c8GHb9xRsBlPSuRTOWRnA9std1F/KrqxtmQdIow/EIAiChunrsdB2TqRhCxXeL0ae\nb6tjvzKwcjfqeX8z7Rq17YXPba8GbE8taVd2P61S5TXSzgavp2yZW/Zh3Y2U2ew91Bq5P039bjT4\nGTV9/7ZI81Ms0O5b5PztBXAaaqw772n7ZRd6TJLeX7Ke6nmHnto1ZCvp1JJ2e5UsspHlEPeXtFOT\ny4Py7WzkesrafrkP626kzLKfe2/cn2Z/N6D8tTf7uoMCMRTZh0i6BridFOEIae+wnWzvU/L8G2x/\nvJea1zQkfcL2dSXsvmv7lEXRpiAIBi7RY+tbjgT+gzQXNQPYBjii7MnNdmqSlq2Rt1gOVkHSkpK2\nrCysLksZp5btFnBqkraWNDy/3ljScZJGNFK3pJOr3n9Q0vGS/lfSjyUdmec2q8/bSdK5kv4o6RpJ\nZ0pav04dPWqnpF1L2FzaybElauSt0t26JS0n6UM18jfvjl2dev9SJ38jSbtUfxcl7VH1fndJh+c5\n6GL+F7qqu2B7ctdWIOmwGnk9veeHVb0v9b0MyhE9tgGCpM1IO0avRVokfYLt2fnYvba3LlHGM7bX\nLbzfB/glSR3lSODbwBvAEODL1Q5L0k7AJ0lRjnOBx4HRtqdW2S0L7FFlNzYPxVZsTgH2JA3N3kJy\n+rcBuwI32z6j5Ocy75okHQPsBdwBjCDNcb5CUlb5iu3bs933SQudbyWpekzLbfwK8D+2r2pmO2t8\n7mOqTUi7Rv8FwPbe2W4n4P+ApYEHSPMx0/OxB2xv2Y26Pw38hLRofgng87bvqy6zrF1+P7HG9WwI\nTMnXs3m2O4a0GemjpM1Hj7X9xxp1/w+wfb7mTwA/sf2zRq671rU38Bk19Z6X/V4GDdDXk3ztnEgL\nsr9N2lDwokqqstkMGEcKjb8AWLFw7N7C6ztJzmIF4HhgMvChfKyobHJcnfQNYFZV3Q+SHvDrAa8B\nQ3L+B4DxVbbfB34NfA64GvgB8P9yGfsX7D4N3EtSJnmS9GC+jKSosnnBbhJp4fZ7c93L5fz3ABOr\n6n6tTnodmFNdZn79XuD2/Hrdqs9oUuH1IODv+fWKwMNVdZdqJykEv1a6DnizqswHgN8AOwIfy3+f\nz68/VrC7D9gkv/4UaTHytjXueSN1TwDWyK+3Bh4D9q1RZim7Qv2/ATbK353BpO/zB4APVH2Wy+bX\ng0m7Zx9bo+5J5EXXpO/7jcA5deou+92YWCdNAt7u5j0vVSYlv5eRyqdYoN23/BH4G/BnUs+lFucB\np5Kc2xeBOyXtbftJFlz4/D7blcWcP5R0P3CTpINJGoIV/ofkdObUqGuhoWnb/4R5vzArv7CfrgxP\nFtjL9mbZ9grgr7a/KYn9SxAAABMkSURBVOnqfI2VXs53SA/ft/Jw2WW2d8/DV+eThmYhPXTmAm9J\netL2a7nuf0nqYEFeAYa7tljus1VZg0if9VLAsrnMZ6qG8zokreS0DmxN0kMM27MlVU/ml23nR0lO\n/43qJpIcQ5FhwLHAScA3bU+Q9C/bf62yW9L25Fzf1ZIeBa6RdAIL3vNG6l7c9vO5zHtzr/B6SetU\nlVnWDtt7S9qX9MPsh7bHSHrX9tNVdS9m+418znRJOwJXS/oACwZRDLI9J9u9IukTwAWSriIpihQp\n+91YHdidhYUHBNxVlVf2njdSZpnvZVCScGx9y3ttn9CFTVmHhaTlbb8KYPs2SZ8Efg8U58QeAP5g\ne6GIMElfrJG3mNMQ4RcKeYuz8AOkrDMQ8K/8+k3ywmLbE6vmFN6R9F7bbwFbFa+RNDRa5FLSr/9a\naui/LbweTVKhuIf0sD8rl7kqadF4hf8BHlRSdhlCjjDMdg9VlV+2neOAt2o4JyRNKb7Pn/c5+UF9\njqQXqP1/9V1J76/8+LA9WdIuwPVAce6rdN3A65I+lH84Yfv57GD+AGzSDbvKNV0raSxwuqTDWfj7\nA/CCpKG2J+Rz3lCKlL2INHJR4UlJH6tcT3Yyh0v6HmkovEjZ78b1pN7ihGojSbdXZZW952XLLPu9\nDMrS113Gdk7A94ARXdg8BCxflbc5adjp5ULeZ8nDUFW26wK/KrwfQlL4qFXX6lXvhwNL17AbDHyu\nKu8zwNOkOYdngI/n/FWB3xbsziKJ955E6sl9O+evRFqsXrFbqk4bVwE268Fnvglp2G6jLuxWIvWc\nVujCrlfaWVXWx0lze9X5/wVsUSN/BeCkbta1BbBBjfwlgIMateukjiNr5K9NnfWRwH8WXr8HeE8d\nu7Wa8Zkv6nte9nsZqVyK4JE+RNLrwDLA28C7pN6MbS9XsPks8JTtcVXnrgv8t+3/10n5q9me2SuN\nr13fSsAHScKtr3RiNwLYmKRcfkvOW4y0W0Fd5RFJX7H9i06OL+GFt9JZxfZLnbXZDex1Jmkj2491\nYdNpO7tbdz5nWefhukVFd9pZdf6SwLvOD5s8bLkl8IjtP5Uso9R117s/3fluNFp3g+1c5Pexrehr\nzxqpOYnUwyimlYHppICHlUqWcUHV++VIQSH/B3y26tgvGmhbV72jvWvk1Qpueanyvsp2J9JyiZeA\nsSy4/c0DhdffKbzemBTpOC1/TgttG1Knrc90p53Af5Ki/SaTouhuIQXPPAts18Bn+Uzh9UakCNgb\nSEOPF5PmlO4lSbNV7NYhaXj+jRSsVNzu6A9V5ZdqZ4NlPkQOegK+SZpf+k4u+/vd+dwbuD+lvhvN\nqLu77SSNwHQZIBapfIo5tj5GSch2A1LINgC27ygcfz9wCmns/mTgq6R5hEdJEWPPZ9OXSEOBRdbi\n/7d3/rF2VVUe/6y2SG2LJFZsQDACBjCggj8awuD8wVRkNGlJLT9EEeuPqGBhZILGYKLIxCFoVBhl\nRsCgoIAgPywmICg/BBULSn+KvyhDVDBTcNSqUaQu/1j79u133rnv7XN7Yb/7+v0kO++ec9bZZ52z\n77vr7L3XXivm1JzoSfV6Va2qEK7GOZcRQ57XAW9Pc3YnefSqDu9wm7cSQ6KY2fKW637OIqkp7n59\n2n8O4e22iTHHgdnAbi31nw+8zmOOaQVwm5md7NHLzef3lhPDvxAONGe4+81mtphwXT8i6Xhhn/sw\nYpgvp1TPTxMeoQsIQ3Ssu99jZq8A/oswKKTrnznJ9fP1XRen+1hALAX4ILCScB3/LBFcG2KO6jri\nx/MdwF0Wi+afIOafBtGzS52zPS09IYasX+PhaHEe8f38UJf77tg+Rd+NDs+8i56ldV5EmYOYKESG\nrSLJWeMMYm5hLWEsvk8EPO7xReIHZj6xVuYrhAE6lvAiXJbkziLW0Zzl7htS/Q+7+76Ny24hDGD+\ng+9p+/kN2f3dvTcZf6OZnQ3cbmZLW+6l9Mfmq8Qc25Zs33xiPZIDPcN2MJHVYD5wjocX5Snufk7L\nNUq9A3P28jQM5uHV9+zs2Eqi59U2LPqmxnapnrtk7bLF3e9J1/5R49pQ7rm6m6e1hGZ2rrtfnfbf\nZGb59fdw9/9Jn1eZ2VuA76R2bD6fUj271PkHMzvE3TcSL2BzCQeiOY37Kb3vLu1T+t3o4i1cKtul\nHYscxEQhtbuMO3Mh1q/MBdam7YOA6xsy+fqd5jDL2sb23oRb/aeIHsPmlmv+HHhhH31+2dh+kHDB\nzve9jeidPNLYv5WImnJKS3k8k3s1sfD5vdm+hyd5RsuA7xIT6xPuJ8ncT8PpgLGXha3Zvt8xtn5r\nC+GV2ju2Mft8O3BEn2u16jqVnozPmHxs41hzbdz3iDx8k7YR49dMndqvztRecxvHlxDZyx8bRM+O\ndb6MGI68PJWHiNGA+8mGuDvcd3H7dPhuFF27o56lckUOYirlpboCO3MB7kt/15I8rcg8A9N2/kPz\nH41jG/rUu5QY1vhNy7HTaPGkS8dWNbbPB5a0yB3DxCzJXX5sZhE91TuIdVStBiuTn0+8+X6nz/F+\n3oG7k3kHkhY4Z6W3GHgRcFom91wyo9ehPfvqmdpkQp3E3NgHGvsOJHpEbddYlH1+d+8eGjIvJqJx\n9LbfT7awO9t/GHDbIHp2qTPtn01E6ziD6G2dQMPjtMN9F7dPh+9GF2/hItkO91Pk0axSXuQVWREz\nu4EYVvk3xvKt7eLur89kPgac7w0PKou4hee5+4ps30HEvNoPiMWe+7v7RjM7xseGOtr0uNzd39qy\n/3TgBndvLnJuq+O5wF881vYUYWZ7EXNbr3L3/UrPm+6Y2UIvyHEnpjfPtFexGCK1LatKFKIHsZSY\nEyg9Z2X2+XQi9t6NhJffsuxY7hnYFlbpj73tRv2/Bx4lPN9Opc/bZ4VndXNju8h7kwgP9t/A5wiv\n0Y8Sw8HXkMJDJbljss+7Eyl61hMLeptv7+eR3t6JdW+biSGkR2jp0fS5n6Y36myiN3Yu2fqtdCz3\n7JwHfICYX51LDBOvJnraE3pyjXp+NsBzv3gY1+7XlqXt8zR9N3bYq7jlGZW24w7ft8r4oh5bZZJX\n5D5kjjzu/qPCc/NAqhsId+w/WkQ8/xpwhbtfYGYPuPthSe4BYn7kUsacRq4CTkzXviur/wEissIS\nYuhoKZHD6ipiLnBrJvscwrttb+LH5crs2EXufmr63ObluZyINbjdyzN54bXeNvANd98zq/86wpjc\nS0RI+RvJe9PGB8+9hTFHnJMIR5wrCUecJe6+LMnl51wK/IYIML2cMFbHZtfe4GOhxO4ghuvuM7MD\niIXpr0rHJvNGXefue2d1XkoYjjXAyUR4sjNbdLuGcBF/NjHs9SDhnLOUmFc6OcltZcwJoec0NA/4\nMxPXTRbpWXrtJFvUlh3a5+n4bvydiV7FexNLBdyzEYUOz6i0HYvuW5Qjw1YRMzuXeNPdzFgoHnf3\nozKZZmT07YeAA9x91yS3yd0Pzs5bQBi3HwNHufuhaX9vfuv1jMUh3OwtQ4E2MUr7LsQ8yZuIf7g9\nsmPDNi7bgLsY773Z43B33+6hZ2Zre/eXts9O97eUmO/pXTs38M2I7WuzZ5Tr26y7uf0gEW3iKTO7\n190Pz47lRm8b/b1RX+Duz8rOW+9jEe/nEO7gz0vP/d7sHta6+6FmZkSQ5D3d3dP2uqyOCwnP1LM8\nxUzs4zFbrGfptbM6p2zLDu3zdHw3/p0yr+Iuz6i0HYvuW3SgdpdxZy7E0OGkQ49EjLtDSZHQs/Ii\n4NFM7nbg0Ma5cwgvtG0t9fY8KD9Ln0WlTBJZnMbkPRM9NM8mvAQXMn4otMjLE9hIS8imdGwg700K\nHXGIt/TeYuvNpBfAdKyZWWAVsU7vKGII6QJiWPkcosfck+vijfqTFpmPpOf582xf/ryaWSHWNbZf\nmb4jpxPOO/08TIv07Hjtoracon3Wd62vy3ej8T/R16u44zMqbcei+1YpL0o0WpeNTFxQ2qQXSPWR\nRvlfIvt2j7cSQ2bbcfenPJxC/rlZqbv/yt2PIyJXfLnPtU/op5RPdBLZ1bKI/x45qS4hckwtzOTy\n71wzeebs7PNH6Z8Id1Vj+ybGr/3D3b9IGKYns91fTz1Z3P3DvZ3JEScPBnwJ8cO2APgS8ZbdG0Yd\nF9DWIw/Yx4m5lGVJjw8SyWPzpJefIeZr2ji/sX2/NRJreqyLu4x4ocnleveTB6nen1h+kZ//Q2JI\nGaK3M5d2SvUsvjblbTlZ+/xsgPqg/LuR/0/cSURFmdfnGl2eUUk7lt63KKW2Zd2ZC+Fs8GtiwfJ2\nh47aeg14L0VLA4CP0d9F/WuNfQcR0TMWNOtsOb+f7L8OUueQrt2sczGRQgUipNeZ9AmCXSrbR+4N\nZL3MFrnXEPObkwbgzs69vItc89otckcmPY8eRI7ode5TqFORbFOOmDs8pI/srsSL5JK0fRIx8nEa\n40OLTSb3rEad+xF5FC8geozvIeV5U+leNMdWETPbRGSo3kCW7sJb0ouMMma20t0v6yJnhdmU0/Yq\n4H1TyQ5broue1iHrcqnsDsgtJnolbdde3WwW2rN3F8kl2e0Z3M3sXel53QAcDdzk7ud1lPs9kfLo\nIcKR6Vp3zyPZjClVKNsid433CZBsZl8hnuU8YtH/AiJizr8QRv2UAjnc/W1JThm0h01ty7ozF9IC\n7ZleGCwwbFE25S6yw5YboM7SjOClGZqHKtfTmbLs3UVyLc/hPtKyEcKBaMMgcsRQ5NHEUowtwC1E\nlJvdWu5nStmOda5Pf+cQc+C97NfWeO6lcsqgPeSiWJF1udvM/pMYgtwe984L3f2nE1N4by7qKkd5\nNuUussOW6yLbJSN4qeyw5SCcTEqyd5fKAcyyWNYyi+jRbEnX/5OZPTWAnHskY70VuLXhrftJIgdg\nV9kudc6ySMUznzBEuxMJQXdlfNDiUjlQBu2hIsNWl8PS3zxSvtOY7B4RFgGvI6Kn5BgRM6+rXGk2\n5S6yw5brItslI3ip7LDl8MLs3aVyid2J9Y8GuJnt6ZFxewHjjX+p3LiXC488a6uB1WbWdPgole1S\n5xeIdZezCcN+rZltJv6Prx5AThm0h03tLuPOWoi30uNr6zHE+/kCcGSfY1cOIFeUTbmL7LDlOtZZ\nnHW5VHbYcn1kWrN3DyrXOGcesG9XOWL9Zuk1imS71Jnk9yIyREB4Nq8AFu+AnDJoD7HIeaQiZna/\np8gUQgghhoMMW0UsEi0+ToQi+lNvv7tr+EEIIQZEhq0iZvZwy273GRTpXgghnmlk2IQQQswo5BVZ\nkeTK+17GQl7dCXzewyNLCCHEAKjHVhGLtBa7EPEIIVJbbHP3d9bTSgghRhsZtoqY2Tp3f/lU+4QQ\nQpSj6P512ZaioQNgZvsR0QeEEEIMiObY6nIWcEeKRmBEnrWVdVUSQojRRkORFTCz49z9WjPbF3gU\nODAd+qm7/3WSU4UQQkyBDFsFeulMmilQhBBC7DgybBUws9uIYMeLiRxM4/Asl5UQQohuyLBVIKWy\neAVwBTDBtd9nWKJRIYR4JpHzSAXc/Ukzuw+4S0ZMCCGGi9z9K+GR+PHg2noIIcRMQz22uqw1s9XA\ntYyP7n99PZWEEGK0kWGry1zgCcZnzHZAhk0IIQZEziNCCCFmFJpjq4iZHWBm3zazjWn7ZWb24dp6\nCSHEKCPDVpdLgA8BfwNw9/XAiVU1EkKIEUeGrS7z3H1NY99TVTQRQogZggxbXR5P0f0dwMxWAI/V\nVUkIIUYbOY9UJKWpuRg4Avh/4GHgze7+SFXFhBBihJFhmwaY2Xxglrtvra2LEEKMOhqKrIiZLTSz\nC4G7gTvN7AIzW1hbLyGEGGVk2OpyNbAFeCOwIn3+alWNhBBixNFQZEXMbKO7H9LYt8HdX1pLJyGE\nGHXUY6vLrWZ2opnNSuV44Ju1lRJCiFFGPbaKmNlWYD6wLe2azVgwZHf351RRTAghRhgZtmmMmR3s\n7ptq6yGEEKOEhiKnN1fUVkAIIUYNGbbpjdVWQAghRg0ZtumNxomFEKIjMmxCCCFmFDJs05snaysg\nhBCjhrwiK2Nmy4EjiWHHe9z9hsoqCSHESCPDVhEzuwh4MXBV2nUC8JC7n1ZPKyGEGG1k2CpiZj8B\nXuKpEcxsFrDJ3V9SVzMhhBhdNMdWl18AL8y290n7hBBCDMic2grsjJjZTcSc2m7Ag2a2Jh1aDKzp\ne6IQQogpkWGrwydrKyCEEDMVzbFVxswWAa9Om2vc/f9q6iOEEKOO5tgqktLUrAGOA44HfmBmK+pq\nJYQQo416bBUxs3XAa3u9NDPbA/iWu7+8rmZCCDG6qMdWl1mNoccnUJsIIcQOIeeRutxiZt9kbIH2\nicDNFfURQoiRR0ORlUkhtf4pbd7t7jfW1EcIIUYdGbYKmNk97n6kmW0l1rPledf+DvwW+IS7X1RF\nQSGEGGFk2KYhZrYQ+J67H1hbFyGEGDVk2KYpZranuz9WWw8hhBg1ZNiEEELMKORaLoQQYkYhwyaE\nEGJGIcMmhBBiRiHDJoQQYkbxDyePHUYKLZoNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXUJicmjlT_4",
        "colab_type": "text"
      },
      "source": [
        "So it looks like for now, it is safe to drop this feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V7Recx4lZGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping feature 'v239'\n",
        "\n",
        "numeric_df.drop('v239', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrUGXvK_B6J4",
        "colab_type": "text"
      },
      "source": [
        "We will then choose to impute the rest of the missing numeric features, during our imputation step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJAWL1hje97q",
        "colab_type": "text"
      },
      "source": [
        "## Examination of the categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0u62ihTGiV-",
        "colab_type": "code",
        "outputId": "0f110904-4775-4796-f0db-5103a802f2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        }
      },
      "source": [
        "# take a look at the missing values for categorical features dataframe\n",
        "print(\"Proportionally, categorical features contribute {0:.2f}% of the total features in the dataset\".format(categorical_df.shape[1]/final_kept_df.shape[1]*100))\n",
        "print((categorical_df.isnull().sum().sort_values(ascending=False)/(categorical_df.shape[0]) * 100 )[:20])\n",
        "b = pd.Series(categorical_df.isnull().sum().sort_values(ascending=False)/(categorical_df.shape[0]) * 100 )\n",
        "b.plot(kind='bar')\n",
        "\n",
        "# 17 features with more than 20% of its values missing of 205 features\n",
        "print(\"The number of categorical features with more than 20% of its values missing is: {}, which is {}% of all categorical features\".format(17, 17/categorical_df.shape[1]*100))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Proportionally, categorical features contribute 85.65% of the total features in the dataset\n",
            "ctryqual          47.432606\n",
            "v291              45.811938\n",
            "v137              45.250321\n",
            "cnt_brth          43.993368\n",
            "v3                39.190201\n",
            "birthrgn          37.366282\n",
            "v269              35.761660\n",
            "v91               35.745614\n",
            "v47               33.290543\n",
            "v236              33.178220\n",
            "v289              27.251819\n",
            "v96               24.919769\n",
            "earnhrbonusdcl    22.368421\n",
            "earnhrdcl         22.117030\n",
            "v255              21.266581\n",
            "v212              21.074027\n",
            "reg_tl2           20.180787\n",
            "v62               17.233633\n",
            "earnflag          16.714805\n",
            "v8                16.442020\n",
            "dtype: float64\n",
            "The number of categorical features with more than 20% of its values missing is: 17, which is 9.18918918918919% of all categorical features\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFZCAYAAACIUdS7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgWo8NI_6gMx",
        "colab_type": "code",
        "outputId": "82c5e03a-d897-4947-ea7f-9a1456dd806e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "temp = pd.DataFrame(categorical_df.columns, columns=['feature_name'])\n",
        "temp['num_unique_values'] = [len(categorical_df[col].unique()) for col in categorical_df.columns]\n",
        "print(\"There are {} features that have <=10 unique values in feature column, which could benefit greatly from categorization.\".format(temp[temp['num_unique_values'] <= 10].sort_values('num_unique_values', ascending=False).shape[0]))\n",
        "print(\"This is {0:.2f}% of the categorical features that could benefit from categorization optimization\".format(temp[temp['num_unique_values'] <= 10].shape[0]/categorical_df.shape[1] * 100))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 171 features that have <=10 unique values in feature column, which could benefit greatly from categorization.\n",
            "This is 92.43% of the categorical features that could benefit from categorization optimization\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bESORlL79TkV",
        "colab_type": "code",
        "outputId": "4025ddb2-e65c-4511-8182-b162905b26cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# we can see that the categorical features, because of many data points and features there are, contribute heavily to the memory usage\n",
        "\n",
        "categorical_df.info(memory_usage='deep')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 18696 entries, 0 to 19999\n",
            "Columns: 185 entries, v85 to v74\n",
            "dtypes: category(4), object(181)\n",
            "memory usage: 231.8 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGGRPorcNRT9",
        "colab_type": "code",
        "outputId": "2113d258-5439-415d-c012-513f803ec9bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# have a look at the memory usage of the top 10 object columns before categorization\n",
        "\n",
        "categorical_df[[col for col in categorical_df.columns if len(categorical_df[col].unique()) <= 10]].memory_usage(deep=True)[:10].sort_values(ascending=False)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "v122                  1774191\n",
              "v34                   1416454\n",
              "planning_wle_ca       1387720\n",
              "influence_wle_ca      1383578\n",
              "v200                  1348598\n",
              "v85                   1252554\n",
              "ageg10lfs             1171450\n",
              "computerexperience    1121515\n",
              "v227                  1107972\n",
              "Index                  149568\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HHdHET99HIP",
        "colab_type": "text"
      },
      "source": [
        "We can cast some of the object features to category to better optimize for memory usage and computation, however  we can only do this after the nan values and other values are imputed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVdPuwT73xDS",
        "colab_type": "text"
      },
      "source": [
        "## Unique categorical groupings in the categorical features \n",
        "\n",
        "Just to get a little perspective on how many categories there are for the dataset, we will print each of their unique values for the first several features. This will help us have an idea of how much the dataset will ballon once we onehot encode for each categorical feature value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfCdT__8nJA9",
        "colab_type": "code",
        "outputId": "2e6b21cd-276e-484f-cbbc-91f317098a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# unique values for each categorical feature. need to know how what encoding scheme we should use\n",
        "\n",
        "num_cat_gtoe_10 = []\n",
        "for column in categorical_df.columns:\n",
        "    if len(categorical_df[column].unique()) >= 10:\n",
        "        print(f\"######### {column} ##########\")\n",
        "        print(categorical_df[column].unique()) # returns np.ndarray\n",
        "        print(\"Number of unique values: {}\\n\".format(len(categorical_df[column].unique())))\n",
        "        num_cat_gtoe_10.append(column)\n",
        "print(\"There are {} categorical columns with more than 10 categories\".format(len(num_cat_gtoe_10)))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "######### earnmthalldcl ##########\n",
            "[6th decile, 2nd decile, 7th decile, 9th decile, 3rd decile, ..., 5th decile, NaN, Lowest decile, 8th decile, 4th decile]\n",
            "Length: 11\n",
            "Categories (10, object): [Lowest decile < 2nd decile < 3rd decile < 4th decile ... 7th decile <\n",
            "                          8th decile < 9th decile < Highest decile]\n",
            "Number of unique values: 11\n",
            "\n",
            "######### lng_bq ##########\n",
            "['eng' 'rus' 'tur' 'swe' 'deu' 'kor' 'ita' 'pol' 'fra' 'jpn' 'nld' 'spa'\n",
            " 'slv' 'dan' 'slk' 'heb' 'ces' 'est' 'ell' 'fin' 'nor' 'ara' 'cat' 'lit'\n",
            " '999' 'glg' 'hun']\n",
            "Number of unique values: 27\n",
            "\n",
            "######### reg_tl2 ##########\n",
            "['99999' 'UKJ' 'UKI' nan 'RU40' 'SE11' 'KR01' 'IE02' 'SG00' 'PL22' 'UKD'\n",
            " 'RU28' 'FR71' 'JPH' 'UKH' 'NL3' 'FR10' 'CL09' 'JPD' 'KR03' 'KR05' 'ES12'\n",
            " 'KR04' 'RU74' 'FR22' 'KR02' 'FR81' 'SI01' 'FR43' 'DK04' 'PL11' 'UKG'\n",
            " 'UKF' 'ES13' 'BE2' 'RU64' 'SK02' 'PL12' 'IL04' 'ES22' 'FR21' 'JPG' 'CZ05'\n",
            " 'PL43' 'ES30' 'ES61' 'RU45' 'JPC' 'JPF' 'RU50' 'CL05' 'JPE' 'UKC' 'EE00'\n",
            " 'CZ08' 'GR3' 'FR51' 'JPJ' 'FR30' 'SK01' 'PL32' 'CL13' 'SE33' 'ES51'\n",
            " 'FR24' 'ES70' 'RU01' 'FR52' 'RU19' 'NL4' 'RU27' 'KR06' 'JPI' 'RU54'\n",
            " 'PL63' 'UKE' 'PL41' 'RU41' 'UKN' 'PL21' 'RU22' 'DK01' 'CZ01' 'PL61'\n",
            " 'RU39' 'CZ04' 'JPB' 'NL2' 'FR82' 'NZ01' 'PL52' 'ES52' 'FR23' 'CZ07'\n",
            " 'SE22' 'FR61' 'FR62' 'RU65' 'PL51' 'CL08' 'RU37' 'SK03' 'PL33' 'RU08'\n",
            " 'SE31' 'IL07' 'NZ02' 'IL02' 'PL31' 'RU58' 'PL42' 'ES42' 'GR2' 'ES53'\n",
            " 'SE12' 'UKK' 'IL05' 'RU56' 'CZ06' 'ES23' 'ES62' 'ES21' 'ES41' 'RU67'\n",
            " 'LT08' 'CZ03' 'GR1' 'ES24' 'IE01' 'PL34' 'JPA' 'LT04' 'FR42' 'FR41' 'NL1'\n",
            " 'SE21' 'RU44' 'SI02' 'PL62' 'LT05' 'ES11' 'LT09' 'CZ02' 'RU15' 'FR83'\n",
            " 'DK02' 'FR25' 'ES43' 'CL02' 'IL01' 'ES63' 'CL06' 'IL06' 'DK05' 'RU16'\n",
            " 'SK04' 'DK03' 'CL07' 'LT07' 'IL03' 'LT02' 'FR72' 'LT06' 'SE23' 'CL01'\n",
            " 'FR53' 'CL14' 'LT03' 'GR4' 'LT01' 'LT10' 'FR26' 'KR07' 'SE32' 'FR63'\n",
            " 'CL10']\n",
            "Number of unique values: 176\n",
            "\n",
            "######### earnhrdcl ##########\n",
            "['7th decile' nan 'Lowest decile' '2nd decile' 'Highest decile'\n",
            " '5th decile' '3rd decile' '4th decile' '6th decile' '9th decile'\n",
            " '8th decile']\n",
            "Number of unique values: 11\n",
            "\n",
            "######### isic1c ##########\n",
            "['M' 'C' 'D' 'N' 'G' 'P' 'I' 'O' 'K' 'F' 'A' 'L' 'R' 'Q' 'H' 'J' nan 'B'\n",
            " 'T' 'S' 'E']\n",
            "Number of unique values: 21\n",
            "\n",
            "######### cntryid ##########\n",
            "['Canada' 'United Kingdom' 'Norway' 'United States' 'Russian Federation'\n",
            " 'Turkey' 'Sweden' 'Germany' 'Korea' 'Ireland' 'Singapore' 'Italy'\n",
            " 'Poland' 'France' 'Japan' 'Netherlands' 'Chile' 'Spain' 'Slovenia'\n",
            " 'Denmark' 'Belgium' 'Slovak Republic' 'Israel' 'Czech Republic' 'Estonia'\n",
            " 'Greece' 'Finland' 'Austria' 'New Zealand' 'Lithuania']\n",
            "Number of unique values: 30\n",
            "\n",
            "######### cntryid_e ##########\n",
            "['Canada (English)' 'England (UK)' 'Norway' 'United States'\n",
            " 'Russian Federation' 'Turkey' 'Sweden' 'Germany' 'Korea' 'Ireland'\n",
            " 'Singapore' 'Italy' 'Poland' 'France' 'Japan' 'Netherlands' 'Chile'\n",
            " 'Spain' 'Slovenia' 'Denmark' 'Canada (French)' 'Flanders (Belgium)'\n",
            " 'Slovak Republic' 'Israel' 'Czech Republic' 'Estonia' 'Greece' 'Finland'\n",
            " 'Austria' 'Northern Ireland (UK)' 'New Zealand' 'Lithuania' nan]\n",
            "Number of unique values: 33\n",
            "\n",
            "######### v31 ##########\n",
            "['General programmes' 'Engineering, manufacturing and construction'\n",
            " 'Social sciences, business and law' nan\n",
            " 'Science, mathematics and computing' 'Agriculture and veterinary'\n",
            " 'Health and welfare' 'Humanities, languages and arts' 'Services'\n",
            " 'Teacher training and education science']\n",
            "Number of unique values: 10\n",
            "\n",
            "######### lng_home ##########\n",
            "['999' 'eng' 'rus' 'kor' 'pol' 'fra' 'jpn' 'lit' 'nld' 'spa' 'slv' 'dan'\n",
            " 'slk' 'heb' 'ces' 'est' 'ell' 'fin' 'deu' 'nor' 'ita' 'cat' 'ara' 'glg'\n",
            " 'guj' 'hye' 'eus' 'por' 'hun' 'hrv' 'zho' 'swe' 'tam' nan 'fas' 'kur'\n",
            " 'ber' 'ben' 'srp' 'tur' 'hin' 'ron' 'sin' 'urd' 'run' 'phi' 'gla' 'bul'\n",
            " 'sla' 'pap']\n",
            "Number of unique values: 50\n",
            "\n",
            "######### lng_ci ##########\n",
            "['eng' 'nor' 'rus' 'tur' 'swe' 'deu' 'kor' 'ita' 'pol' 'fra' 'jpn' 'nld'\n",
            " 'spa' 'slv' 'dan' 'slk' 'heb' 'ces' 'est' 'ell' 'fin' 'cat' 'ara' 'lit'\n",
            " '999' 'glg' 'eus' nan 'hun']\n",
            "Number of unique values: 29\n",
            "\n",
            "######### v59 ##########\n",
            "[nan 'ISCED 5B'\n",
            " 'ISCED 5A bachelor degree, 5A master degree, and 6 (without distinction)'\n",
            " 'ISCED 5A, master degree' 'ISCED 3 (without distinction A-B-C, 2y+)'\n",
            " 'ISCED 5A, bachelor degree' 'ISCED 3A-B' 'ISCED 4A-B'\n",
            " 'ISCED 3C 2 years or more' 'Foreign qualification' 'ISCED 6' 'ISCED 2'\n",
            " 'ISCED 4 (without distinction A-B-C)' 'ISCED 3C shorter than 2 years'\n",
            " 'ISCED 1' 'ISCED 4C' 'No formal qualification or below ISCED 1']\n",
            "Number of unique values: 17\n",
            "\n",
            "######### v92 ##########\n",
            "[nan 'Full-time employed (self-employed, employee)' 'Unemployed'\n",
            " 'Part-time employed (self-employed, employee)'\n",
            " 'Fulfilling domestic tasks or looking after children/family'\n",
            " 'Pupil, student' 'Apprentice, internship' 'Permanently disabled' 'Other'\n",
            " 'In retirement or early retirement'\n",
            " 'In compulsory military or community service']\n",
            "Number of unique values: 11\n",
            "\n",
            "######### v212 ##########\n",
            "[nan 'ISCED 3 (without distinction A-B-C, 2y+)' 'ISCED 5B'\n",
            " 'ISCED 5A, bachelor degree' 'ISCED 3A-B' 'ISCED 4C' 'ISCED 4A-B'\n",
            " 'ISCED 5A, master degree'\n",
            " 'ISCED 5A bachelor degree, 5A master degree, and 6 (without distinction)'\n",
            " 'ISCED 6' 'ISCED 1' 'ISCED 4 (without distinction A-B-C)' 'ISCED 2'\n",
            " 'No formal qualification or below ISCED 1' 'ISCED 3C 2 years or more'\n",
            " 'ISCED 3C shorter than 2 years']\n",
            "Number of unique values: 16\n",
            "\n",
            "######### v19 ##########\n",
            "['Aged 20-24' nan 'Aged 25-29' 'Aged 30-34' 'Aged 35-39' 'Aged 40-44'\n",
            " 'Aged 19 or younger' 'Aged 45-49' 'Aged 50-54' 'Aged 55 or older']\n",
            "Number of unique values: 10\n",
            "\n",
            "######### cnt_brth ##########\n",
            "[nan 'United Kingdom of Great Britain and Northern Ireland'\n",
            " 'Russian Federation' 'Turkey' 'Republic of Korea' 'Malaysia' 'Poland'\n",
            " 'France' 'Japan' 'Lithuania' 'Netherlands' 'Chile' 'Ethiopia' 'Spain'\n",
            " 'Croatia' 'Denmark' 'Belgium' 'Slovakia' 'Israel' 'Czech Republic'\n",
            " 'Venezuela (Bolivarian Republic of)' 'Canada' 'Estonia' 'Greece'\n",
            " 'Finland' 'South Africa' 'Austria' 'Republic of Moldova' 'Algeria'\n",
            " 'Italy' 'Morocco' 'Singapore' 'China' 'Australia' 'Colombia' 'Ghana'\n",
            " 'Argentina' 'India' 'Slovenia' 'Armenia' 'Dominican Republic' 'Zimbabwe'\n",
            " 'Tunisia' 'Germany' 'Ukraine' 'Cuba' 'Brazil' 'Uzbekistan' 'Switzerland'\n",
            " 'Senegal' 'Philippines' 'Egypt'\n",
            " 'The former Yugoslav Republic of Macedonia' 'Bosnia and Herzegovina'\n",
            " 'United States of America' 'Peru' 'Thailand' 'Congo' 'Romania'\n",
            " 'Afghanistan' 'Mexico' 'Saint Lucia' 'Bangladesh' 'Kenya' 'Bolivia'\n",
            " 'Paraguay' 'Indonesia' 'Serbia' 'Cyprus' 'Portugal' 'Ireland' 'Sri Lanka'\n",
            " 'Myanmar' 'Belarus' 'Burundi' 'Cameroon' 'Azerbaijan' 'Mauritius' 'Iraq'\n",
            " 'Albania' 'Viet Nam' 'Sweden' 'Latvia'\n",
            " 'Hong Kong Special Administrative Region of China' 'Norway'\n",
            " 'Trinidad and Tobago' 'Nigeria' 'Kyrgyzstan']\n",
            "Number of unique values: 88\n",
            "\n",
            "######### earnhrbonusdcl ##########\n",
            "['7th decile' nan 'Lowest decile' '8th decile' '2nd decile'\n",
            " 'Highest decile' '6th decile' '3rd decile' '4th decile' '5th decile'\n",
            " '9th decile']\n",
            "Number of unique values: 11\n",
            "\n",
            "######### ageg5lfs ##########\n",
            "['Aged 25-29' 'Aged 60-65' 'Aged 30-34' 'Aged 20-24' 'Aged 35-39'\n",
            " 'Aged 40-44' 'Aged 45-49' 'Aged 55-59' 'Aged 50-54' 'Aged 16-19']\n",
            "Number of unique values: 10\n",
            "\n",
            "######### ctryqual ##########\n",
            "[nan 'North America and Western Europe' 'Central and Eastern Europe'\n",
            " 'East Asia and the Pacific (richer countries)'\n",
            " 'East Asia and the Pacific (poorer countries)' 'Sub-Saharan Africa'\n",
            " 'Latin America and the Caribbean' 'Arab States' 'South and West Asia'\n",
            " 'Central Asia']\n",
            "Number of unique values: 10\n",
            "\n",
            "######### birthrgn ##########\n",
            "[nan 'North America and Western Europe' 'Central Asia'\n",
            " 'Central and Eastern Europe'\n",
            " 'East Asia and the Pacific (richer countries)'\n",
            " 'East Asia and the Pacific (poorer countries)'\n",
            " 'Latin America and the Caribbean' 'Sub-Saharan Africa' 'Arab States'\n",
            " 'South and West Asia']\n",
            "Number of unique values: 10\n",
            "\n",
            "There are 19 categorical columns with more than 10 categories\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjjAdbrm6j6l",
        "colab_type": "text"
      },
      "source": [
        "## Impressions on missing categorical data\n",
        "Proportionally, there are more missing numerical feature values than there are categorical feature values. There are some categorical feature values that use numeric values to indicate a discrete category or range. This can be gleened by particular values such as '9999' or '999' to indicate a missing value or distinct category. Some of the features that encode their values as such include:\n",
        "* ~~reg_tl2~~\n",
        "* ~~lng_home~~\n",
        "* ~~ageg10lfs~~\n",
        "* ~~ageg10lfs_t~~\n",
        "\n",
        "These features are seemingly identical, and therefore we select one to keep and we drop the other:\n",
        "* ~~ageg10lfs~~\n",
        "* ~~ageg10lfs_t~~\n",
        "\n",
        "One feature has 946 unique values which probably indicates that the values maybe numeric in nature as opposed to categorical. There are also two alphabetical letter values feature, namely : 'C' and 'G'. These values will be imputed as np.nan values before the the numeric casting of the feature column. Additionally, the numeric values in this feature are actually strings and will have to be forced cast to int or float values\n",
        "* ~~v71~~\n",
        "\n",
        "Another categorical feature uses extensive numerical coding, interleaved with few alphabetic numeric coding. The instict is to cast the alphabetical coding can be cast to np.nan before the entire feature category can be cast as a numeric column, however, after looking at the value_counts for each of categories in this feature, we can decide to leave it alone as there are a signficant numer of data points that use the alphabetical encoding:\n",
        "* ~~isic2c~~\n",
        "\n",
        "Can be cast to numeric:\n",
        "* ~~isic2l~~\n",
        "\n",
        "This feature seems to be a more granular subfeature of 'cntryrgn' and a few other of the country based features, however this feature has significantly more unique values (176 unique values). As it is a sparser representation of the other superfeatures, it can be dropped:\n",
        "* ~~reg_tl2~~\n",
        "\n",
        "There are a lot of missing values for the lng_home feature when we look at the value_counts. If questionnaire was completed in English, and the language of the exercise was done in English, then may be safe to assume that the primary language spoken at home maybe the same language. Therefore, we will apply this logic for all the missing values in the lng_home feature. These are the language categorical variables.\n",
        "* ~~lng_bq~~\n",
        "* ~~lng_ci~~\n",
        "* ~~lng_home~~\n",
        "\n",
        "Some features have exactly only one categorical value. These can be dropped as they do no add further information\n",
        "* ~~uni -> only value is 'cl3770'~~\n",
        "\n",
        "Instead of 'No' as the other binary value in a categorical feature, this feature has NaN instead... This value will have to be replaced with the string 'No':\n",
        "* ~~v270~~\n",
        "\n",
        "Some features have a large category space, which would balloon the dataset once onehot-encoded. There are 24 columns with more than 10 categories and they are: \n",
        "* ['isic1l', 'ageg5lfs', 'v71', 'earnmthalldcl', 'earnhrdcl', 'ctryqual', 'cntryid', 'reg_tl2', 'cnt_brth', 'isic1c', 'lng_ci', 'cntryid_e', 'v92', 'v59', 'edcat8', 'v31', 'lng_bq', 'v19', 'isic2l', 'lng_home', 'birthrgn', 'v212', 'earnhrbonusdcl', 'isic2c']\n",
        "\n",
        "There are also many seemingly highly correlated and repeated features that can be dropped which pertain to information about which country or region an employee is from:\n",
        "* 'ctryrgn', 'ctryqual', 'birthrgn', 'cntryid_e', 'cntryid'\n",
        "\n",
        "Our best bet would be to select to keep just one of these features - preferrably a feature with a relatively low number of categories, and then drop the rest.\n",
        "\n",
        "Therefore we will try to do our best to reduce the number of categories by possibly coming up with higher level categories to encompass these features or cast them as numeric features if the majority of their values are numerically encoded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbP4o1MWdok5",
        "colab_type": "text"
      },
      "source": [
        "## Pre-Imputer Imputation for categorical features\n",
        "Therefore, some of the imputation and preprocessing can be done before the encoding step of the preprocessing portion of the pipeline (dropping,casting, merging, etc). The next few segments of code will go through the next preprocessing steps as outlined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmrAYnBWVYco",
        "colab_type": "code",
        "outputId": "6d1cbf89-7d8c-422c-ee8f-e67f37f77a7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# NaN's -> 'No' for 'v270'\n",
        "\n",
        "values = {'v270': 'No'}\n",
        "categorical_df.fillna(value=values, inplace=True)\n",
        "print(categorical_df['v270'].unique())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Yes' 'No']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWjzCLPDFXc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# address missing values for lng_home  and the other language features\n",
        "\n",
        "categorical_df['lng_home'] = categorical_df['lng_bq'].where(categorical_df['lng_bq'] == categorical_df['lng_ci'])\n",
        "\n",
        "# language features\n",
        "import re\n",
        "language = ['lng_bq', 'lng_ci', 'lng_home']\n",
        "num_pattern = re.compile('\\d\\d\\d')\n",
        "\n",
        "# replace the 999 value with np.nan\n",
        "for col in language:\n",
        "    categorical_df[col].replace(to_replace=num_pattern, value=np.nan, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly3EHoPutlhU",
        "colab_type": "code",
        "outputId": "bd2e2021-664a-4aa2-e0bc-90d2a84639ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# categorical features with only one value\n",
        "\n",
        "for column in categorical_df.columns:\n",
        "    if len(categorical_df[column].unique()) <=1:\n",
        "        print(column)\n",
        "        print(\"The only unique value for {} is: {}\".format(column, categorical_df[column].unique()))\n",
        "\n",
        "# dropping column 'uni' with value only cl3770\n",
        "categorical_df.drop(columns='uni', inplace=True, axis=1)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uni\n",
            "The only unique value for uni is: ['cl3770']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3tGFRn35ETy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# addressing the missing values of feature reg_tl2\n",
        "\n",
        "categorical_df.drop(columns='reg_tl2', inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3wrlIP8DQzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from here, we select only one of these to keep and we will drop the rest\n",
        "\n",
        "country_features = ['ctryrgn', 'ctryqual', 'birthrgn', 'cntryid_e', 'cntryid']\n",
        "# categorical_df[country_features].head()\n",
        "\n",
        "# we decide to only keep the ctryrgn and drop the rest for now, however, cntryid is another candidate to keep if we wanted more granularity with respect to country information\n",
        "categorical_df.drop(columns=['ctryqual', 'birthrgn', 'cntryid_e', 'cntryid'], inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq7HttdTEh3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we drop 'ageg10lfs_t' because it contains identical values to 'ageg10lfs'\n",
        "\n",
        "categorical_df.drop(columns='ageg10lfs_t', inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVl4dECJ4JOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop dupe education columns\n",
        "\n",
        "categorical_df.drop(columns=['v59', 'v212'], inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTOpWmzgNvJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# drop neet because only one value\n",
        "\n",
        "categorical_df.drop('neet', inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm4fxtICmwD0",
        "colab_type": "text"
      },
      "source": [
        "### Setting Ordinality to Categorical Features\n",
        "\n",
        "Although we touched on setting the ordinality of some of the object or categorical features earlier, now would be the time to go through the rest of the categorical features and set the ordinality for them. Unfortunately, unless you do some NLU, and NLP with another feature, we may have to go through each of the features and handcraft ordinality from the text data ourselves. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34-ixme1iYcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorical_look_filter(dataset):\n",
        "    \"\"\" For each feature in a pandas dataset, print out the unique values in the dataset.\"\"\"\n",
        "    \n",
        "    bin_feats = []\n",
        "    multicat_feats = []\n",
        "    \n",
        "    for col in dataset.columns:\n",
        "    # Binary\n",
        "        if 'Yes' in dataset[col].unique() or len(dataset[col].unique()) == 2:\n",
        "             \n",
        "            bin_feats.append(col)\n",
        "    # Multi-Category\n",
        "        else:\n",
        "            multicat_feats.append(col)\n",
        "\n",
        "    return bin_feats, multicat_feats\n",
        "    \n",
        "bin_features, multicategory_features = categorical_look_filter(categorical_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT1Ol9pxzKUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "other_bin_features = [\"faet12\", 'v46', 'earnflag', 'v53', 'nfe12', 'nativelang', 'v205', 'nopaidworkever', 'v84', 'paidwork5', 'fe12', 'paidwork12', 'aetpop']\n",
        "binary_df = categorical_df[bin_features + other_bin_features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtnnRgst7m0T",
        "colab_type": "text"
      },
      "source": [
        "### Encoding Binary Features\n",
        "We use a combination of pd.Categorical and mappings to encode these features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXc8O2Z0G_Es",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping Binary Cases for these series\n",
        "\n",
        "binary_df = binary_df.replace(to_replace={'Yes': 1, 'No': 0})\n",
        "binary_df = binary_df.replace(to_replace={'Male': 1, 'Female': 0})\n",
        "binary_df['faet12'] = binary_df['faet12'].map({'Did not participate in formal AET': 0, 'Participated in formal AET': 1})\n",
        "binary_df['v46'] = binary_df['v46'].map({'One job or business': 0, 'More than one job or business': 1})\n",
        "binary_df['earnflag'] = binary_df['earnflag'].map({'Earnings and/or bonuses imputed': 0, 'Reported directly': 1})\n",
        "binary_df['v53'] = binary_df['v53'].map({'Employee': 0, 'Self-employed': 1})\n",
        "binary_df['nfe12'] = binary_df['nfe12'].map({'Did not participate in NFE': 0, 'Participated in NFE': 1})\n",
        "binary_df['nativelang'] = binary_df['nativelang'].map({'Test language not same as native language': 0, 'Test language same as native language': 1})\n",
        "binary_df['v205'] = binary_df['v205'].map({'Unemployed': 0, 'Employed': 1, 'Out of the labour force': 2})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRDVq1rgW-Qy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These columns are apparently dataframes, so I have to switch over to using the replace method with dictionaries instead\n",
        "\n",
        "binary_df['nopaidworkever'] = binary_df['nopaidworkever'].replace({\"Has not has paid work ever\": 0, \"Has had paid work\": 1})\n",
        "binary_df['v84'] = binary_df['v84'].replace({\"Recent work experience in last 12 months\": 0, \"Currently working (paid or unpaid)\": 1})\n",
        "binary_df['paidwork5'] = binary_df['paidwork5'].replace({\"Has not had paid work in past 5 years\": 0, \"Has had paid work in past 5 years\": 1})\n",
        "binary_df['fe12'] = binary_df['fe12'].replace({\"Did not participate in FE\": 0, \"Participated in FE\": 1})\n",
        "binary_df['paidwork12'] = binary_df['paidwork12'].replace({\"Has not had paid work during the 12 months preceding the survey\": 0, \"Has had paid work during the 12 months preceding the survey\": 1})\n",
        "binary_df['aetpop'] = binary_df['aetpop'].replace({\"Excluded from AET population\": 0, \"AET population\": 1})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7kN0KI0WNN8",
        "colab_type": "code",
        "outputId": "2920ccb1-bf10-4708-b7b6-de25200668a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "binary_df.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18696, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZoNByMGX_bu",
        "colab_type": "code",
        "outputId": "9f05688a-ef57-4e95-e4ab-a3846abef740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "binary_df.head()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>computerexperience</th>\n",
              "      <th>v227</th>\n",
              "      <th>v84</th>\n",
              "      <th>v102</th>\n",
              "      <th>v17</th>\n",
              "      <th>v201</th>\n",
              "      <th>v250</th>\n",
              "      <th>v255</th>\n",
              "      <th>v188</th>\n",
              "      <th>v28</th>\n",
              "      <th>v101</th>\n",
              "      <th>v115</th>\n",
              "      <th>nativespeaker</th>\n",
              "      <th>gender_r</th>\n",
              "      <th>v225</th>\n",
              "      <th>v251</th>\n",
              "      <th>v176</th>\n",
              "      <th>paidwork12</th>\n",
              "      <th>v270</th>\n",
              "      <th>v142</th>\n",
              "      <th>v153</th>\n",
              "      <th>v285</th>\n",
              "      <th>v90</th>\n",
              "      <th>aetpop</th>\n",
              "      <th>v258</th>\n",
              "      <th>paidwork5</th>\n",
              "      <th>nopaidworkever</th>\n",
              "      <th>v60</th>\n",
              "      <th>v157</th>\n",
              "      <th>v152</th>\n",
              "      <th>v256</th>\n",
              "      <th>fe12</th>\n",
              "      <th>v74</th>\n",
              "      <th>faet12</th>\n",
              "      <th>v46</th>\n",
              "      <th>earnflag</th>\n",
              "      <th>v53</th>\n",
              "      <th>nfe12</th>\n",
              "      <th>nativelang</th>\n",
              "      <th>v205</th>\n",
              "      <th>nopaidworkever</th>\n",
              "      <th>v84</th>\n",
              "      <th>paidwork5</th>\n",
              "      <th>fe12</th>\n",
              "      <th>paidwork12</th>\n",
              "      <th>aetpop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   computerexperience  v227  v84  v102  ...  paidwork5  fe12  paidwork12  aetpop\n",
              "0                 1.0   0.0    1   0.0  ...          1     1           1       1\n",
              "1                 1.0   1.0    1   0.0  ...          1     0           1       1\n",
              "2                 1.0   1.0    1   1.0  ...          1     1           1       1\n",
              "3                 1.0   1.0    1   0.0  ...          1     0           1       1\n",
              "4                 1.0   0.0    1   0.0  ...          1     1           1       0\n",
              "\n",
              "[5 rows x 46 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxxGZFB5fuU8",
        "colab_type": "text"
      },
      "source": [
        "## Label Encoding\n",
        "\n",
        "Before you can even impute for the missing values and setting up ordinality with the categorical features, you must first set up the label encoding scheme for each feature. Later, we can use the inverse encoding scheme to set up the ordinality mapping of each categorical feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S1xUXlLdill",
        "colab_type": "text"
      },
      "source": [
        "You have to do encoding before you can impute for missing value. Therefore the plan is:\n",
        "\n",
        "\n",
        "1.   Use the label encoder to encode the string values in the features (LabelEncoder.fit_transform(X)).\n",
        "2.   Impute for the missing values (missing_imputer.fit_transform(X))\n",
        "3.   Using the inverse mapping (with LabelEncoder.inverse_transform(X)) for the label encoding, set up the ordinality of the ordinal features using the specified ordinality mapping. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icJ_3aPNJxkY",
        "colab_type": "text"
      },
      "source": [
        "### Nominal Cateogrical Encodings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WNqAdXWZERM",
        "colab_type": "text"
      },
      "source": [
        "Note: you can get the original encoding scheme back from the encoder with the le.classes_ method, which will return a list of all the unique classes in each feature. These features classes are assigned numeric encodings, based on their index in the alphabetically ordered list of the collection of all the possible classes in that feature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_9Rfq9ugQdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "nominal_multicategorical_feats = [\"v3\", 'ctryrgn', 'v91', 'lng_home', 'cnt_brth', 'lng_ci', 'v31', 'v96', \"isic1c\", \"v92\", \"v88\", \"v140\", \"v137\"]\n",
        "nominal_df = categorical_df[nominal_multicategorical_feats]\n",
        "nominal_categorical_encoding_manifest = {}\n",
        "\n",
        "##### Using LabelEncoding to Encode\n",
        "# temporarily fill nan values with an encoding, and then after labelencoding, inverse transform, set nans back to np.nan and then impute for missing\n",
        "nominal_df.fillna('Null', inplace=True)\n",
        "\n",
        "for col in nominal_df.columns:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(nominal_df[col].values.ravel())\n",
        "    nominal_df[col] = le.transform(nominal_df[col].values.ravel())\n",
        "    null_index = list(le.classes_).index('Null')\n",
        "    nominal_categorical_encoding_manifest[col] = list(le.classes_)\n",
        "#     print(f\"{col}: {null_index}, type: {type(null_index)}\\n\")\n",
        "    nominal_df[col].replace(to_replace=list(le.classes_).index('Null'), value=np.nan, inplace=True)\n",
        "    le = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfjVCevyYngq",
        "colab_type": "code",
        "outputId": "9f78ade2-6e07-49a8-d5d2-4a25f69c45d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nominal_df.shape"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18696, 13)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBaPsPku6gWn",
        "colab_type": "code",
        "outputId": "d1553521-8a40-4ad9-ad06-b27abe3ad59c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "nominal_df.head()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v3</th>\n",
              "      <th>ctryrgn</th>\n",
              "      <th>v91</th>\n",
              "      <th>lng_home</th>\n",
              "      <th>cnt_brth</th>\n",
              "      <th>lng_ci</th>\n",
              "      <th>v31</th>\n",
              "      <th>v96</th>\n",
              "      <th>isic1c</th>\n",
              "      <th>v92</th>\n",
              "      <th>v88</th>\n",
              "      <th>v140</th>\n",
              "      <th>v137</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   v3  ctryrgn  v91  lng_home  cnt_brth  ...  isic1c  v92  v88  v140  v137\n",
              "0 NaN      3.0  NaN       7.0       NaN  ...    12.0  NaN  1.0   2.0   NaN\n",
              "1 NaN      3.0  3.0       7.0      82.0  ...     2.0  2.0  1.0   3.0   2.0\n",
              "2 NaN      3.0  4.0       7.0      82.0  ...     3.0  2.0  1.0   2.0   NaN\n",
              "3 NaN      3.0  4.0       NaN       NaN  ...    13.0  2.0  1.0   2.0   4.0\n",
              "4 NaN      3.0  NaN       7.0       NaN  ...     6.0  2.0  1.0   2.0   NaN\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d51Px7hnKUrx",
        "colab_type": "text"
      },
      "source": [
        "### Ordinal Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSXHiDzlBT5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set ordinality to categorical features with some degree of scale. We can do this by creating a dictionary of the mappings per suspected ordinal feature\n",
        "ordinality_mapping = [\n",
        "    [[\"v233\", \"v280\", \"v103\", \"v15\", \"v24\", \"v108\", \"v218\", \"v171\", \"v189\", \n",
        "     \"v204\", \"v166\", \"v267\", \"v292\", \"v155\", \"v165\", \"v190\", \"v288\", \n",
        "     \"v276\",\"v43\", \"v197\", \"v214\", \"v7\", \"v175\", \"v139\", \"v123\", \"v14\", \"v178\",\n",
        "    \"v34\", \"v106\", \"v246\", \"v131\", \"v111\", \"v173\", \"v260\", \"v164\", \"v186\", \"v240\", \"v208\",\n",
        "    \"v275\", \"v132\", \"v141\", \"v25\", \"v177\", \"v149\", \"v23\", \"v193\", \"v237\", \"v162\", \"v146\",\n",
        "    \"v277\", \"v40\", \"v73\", \"v195\"], \n",
        "     ['Never','Less than once a month','Less than once a week but at least once a month','At least once a week but not every day','Every day']],\n",
        "    [['v244', \"v65\", \"v263\", \"v158\", \"v57\", \"v170\", \"v198\", \"v278\", \"v25\", \"v191\", \"v114\", \"v27\"], ['Not at all','Very little', 'To some extent', 'To a high extent','To a very high extent']],\n",
        "    [\"ageg10lfs\", ['24 or less','25-34', '35-44','45-54', '55 plus']],\n",
        "    [\"v151\", ['Aged 15 or younger', 'Aged 16-19', 'Aged 20-24', 'Aged 25-29','Aged 30-34', 'Aged 35 or older']],\n",
        "    [\"v181\", ['Extremely dissatisfied', 'Dissatisfied', 'Neither satisfied nor dissatisfied', 'Satisfied', 'Extremely satisfied']],\n",
        "    [\"v271\", ['Straightforward','Moderate','Complex']],\n",
        "    [\"v122\", ['No', 'Yes, unpaid work for family business', 'Yes, paid work one job or business','Yes, paid work more than one job or business or number of jobs/businesses missing']], \n",
        "    [[\"v247\", \"v134\", \"v13\", \"v18\", \"v26\", \"v124\", \"v99\", \"v282\", \"v51\", \"v2\", \"v248\"], ['Never','Rarely','Less than once a week' ,'At least once a week']], \n",
        "    [[\"v291\", \"v77\"], ['None of the time', 'Up to a quarter of the time','Up to half of the time','More than half of the time','All of the time']],\n",
        "    [\"v269\", ['Not useful at all', 'Somewhat useful' , 'Moderately useful','Very useful']],\n",
        "    [[\"v216\", \"v124\"], ['Rarely or never','Less than once a week', 'At least once a week']],\n",
        "    [[\"v253\", \"v284\"], ['Never', 'Rarely', 'Less than once a week but at least once a month', 'At least once a week']],\n",
        "    [\"ageg5lfs\", ['Aged 16-19','Aged 20-24','Aged 25-29','Aged 30-34','Aged 35-39', 'Aged 40-44', 'Aged 45-49','Aged 50-54','Aged 55-59','Aged 60-65']],\n",
        "    [\"v289\", ['No income', 'Lowest quintile','Next lowest quintile','Mid-level quintile', 'Next to highest quintile' ,'Highest quintile']],\n",
        "    [\"v261\", ['0 - 20 hours','21 - 40 hours', '41 - 60 hours' , '61 - 80 hours', '81 - 100 hours', 'More than 100 hours']],\n",
        "    [\"monthlyincpr\", ['Less than 10','10 to less than 25', '25 to less than 50', '50 to less than 75', '75 to less than 90', '90 or more']],\n",
        "    [\"v221\", ['None','Less than 1 month','1 to 6 months','7 to 11 months', '1 or 2 years','3 years or more']],\n",
        "    [[\"v85\", \"v50\", \"v69\"], ['Strongly disagree', 'Disagree', 'Neither agree nor disagree', 'Agree', 'Strongly agree']],\n",
        "    [[\"readhome_wle_ca\", \"influence_wle_ca\", \"readytolearn_wle_ca\", \n",
        "     \"learnatwork_wle_ca\", \"readwork_wle_ca\", \"planning_wle_ca\", \"taskdisc_wle_ca\"], ['All zero response', 'Lowest to 20%', 'More than 20% to 40%', 'More than 40% to 60%', 'More than 60% to 80%', 'More than 80%']],\n",
        "    [[\"v82\", \"v70\"], ['Employee, not supervisor', 'Self-employed, not supervisor','Employee, supervising fewer than 5 people', 'Employee, supervising more than 5 people', 'Self-employed, supervisor']],\n",
        "    [\"v200\", ['Not definable', 'Less than high school', 'High school' 'Above high school']],\n",
        "    [\"v62\", ['A higher level would be needed', 'This level is necessary', 'A lower level would be sufficient']],\n",
        "    [\"v236\", ['No, not at all', 'There were no such costs', 'No employer or prospective employer at that time' ,'Yes, partly', 'Yes, totally']],\n",
        "    [\"v19\", ['Aged 19 or younger', 'Aged 20-24', 'Aged 25-29', 'Aged 30-34' ,'Aged 35-39' ,'Aged 40-44', 'Aged 45-49', 'Aged 50-54', 'Aged 55 or older']],\n",
        "    [[\"earnhrbonusdcl\", \"earnhrdcl\"], ['Lowest decile','2nd decile', '3rd decile', '4th decile', '5th decile', '6th decile', '7th decile', '8th decile', '9th decile', 'Highest decile']],\n",
        "    [\"imyrcat\", ['In host country 5 or fewer years', 'In host country more than 5 years', 'Non-immigrants']],\n",
        "    [\"v48\", ['1 to 10 people', '11 to 50 people', '51 to 250 people', 'More than 1000 people', '251 to 1000 people']],\n",
        "    [\"v47\", ['Days', 'Weeks',  'Hours']],\n",
        "    [\"v94\", ['Respondent reported no learning activities', 'Respondent reported 1 learning activity', 'Respondent reported learning activities but number is not known', 'Respondent reported more than 1 learning activity']],\n",
        "    [\"v8\", ['Decreased', 'Stayed more or less the same', 'Increased']]\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FHw0WSzVrza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ordinal_features = []\n",
        "\n",
        "for mask, cat in ordinality_mapping:\n",
        "    if isinstance(mask, list):\n",
        "        for label in mask:\n",
        "#             print(f\"{label}: {cat}\")\n",
        "            ordinal_features.append(label)\n",
        "\n",
        "    elif isinstance(mask, str):\n",
        "#         print(f\"{mask}: {cat}\")\n",
        "        ordinal_features.append(mask)\n",
        "\n",
        "ordinal_df = categorical_df[ordinal_features]\n",
        "ordinal_df.fillna('Null', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeX6Ybe98Xv-",
        "colab_type": "code",
        "outputId": "88c40004-3022-485d-cf0e-b20c9e555802",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ordinal_df.shape"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18696, 116)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReP6xyZyEVEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mapping the values based on the ordinality mapping\n",
        "# some of these features, for some reason, are dataframes, so you have to convert them to series as an intermediary\n",
        "# and then do inplace replacement of the string values with the mapping.\n",
        "# the integere mapping here implies ordinality, where as the integer label encoding for the nominal features doesn't\n",
        "\n",
        "for mask, cat in ordinality_mapping:\n",
        "    if isinstance(mask, list):\n",
        "        for label in mask:\n",
        "            indiv_feat_mapping = {key: val for val, key in enumerate(cat)}\n",
        "            series = pd.Series(ordinal_df[label].values.ravel())\n",
        "            ordinal_df[label] = series.map(indiv_feat_mapping)\n",
        "\n",
        "    elif isinstance(mask, str):\n",
        "        indiv_feat_mapping = {key: val for val, key in enumerate(cat)}\n",
        "        series = pd.Series(ordinal_df[mask].values.ravel())\n",
        "        ordinal_df[mask] = series.map(indiv_feat_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmDBWiKjnBa3",
        "colab_type": "code",
        "outputId": "0cdefffe-6183-45d6-f6aa-5782fd3e5d8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# look at num missing values\n",
        "\n",
        "ordinal_features_to_drop = [\"v278\", \"v25\", \"v124\", \"v25\", \"v124\", \"v200\"]\n",
        "(ordinal_df[ordinal_features_to_drop].isnull().sum()/ordinal_df[ordinal_features_to_drop].shape[0] * 100).sort_values(ascending=False)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "v124    100.000000\n",
              "v124    100.000000\n",
              "v25     100.000000\n",
              "v25     100.000000\n",
              "v124    100.000000\n",
              "v124    100.000000\n",
              "v25     100.000000\n",
              "v25     100.000000\n",
              "v278    100.000000\n",
              "v200     95.539153\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7rWkTLleSFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The above features have too many features missing, so we will drop them\n",
        "\n",
        "ordinal_df.drop(ordinal_features_to_drop, inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hm6XAYQebOQ",
        "colab_type": "code",
        "outputId": "90bdd30e-07a0-4d04-e0b2-5aa106f60ffe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ordinal_df.shape"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18696, 110)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVNode5seoH7",
        "colab_type": "code",
        "outputId": "f1233ba9-3d1e-4e8b-c0bf-e78b2aec5e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "ordinal_df.head()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v233</th>\n",
              "      <th>v280</th>\n",
              "      <th>v103</th>\n",
              "      <th>v15</th>\n",
              "      <th>v24</th>\n",
              "      <th>v108</th>\n",
              "      <th>v218</th>\n",
              "      <th>v171</th>\n",
              "      <th>v189</th>\n",
              "      <th>v204</th>\n",
              "      <th>v166</th>\n",
              "      <th>v267</th>\n",
              "      <th>v292</th>\n",
              "      <th>v155</th>\n",
              "      <th>v165</th>\n",
              "      <th>v190</th>\n",
              "      <th>v288</th>\n",
              "      <th>v276</th>\n",
              "      <th>v43</th>\n",
              "      <th>v197</th>\n",
              "      <th>v214</th>\n",
              "      <th>v7</th>\n",
              "      <th>v175</th>\n",
              "      <th>v139</th>\n",
              "      <th>v123</th>\n",
              "      <th>v14</th>\n",
              "      <th>v178</th>\n",
              "      <th>v34</th>\n",
              "      <th>v106</th>\n",
              "      <th>v246</th>\n",
              "      <th>v131</th>\n",
              "      <th>v111</th>\n",
              "      <th>v173</th>\n",
              "      <th>v260</th>\n",
              "      <th>v164</th>\n",
              "      <th>v186</th>\n",
              "      <th>v240</th>\n",
              "      <th>v208</th>\n",
              "      <th>v275</th>\n",
              "      <th>v132</th>\n",
              "      <th>...</th>\n",
              "      <th>v18</th>\n",
              "      <th>v26</th>\n",
              "      <th>v99</th>\n",
              "      <th>v282</th>\n",
              "      <th>v51</th>\n",
              "      <th>v2</th>\n",
              "      <th>v248</th>\n",
              "      <th>v291</th>\n",
              "      <th>v77</th>\n",
              "      <th>v269</th>\n",
              "      <th>v216</th>\n",
              "      <th>v253</th>\n",
              "      <th>v284</th>\n",
              "      <th>ageg5lfs</th>\n",
              "      <th>v289</th>\n",
              "      <th>v261</th>\n",
              "      <th>monthlyincpr</th>\n",
              "      <th>v221</th>\n",
              "      <th>v85</th>\n",
              "      <th>v50</th>\n",
              "      <th>v69</th>\n",
              "      <th>readhome_wle_ca</th>\n",
              "      <th>influence_wle_ca</th>\n",
              "      <th>readytolearn_wle_ca</th>\n",
              "      <th>learnatwork_wle_ca</th>\n",
              "      <th>readwork_wle_ca</th>\n",
              "      <th>planning_wle_ca</th>\n",
              "      <th>taskdisc_wle_ca</th>\n",
              "      <th>v82</th>\n",
              "      <th>v70</th>\n",
              "      <th>v62</th>\n",
              "      <th>v236</th>\n",
              "      <th>v19</th>\n",
              "      <th>earnhrbonusdcl</th>\n",
              "      <th>earnhrdcl</th>\n",
              "      <th>imyrcat</th>\n",
              "      <th>v48</th>\n",
              "      <th>v47</th>\n",
              "      <th>v94</th>\n",
              "      <th>v8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 110 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   v233  v280  v103  v15  v24  v108  ...  earnhrdcl  imyrcat  v48  v47  v94   v8\n",
              "0   4.0   4.0   4.0  2.0  0.0   4.0  ...        6.0      2.0  1.0  NaN  NaN  2.0\n",
              "1   4.0   4.0   3.0  3.0  1.0   1.0  ...        NaN      2.0  NaN  1.0  3.0  NaN\n",
              "2   4.0   3.0   3.0  2.0  2.0   1.0  ...        NaN      2.0  NaN  0.0  1.0  NaN\n",
              "3   4.0   4.0   4.0  3.0  2.0   3.0  ...        NaN      0.0  NaN  1.0  3.0  NaN\n",
              "4   0.0   3.0   0.0  3.0  2.0   0.0  ...        0.0      1.0  1.0  NaN  0.0  0.0\n",
              "\n",
              "[5 rows x 110 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPoirdUXfEdS",
        "colab_type": "text"
      },
      "source": [
        "Putting all the hard work of preprocessing our categorical features together back into one dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpGlxmi9e26b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categorical_df = pd.concat([binary_df, ordinal_df, nominal_df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj5o1fVrfKge",
        "colab_type": "code",
        "outputId": "4722e195-d386-4d3f-8c80-affe5b414fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "categorical_df.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18696, 169)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CZ2IxYcfMIq",
        "colab_type": "code",
        "outputId": "419d43e9-31a1-406a-ca8e-6209a8fa3702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "categorical_df.head()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>computerexperience</th>\n",
              "      <th>v227</th>\n",
              "      <th>v84</th>\n",
              "      <th>v102</th>\n",
              "      <th>v17</th>\n",
              "      <th>v201</th>\n",
              "      <th>v250</th>\n",
              "      <th>v255</th>\n",
              "      <th>v188</th>\n",
              "      <th>v28</th>\n",
              "      <th>v101</th>\n",
              "      <th>v115</th>\n",
              "      <th>nativespeaker</th>\n",
              "      <th>gender_r</th>\n",
              "      <th>v225</th>\n",
              "      <th>v251</th>\n",
              "      <th>v176</th>\n",
              "      <th>paidwork12</th>\n",
              "      <th>v270</th>\n",
              "      <th>v142</th>\n",
              "      <th>v153</th>\n",
              "      <th>v285</th>\n",
              "      <th>v90</th>\n",
              "      <th>aetpop</th>\n",
              "      <th>v258</th>\n",
              "      <th>paidwork5</th>\n",
              "      <th>nopaidworkever</th>\n",
              "      <th>v60</th>\n",
              "      <th>v157</th>\n",
              "      <th>v152</th>\n",
              "      <th>v256</th>\n",
              "      <th>fe12</th>\n",
              "      <th>v74</th>\n",
              "      <th>faet12</th>\n",
              "      <th>v46</th>\n",
              "      <th>earnflag</th>\n",
              "      <th>v53</th>\n",
              "      <th>nfe12</th>\n",
              "      <th>nativelang</th>\n",
              "      <th>v205</th>\n",
              "      <th>...</th>\n",
              "      <th>ageg5lfs</th>\n",
              "      <th>v289</th>\n",
              "      <th>v261</th>\n",
              "      <th>monthlyincpr</th>\n",
              "      <th>v221</th>\n",
              "      <th>v85</th>\n",
              "      <th>v50</th>\n",
              "      <th>v69</th>\n",
              "      <th>readhome_wle_ca</th>\n",
              "      <th>influence_wle_ca</th>\n",
              "      <th>readytolearn_wle_ca</th>\n",
              "      <th>learnatwork_wle_ca</th>\n",
              "      <th>readwork_wle_ca</th>\n",
              "      <th>planning_wle_ca</th>\n",
              "      <th>taskdisc_wle_ca</th>\n",
              "      <th>v82</th>\n",
              "      <th>v70</th>\n",
              "      <th>v62</th>\n",
              "      <th>v236</th>\n",
              "      <th>v19</th>\n",
              "      <th>earnhrbonusdcl</th>\n",
              "      <th>earnhrdcl</th>\n",
              "      <th>imyrcat</th>\n",
              "      <th>v48</th>\n",
              "      <th>v47</th>\n",
              "      <th>v94</th>\n",
              "      <th>v8</th>\n",
              "      <th>v3</th>\n",
              "      <th>ctryrgn</th>\n",
              "      <th>v91</th>\n",
              "      <th>lng_home</th>\n",
              "      <th>cnt_brth</th>\n",
              "      <th>lng_ci</th>\n",
              "      <th>v31</th>\n",
              "      <th>v96</th>\n",
              "      <th>isic1c</th>\n",
              "      <th>v92</th>\n",
              "      <th>v88</th>\n",
              "      <th>v140</th>\n",
              "      <th>v137</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 169 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   computerexperience  v227  v84  v102  v17  ...  isic1c  v92  v88  v140  v137\n",
              "0                 1.0   0.0    1   0.0  0.0  ...    12.0  NaN  1.0   2.0   NaN\n",
              "1                 1.0   1.0    1   0.0  0.0  ...     2.0  2.0  1.0   3.0   2.0\n",
              "2                 1.0   1.0    1   1.0  0.0  ...     3.0  2.0  1.0   2.0   NaN\n",
              "3                 1.0   1.0    1   0.0  1.0  ...    13.0  2.0  1.0   2.0   4.0\n",
              "4                 1.0   0.0    1   0.0  0.0  ...     6.0  2.0  1.0   2.0   NaN\n",
              "\n",
              "[5 rows x 169 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCFvnIGg4aUp",
        "colab_type": "text"
      },
      "source": [
        "## Imputation for Missing Values\n",
        "We want to then use an informed approach to imputation of missing data values. One method could be the use of KNN imputation or random forest and proximity matrix to imputing the missing values for our dataset with some similarity metric.\n",
        "\n",
        "We need to import for missing values first because we can apply the astype 'category' to these categorical, and oridinal features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GHjiOiAh8J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install missingpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqp5c26kfq81",
        "colab_type": "text"
      },
      "source": [
        "We combine the numeric dataframe back with the categorical dataframe at this point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaOkDCh4NJip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df = pd.concat([numeric_df, categorical_df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JGqbdM0g-Hs",
        "colab_type": "text"
      },
      "source": [
        "### Final bit of preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bei1DtyUhCn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "occupational_feats = ['v224', 'isco2c']\n",
        "values_to_replace = [9995, 9996, 9997, 9998, 9999]\n",
        "\n",
        "for col in occupational_feats:\n",
        "    for val in values_to_replace:\n",
        "        final_df.loc[final_df[col] == val, col] = np.nan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpcSbmbwrOvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df.drop('v224', inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6wEhHnA-Pwp",
        "colab_type": "code",
        "outputId": "93454af3-2b1a-4aaf-dfdd-c5503505c60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "((final_df.isnull()/final_df.shape[0]) * 100).sum().sort_values(ascending=False)[:5]"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "v291        49.363500\n",
              "v137        45.250321\n",
              "leavedu     44.228712\n",
              "cnt_brth    43.993368\n",
              "v269        39.955071\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V6eXdpqd-el",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Split into features and class\n",
        "\n",
        "X = final_df.loc[:, final_df.columns != 'job_performance'].values\n",
        "y = final_df['job_performance'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUENOIw-rduQ",
        "colab_type": "code",
        "outputId": "a7da12cd-c511-49ee-f0b1-564a4ea0f49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "!pip install missingpy"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting missingpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/be/998d04d27054b58f0974b5f09f8457778a0a72d4355e0b7ae877b6cfb850/missingpy-0.2.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.2MB/s \n",
            "\u001b[?25hInstalling collected packages: missingpy\n",
            "Successfully installed missingpy-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Enub0l1iisZ",
        "colab_type": "text"
      },
      "source": [
        "You could use either Missing Forest Imputation or KNN imputation. We decide to go with KNN imputation instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ParmpYEOiguF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let X be an array containing missing values\n",
        "# from missingpy import MissForest\n",
        "# imputer = MissForest()\n",
        "# X_imputed = imputer.fit_transform(X)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSEwyHGiiBFe",
        "colab_type": "code",
        "outputId": "882970f6-54c0-446f-870b-f9d30dbbc9c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# missing value imputation with KNN\n",
        "from timeit import default_timer\n",
        "from missingpy import KNNImputer, MissForest\n",
        "\n",
        "knn = KNNImputer(n_neighbors=3, weights=\"uniform\",\n",
        "                 metric=\"masked_euclidean\", row_max_missing=0.8,\n",
        "                 col_max_missing=0.8, copy=True)\n",
        "\n",
        "start_timer = default_timer()\n",
        "knn_missing_imputation = knn.fit_transform(X)\n",
        "end_timer = default_timer()\n",
        "print(\"{}s\".format((end_timer - start_timer)/10))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
            "  DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:432: DeprecationWarning: 'warn_on_dtype' is deprecated in version 0.21 and will be removed in 0.23. Don't set `warn_on_dtype` to remove this warning.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "30.483398664900005s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QF7xzvJ9G2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we see that the imputation actually works\n",
        "\n",
        "assert len(knn_missing_imputation) == final_df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GtiGhdZxHDa",
        "colab_type": "code",
        "outputId": "3666552e-a7b5-49d6-c1db-af1fda050d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#The imputation goes back into the dataframe\n",
        "\n",
        "final_df_imputed = pd.DataFrame(knn_missing_imputation, columns = final_df.columns[final_df.columns != 'job_performance'])\n",
        "final_df_imputed['job_performance'] = pd.Series(y)\n",
        "final_df_imputed.head()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v97</th>\n",
              "      <th>influence</th>\n",
              "      <th>writhome</th>\n",
              "      <th>readytolearn</th>\n",
              "      <th>planning</th>\n",
              "      <th>v135</th>\n",
              "      <th>v231</th>\n",
              "      <th>v272</th>\n",
              "      <th>v63</th>\n",
              "      <th>readwork</th>\n",
              "      <th>ictwork</th>\n",
              "      <th>isco2c</th>\n",
              "      <th>yrsqual_t</th>\n",
              "      <th>v235</th>\n",
              "      <th>v202</th>\n",
              "      <th>icthome</th>\n",
              "      <th>nfehrs</th>\n",
              "      <th>taskdisc</th>\n",
              "      <th>leavedu</th>\n",
              "      <th>readhome</th>\n",
              "      <th>writwork</th>\n",
              "      <th>v1</th>\n",
              "      <th>v33</th>\n",
              "      <th>v52</th>\n",
              "      <th>learnatwork</th>\n",
              "      <th>v242</th>\n",
              "      <th>computerexperience</th>\n",
              "      <th>v227</th>\n",
              "      <th>v84</th>\n",
              "      <th>v102</th>\n",
              "      <th>v17</th>\n",
              "      <th>v201</th>\n",
              "      <th>v250</th>\n",
              "      <th>v255</th>\n",
              "      <th>v188</th>\n",
              "      <th>v28</th>\n",
              "      <th>v101</th>\n",
              "      <th>v115</th>\n",
              "      <th>nativespeaker</th>\n",
              "      <th>gender_r</th>\n",
              "      <th>...</th>\n",
              "      <th>v289</th>\n",
              "      <th>v261</th>\n",
              "      <th>monthlyincpr</th>\n",
              "      <th>v221</th>\n",
              "      <th>v85</th>\n",
              "      <th>v50</th>\n",
              "      <th>v69</th>\n",
              "      <th>readhome_wle_ca</th>\n",
              "      <th>influence_wle_ca</th>\n",
              "      <th>readytolearn_wle_ca</th>\n",
              "      <th>learnatwork_wle_ca</th>\n",
              "      <th>readwork_wle_ca</th>\n",
              "      <th>planning_wle_ca</th>\n",
              "      <th>taskdisc_wle_ca</th>\n",
              "      <th>v82</th>\n",
              "      <th>v70</th>\n",
              "      <th>v62</th>\n",
              "      <th>v236</th>\n",
              "      <th>v19</th>\n",
              "      <th>earnhrbonusdcl</th>\n",
              "      <th>earnhrdcl</th>\n",
              "      <th>imyrcat</th>\n",
              "      <th>v48</th>\n",
              "      <th>v47</th>\n",
              "      <th>v94</th>\n",
              "      <th>v8</th>\n",
              "      <th>v3</th>\n",
              "      <th>ctryrgn</th>\n",
              "      <th>v91</th>\n",
              "      <th>lng_home</th>\n",
              "      <th>cnt_brth</th>\n",
              "      <th>lng_ci</th>\n",
              "      <th>v31</th>\n",
              "      <th>v96</th>\n",
              "      <th>isic1c</th>\n",
              "      <th>v92</th>\n",
              "      <th>v88</th>\n",
              "      <th>v140</th>\n",
              "      <th>v137</th>\n",
              "      <th>job_performance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.778923</td>\n",
              "      <td>2.574343</td>\n",
              "      <td>2.588515</td>\n",
              "      <td>3.734814</td>\n",
              "      <td>38.333333</td>\n",
              "      <td>21.666667</td>\n",
              "      <td>2007.666667</td>\n",
              "      <td>2080.000000</td>\n",
              "      <td>2.860090</td>\n",
              "      <td>2.624086</td>\n",
              "      <td>38.666667</td>\n",
              "      <td>12.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>21.666667</td>\n",
              "      <td>2.261395</td>\n",
              "      <td>33.333333</td>\n",
              "      <td>1.466427</td>\n",
              "      <td>23.666667</td>\n",
              "      <td>2.671265</td>\n",
              "      <td>3.690521</td>\n",
              "      <td>38.333333</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>3.449136</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>7.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>2381.623056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40.0</td>\n",
              "      <td>1.912440</td>\n",
              "      <td>3.116459</td>\n",
              "      <td>2.570880</td>\n",
              "      <td>1.958027</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1972.000000</td>\n",
              "      <td>808.666667</td>\n",
              "      <td>3.299227</td>\n",
              "      <td>2.237029</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>15.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>3.538845</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>1.106760</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>3.663056</td>\n",
              "      <td>3.101801</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>2.704957</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>7.333333</td>\n",
              "      <td>7.666667</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2866.885957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.0</td>\n",
              "      <td>2.063495</td>\n",
              "      <td>2.979574</td>\n",
              "      <td>2.955430</td>\n",
              "      <td>1.958027</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>2004.000000</td>\n",
              "      <td>720.000000</td>\n",
              "      <td>2.146608</td>\n",
              "      <td>2.067996</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>2.624791</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>1.181746</td>\n",
              "      <td>24.666667</td>\n",
              "      <td>2.513366</td>\n",
              "      <td>2.818857</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>2.622412</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.666667</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.333333</td>\n",
              "      <td>2871.232434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.0</td>\n",
              "      <td>2.793739</td>\n",
              "      <td>3.036055</td>\n",
              "      <td>1.555305</td>\n",
              "      <td>1.647927</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>173.000000</td>\n",
              "      <td>2.530622</td>\n",
              "      <td>4.466779</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>18.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.479338</td>\n",
              "      <td>320.000000</td>\n",
              "      <td>1.181746</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>3.612399</td>\n",
              "      <td>3.690521</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1.636855</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>21.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>2601.625461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.425363</td>\n",
              "      <td>2.675496</td>\n",
              "      <td>3.345168</td>\n",
              "      <td>1.752098</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>20.333333</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>1.210000</td>\n",
              "      <td>3.130518</td>\n",
              "      <td>0.665753</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>12.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>20.333333</td>\n",
              "      <td>2.645463</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>1.349476</td>\n",
              "      <td>20.333333</td>\n",
              "      <td>3.145437</td>\n",
              "      <td>0.056130</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>1.287352</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>2079.471114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 196 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    v97  influence  writhome  ...  v140      v137  job_performance\n",
              "0   1.0   2.778923  2.574343  ...   2.0  2.666667      2381.623056\n",
              "1  40.0   1.912440  3.116459  ...   3.0  2.000000      2866.885957\n",
              "2  10.0   2.063495  2.979574  ...   2.0  2.333333      2871.232434\n",
              "3   9.0   2.793739  3.036055  ...   2.0  4.000000      2601.625461\n",
              "4   5.0   2.425363  2.675496  ...   2.0  2.666667      2079.471114\n",
              "\n",
              "[5 rows x 196 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8rHopzwXVAAR",
        "colab": {}
      },
      "source": [
        "# new set of ordinal features after some of them have beend dropped\n",
        "# we won't have to do anything with ordinal features again\n",
        "\n",
        "ordinal_features = list(set(ordinal_features) - set(['v124', 'v200', 'v25', 'v278']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iniONbC3h5W",
        "colab_type": "text"
      },
      "source": [
        "## One Hot Encoding for Nominal Features\n",
        "\n",
        "We had to temporarily label encoded the nominal categorical features becuase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrkFeNnnXZlr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df_imputed[nominal_multicategorical_feats]= final_df_imputed[nominal_multicategorical_feats].applymap(lambda x: np.round(x)).astype('int64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA2sP7-3cRMY",
        "colab_type": "text"
      },
      "source": [
        "Reverse the labeling before the onehotencoding so that we can tell what the groupings are from the column headers after 1HE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBg2_FtAfoAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "70605ab9-07e9-42eb-e443-8de4809a48ff"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "final_df_imputed[nominal_multicategorical_feats].head()"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v3</th>\n",
              "      <th>ctryrgn</th>\n",
              "      <th>v91</th>\n",
              "      <th>lng_home</th>\n",
              "      <th>cnt_brth</th>\n",
              "      <th>lng_ci</th>\n",
              "      <th>v31</th>\n",
              "      <th>v96</th>\n",
              "      <th>isic1c</th>\n",
              "      <th>v92</th>\n",
              "      <th>v88</th>\n",
              "      <th>v140</th>\n",
              "      <th>v137</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>82</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>82</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>64</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   v3  ctryrgn  v91  lng_home  cnt_brth  ...  isic1c  v92  v88  v140  v137\n",
              "0   2        3    2         7        46  ...      12    2    1     2     3\n",
              "1   3        3    3         7        82  ...       2    2    1     3     2\n",
              "2   3        3    4         7        82  ...       3    2    1     2     2\n",
              "3   3        3    4        21        64  ...      13    2    1     2     4\n",
              "4   2        3    3         7         8  ...       6    2    1     2     3\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4_3YmWGvJ25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we use the dictionary of kvps for the nominal categorical values we created earlier\n",
        "np.random.seed(123)\n",
        "\n",
        "null_dict = {}\n",
        "\n",
        "assert len(nominal_multicategorical_feats) == len(nominal_categorical_encoding_manifest)\n",
        "\n",
        "for key, value in nominal_categorical_encoding_manifest.items():\n",
        "    null_dict[key] = value.index('Null')\n",
        "    null_replacement = value.index('Null')\n",
        "    \n",
        "    while null_replacement == value.index('Null'):\n",
        "        null_replacement = np.random.randint(low=0, high=len(value))                                \n",
        "        \n",
        "    final_df_imputed.loc[final_df_imputed[key] == value.index('Null'), key] = null_replacement                       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wAATuGHA3ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ensure that the replacement for the null value of the value pair holds true to this condition\n",
        "\n",
        "for col, null_value in null_dict.items():\n",
        "    assert null_value not in test[col].unique(), \"The previous null value encoding has not yet been replaced with a new random value encoding\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSS1fbd-CFqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbe22fff-7082-427f-8303-4f185f5fa756"
      },
      "source": [
        "# now retrieve the string value from the values list of the nominal_categorical_encoding_manifest dictionary\n",
        "# and replace it with the corresponding indexed encoding, and then apply the onehotencoding on these values\n",
        "\n",
        "start_time = default_timer()\n",
        "\n",
        "for key, values in nominal_categorical_encoding_manifest.items():\n",
        "    for value in values:\n",
        "        final_df_imputed.loc[final_df_imputed[key] == values.index(value), key] = values[values.index(value)]\n",
        "        \n",
        "end_time = default_timer()\n",
        "\n",
        "print(\"The replacement operation took {}s\".format((end_time-start_time)/1000))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The replacement operation took 0.002341657330999624s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sI0lH--J0RF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "outputId": "b833a705-6133-4aa2-9a90-35a08ed06d64"
      },
      "source": [
        "final_df_imputed[nominal_categorical_encoding_manifest.keys()].head()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v3</th>\n",
              "      <th>ctryrgn</th>\n",
              "      <th>v91</th>\n",
              "      <th>lng_home</th>\n",
              "      <th>cnt_brth</th>\n",
              "      <th>lng_ci</th>\n",
              "      <th>v31</th>\n",
              "      <th>v96</th>\n",
              "      <th>isic1c</th>\n",
              "      <th>v92</th>\n",
              "      <th>v88</th>\n",
              "      <th>v140</th>\n",
              "      <th>v137</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>An apprenticeship or other training scheme</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>Only outside working hours</td>\n",
              "      <td>eng</td>\n",
              "      <td>Lithuania</td>\n",
              "      <td>eng</td>\n",
              "      <td>General programmes</td>\n",
              "      <td>Per year</td>\n",
              "      <td>M</td>\n",
              "      <td>Full-time employed (self-employed, employee)</td>\n",
              "      <td>Employed or self employed</td>\n",
              "      <td>The private sector (for example a company)</td>\n",
              "      <td>A seminar or workshop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>An indefinite contract</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>Only during working hours</td>\n",
              "      <td>eng</td>\n",
              "      <td>United Kingdom of Great Britain and Northern I...</td>\n",
              "      <td>eng</td>\n",
              "      <td>Engineering, manufacturing and construction</td>\n",
              "      <td>Per two weeks</td>\n",
              "      <td>C</td>\n",
              "      <td>Full-time employed (self-employed, employee)</td>\n",
              "      <td>Employed or self employed</td>\n",
              "      <td>The public sector (for example the local gover...</td>\n",
              "      <td>An organised session for on-the-job training o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>An indefinite contract</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>Only outside working hours</td>\n",
              "      <td>eng</td>\n",
              "      <td>United Kingdom of Great Britain and Northern I...</td>\n",
              "      <td>eng</td>\n",
              "      <td>Social sciences, business and law</td>\n",
              "      <td>Per month</td>\n",
              "      <td>D</td>\n",
              "      <td>Full-time employed (self-employed, employee)</td>\n",
              "      <td>Employed or self employed</td>\n",
              "      <td>The private sector (for example a company)</td>\n",
              "      <td>An organised session for on-the-job training o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>An indefinite contract</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>Only outside working hours</td>\n",
              "      <td>rus</td>\n",
              "      <td>Russian Federation</td>\n",
              "      <td>nor</td>\n",
              "      <td>Social sciences, business and law</td>\n",
              "      <td>Per month</td>\n",
              "      <td>N</td>\n",
              "      <td>Full-time employed (self-employed, employee)</td>\n",
              "      <td>Employed or self employed</td>\n",
              "      <td>The private sector (for example a company)</td>\n",
              "      <td>Other kind of course or private lesson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>An apprenticeship or other training scheme</td>\n",
              "      <td>North America and Western Europe</td>\n",
              "      <td>Only during working hours</td>\n",
              "      <td>eng</td>\n",
              "      <td>Bangladesh</td>\n",
              "      <td>eng</td>\n",
              "      <td>Science, mathematics and computing</td>\n",
              "      <td>Per hour</td>\n",
              "      <td>G</td>\n",
              "      <td>Full-time employed (self-employed, employee)</td>\n",
              "      <td>Employed or self employed</td>\n",
              "      <td>The private sector (for example a company)</td>\n",
              "      <td>A seminar or workshop</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           v3  ...                                               v137\n",
              "0  An apprenticeship or other training scheme  ...                              A seminar or workshop\n",
              "1                      An indefinite contract  ...  An organised session for on-the-job training o...\n",
              "2                      An indefinite contract  ...  An organised session for on-the-job training o...\n",
              "3                      An indefinite contract  ...             Other kind of course or private lesson\n",
              "4  An apprenticeship or other training scheme  ...                              A seminar or workshop\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14l__FRyLZfs",
        "colab_type": "text"
      },
      "source": [
        "# Test Bed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEg0yPNVX9lG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using Dummies to OneHotEncoder, usable code snippet for dummies\n",
        "# dummy_na=True provides an extra column for the nan values, which are 1HE\n",
        "fakes = final_df_imputed.copy()\n",
        "\n",
        "for col in nominal_categorical_encoding_manifest.keys():\n",
        "    fakes = pd.concat([fakes, pd.get_dummies(fakes[col], prefix=col, dummy_na=False)],axis=1).drop([col],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHG2pHHBb9ff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fakes.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0x5H97z8VAA6",
        "colab": {}
      },
      "source": [
        "# mapping the values based on the ordinality mapping\n",
        "# some of these features, for some reason, are dataframes, so you have to convert them to series as an intermediary\n",
        "# and then do inplace replacement of the string values with the mapping.\n",
        "# the integere mapping here implies ordinality, where as the integer label encoding for the nominal features doesn't\n",
        "\n",
        "for mask, cat in ordinality_mapping:\n",
        "    if isinstance(mask, list):\n",
        "        for label in mask:\n",
        "            indiv_feat_mapping = {key: val for val, key in enumerate(cat)}\n",
        "            series = pd.Series(ordinal_df[label].values.ravel())\n",
        "            ordinal_df[label] = series.map(indiv_feat_mapping)\n",
        "\n",
        "    elif isinstance(mask, str):\n",
        "        indiv_feat_mapping = {key: val for val, key in enumerate(cat)}\n",
        "        series = pd.Series(ordinal_df[mask].values.ravel())\n",
        "        ordinal_df[mask] = series.map(indiv_feat_mapping)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um24MZGnJjqm",
        "colab_type": "text"
      },
      "source": [
        "## Feature Selection: Forward Selection\n",
        "\n",
        "We enter our feature selection step of the pipeline and we use an out of the box forward feature selection method from ML XTend to pick the features that result in the best predictive ability of our models. There are a number of different feature selection techniques that we could use (and we may explore that in the future), but for now, using a simple forward selection process is what we are going to stick with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiRZoYt-6wmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mlxtend"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbnKukKT66cQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.values[:,:-1],\n",
        "    df.values[:,-1:],\n",
        "    test_size=0.25,\n",
        "    random_state=42)\n",
        "\n",
        "y_train = y_train.ravel()\n",
        "y_test = y_test.ravel()\n",
        "\n",
        "\n",
        "# Build RF classifier to use in feature selection\n",
        "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
        "\n",
        "# Build step forward feature selection\n",
        "sfs1 = sfs(clf,\n",
        "           k_features=5,\n",
        "           forward=True,\n",
        "           floating=False,\n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=5)\n",
        "\n",
        "# Perform SFFS\n",
        "sfs1 = sfs1.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX1-22kQqcyB",
        "colab_type": "text"
      },
      "source": [
        "# Dev Branch 1 - Data Visualization for EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dPcM7UuxkWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, we plot the several categorical variables of interest against the job performance metric to visualize the distribution of job performance among the categories\n",
        "# Make the plots a little bigger\n",
        "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
        "\n",
        "feature_labels = [i for i in drop_null_missing_df.columns if i != \"job_performance\"]\n",
        "\n",
        "# create a FacetGrib object, on which to map your dataframe data onto\n",
        "g = sns.FacetGrid(drop_null_missing_df, col=\"cntryid\")\n",
        "\n",
        "# Using the FacetGrid.map() function, we will be able to visualize our data. \n",
        "# Provide the map() function with a mapping function and the name of the numeric class variable in your dataframe to plot against\n",
        "# each of your categorical variables\n",
        "g.map(plt.hist, \"job_performance\", alpha=0.7)\n",
        "g.add_legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlvfFNv6So1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Distribution plots per categorical variable. Using A facetGrid object with the sns.distplot mapping\n",
        "# function works a little differently so you will have to specify a things like row_order\n",
        "categories_list = drop_null_missing_df.cntryid.value_counts().index\n",
        "\n",
        "g = sns.FacetGrid(drop_null_missing_df, row=\"cntryid\", row_order=categories_list,\n",
        "                  height=2.0, aspect=3,)\n",
        "g.map(sns.distplot, \"job_performance\", hist=True, rug=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4VMMccVCdHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# groupby country id\n",
        "grouped = drop_null_missing_df.groupby(\"cntryid\").groups\n",
        "print(grouped)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CO8samBPrJ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the facetgrid for every feature against the job_performance metric\n",
        "for feature in feature_labels:\n",
        "    cat_list = drop_null_missing_df[feature].value_counts().index\n",
        "    g = sns.FacetGrid(drop_null_missing_df, row=feature, row_order=cat_list,\n",
        "                      height=1.7, aspect=4)\n",
        "    g.map(sns.distplot, \"job_performance\", hist=True, rug=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_sjwvIKpwbn",
        "colab_type": "text"
      },
      "source": [
        "# Dev Branch 1 - Handling Missing Values - Imputation Step\n",
        "\n",
        "When we pick an imputation strategy for the our data, we have to consider our data is numeric or non-numeric. We also have to consider whether the variable is nominally categorical or ordinally categorical to determine what type of transformative encoding scheme we can apply to those features.\n",
        "\n",
        "We also have to consider that the implications that one-hot encoding would have on our tabular dataset when we already have so many features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpmKCm-kGL1w",
        "colab_type": "text"
      },
      "source": [
        "## Imputation with a Strategy - EDA\n",
        "\n",
        "Before we even start imputng, we would want to visually understand the distribution and nature of our missing data.  For example, if the data has seasonality, it would make little sense to impute with a mean value, however - if the data are constant, it may a good idea to impute the missing data value with the mean or median value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYJag0GyFEhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the missing data features\n",
        "\n",
        "missing_val_features = [feature for feature in df if df[feature].isnull().sum() != 0]\n",
        "\n",
        "print(\"There are {} features with missing values\".format(len(missing_val_features)))\n",
        "\n",
        "for i in missing_val_features:\n",
        "    print(\"### {} ###\".format(i))\n",
        "    print(df[i].value_counts())\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO-VRi-hUgab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# each element in df.dtypes is the datatype of that feature\n",
        "print(df[missing_val_features].dtypes[:10]) # i is the string of datatypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96-NzVzrO_Oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# have a look at the distribution of the missing values in the features that were dropped containing\n",
        "# missing values\n",
        "\n",
        "# for feature in missing_val_features:\n",
        "#     if df[feature].dtype == \"object\":\n",
        "#         fig = plt.figure(1, figsize=(8, 14), frameon=False, dpi=100)\n",
        "#         g = sns.FacetGrid(df, col=feature)\n",
        "#         g.map(plt.hist, \"job_performance\", alpha=0.7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKKHKBn3vo6F",
        "colab_type": "text"
      },
      "source": [
        "## Univariate Crosstab Analysis\n",
        "\n",
        "From what we can see, a portion of our data are categorical variables and it will be important to visually explore and visualize using cross tabulation, which is available from the pandas API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLK_6SQQyArr",
        "colab_type": "text"
      },
      "source": [
        "### Cross Tab Frequency Plots of Features that were dropped due to missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0uHYdP5vlcw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # create a cross tabulation for each categorical feature and then plot it\n",
        "# # These are frequency plots of each of the values that are categorical\n",
        "# # these plots include the features that were dro\n",
        "\n",
        "# for feature in missing_val_features:\n",
        "#     if df[feature].dtype == \"object\":\n",
        "#         tabulation = pd.crosstab(index=df[feature], columns=\"count\")\n",
        "#         tabulation.plot.bar(color=\"green\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol9ldL7ZyHVM",
        "colab_type": "text"
      },
      "source": [
        "### Cross tab frequency plots of categorical features that did not contain any missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSLNED39yG9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for feature in feature_labels:\n",
        "#     if drop_null_missing_df[feature].dtype == \"object\":\n",
        "#         tabulation = pd.crosstab(index=drop_null_missing_df[feature], columns=\"count\")\n",
        "#         tabulation.plot.bar(color=\"purple\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5bVhtyp1bOW",
        "colab_type": "text"
      },
      "source": [
        "## Bivarate Analysis using Box Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBN6aCyO1kWP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sns.set(style=\"whitegrid\")\n",
        "\n",
        "# for feature in feature_labels:\n",
        "#     if drop_null_missing_df[feature].dtype == \"object\":\n",
        "#         g = sns.catplot(x=feature, \n",
        "#                     y=\"job_performance\", \n",
        "#                     data=drop_null_missing_df,\n",
        "#                     palette=\"Set2\",\n",
        "#                    kind=\"box\")\n",
        "#         g.set_xticklabels(rotation=90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buUHOd-mmcBO",
        "colab_type": "text"
      },
      "source": [
        "# Dev Branch 1 - Pre-Processing: Encoding Categorical Variables\n",
        "\n",
        "For simplicity sake, we go with a one hot encoding scheme for our variables, knowing full well that this will lead to a very sparse datset. We will try and not think too hard about this at this time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0-9CVkcnFQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_df = drop_null_missing_df.loc[:, drop_null_missing_df.columns != 'job_performance'] # print(pd.get_dummies(data))\n",
        "\n",
        "# Separate out the features from the class\n",
        "dummy_features = pd.get_dummies(drop_null_missing_df.loc[:, drop_null_missing_df.columns != 'job_performance'])\n",
        "X = dummy_features.values\n",
        "y = drop_null_missing_df.loc[:, \"job_performance\"].values\n",
        "\n",
        "dummy_features = pd.get_dummies(drop_null_missing_df.loc[:, drop_null_missing_df.columns != 'job_performance'])\n",
        "dummy_features[\"job_performance\"] = y\n",
        "\n",
        "print(\"Shape of features dataframe before dummification: {}\".format(features_df.shape))\n",
        "print(\"Shape of features dataframe after dummification: {}\".format(dummy_features.shape))\n",
        "print(\"The dataframe has increase {0:.1f}x in feature size after dummification\".format(dummy_features.shape[1]/features_df.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_7DeDfdx6lB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we also need to reset the index\n",
        "dummy_features = dummy_features.reset_index()\n",
        "dummy_features = dummy_features.iloc[:, 2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5sUalIx6kBx",
        "colab_type": "text"
      },
      "source": [
        "Indeed, we are working with a much more sparse dataset after we have assigned dummy variables to the categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwcHh42w6rYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Due to the sheer volume of encodings for these listed columns, we will keep these as typed\n",
        "# as integers as opposed to the nominal nature of the their encoding\n",
        "\n",
        "iscolc_columns = [\"isco1c\", \"isco2c\", \"isco1l\", \"isco2l\"]\n",
        "for col in iscolc_columns:\n",
        "    print(f\"#### {i} ###\")\n",
        "    print(drop_null_missing_df[col].value_counts()) #remember, value_counts() is a method\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ThimKJveRr3",
        "colab_type": "text"
      },
      "source": [
        " Multiple Correspondence Analysis with the mca package\n",
        " \n",
        " tetrachoric correlation matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVWlxUBCp4CH",
        "colab_type": "text"
      },
      "source": [
        "# Separate the Features from the Class Variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvaQzvVdwFf7",
        "colab_type": "text"
      },
      "source": [
        "## Subsetting the dataset\n",
        "We are randomly sampling the dataset for  subset that data so that we can  train much faster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgM1ZnKNwEgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subdf = df.sample(n=int(0.6*df.shape[0]), random_state=123)\n",
        "subdf.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWi977G3nTQs",
        "colab_type": "text"
      },
      "source": [
        "## Non-scaled data partitioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QQul_MRo-Qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H6or-lC9uM2",
        "colab_type": "text"
      },
      "source": [
        "## Standardizing and Normalizing our data\n",
        "\n",
        "Some of the models we use are sensitive to scaling and perform better with it. Some do not require it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um-sYGcA9thZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
        "scaled_X = scaler.fit_transform(X)\n",
        "scaled_y = scaler.fit_transform(y.reshape(-1,1))\n",
        "\n",
        "# split into training and testing sets\n",
        "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(\n",
        "                                                    scaled_X,\n",
        "                                                    y,\n",
        "                                                    test_size=0.30,\n",
        "                                                    random_state=42\n",
        "                                                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kofMoVAHcmPm",
        "colab_type": "text"
      },
      "source": [
        "# Dev Branch 1a - Create Null Models\n",
        "\n",
        "In this block, we will create our null models to build upon. We will be using SVR, Linear Regression, MLPs and simple neural networks to start off."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3GuRO7GLst-",
        "colab_type": "text"
      },
      "source": [
        "## Dev Branch 1a -  Simple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyf23iwzclap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Simple Linear Model\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# normalization of your features is not advised here because it makes it hard to interpret \n",
        "# the coefficients and they don't normalize well.\n",
        "\n",
        "lm = LinearRegression(fit_intercept=True, normalize=True, copy_X=True, n_jobs=None)\n",
        "lm.fit(X_train, y_train)\n",
        "\n",
        "print(\"Linear Model Score: {}\\n\".format(lm.score(X_train, y_train)))\n",
        "print(\"Linear Model Coefficient:\\n {}\\n\".format(lm.coef_[:10]))\n",
        "print(\"Linear Model Intercept: {}\\n\".format(lm.intercept_ ))\n",
        "y_pred = lm.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7iZFhFgFiqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inverse_y_pred = scaler.inverse_transform(y_pred)\n",
        "print(\"Inverse transform of mse pred\\n{}\\n\".format(inverse_y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m47JngTwrH3h",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "Surprisingly, a high dimensional linear model predicting job performance scores, with default parameters,  returns a relatively high coefficient of determination R2 of 0.33490222049791485, wrt to the number of features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzd0EbhRPZ0e",
        "colab_type": "text"
      },
      "source": [
        "## Dev Branch 1a - Support Vector Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBiFcxr_PX1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Support Vector Machine for Regression\n",
        "from sklearn.svm import SVR\n",
        "import timeit\n",
        "\n",
        "svr = SVR(kernel=\"rbf\", degree=3, gamma=\"auto_deprecated\", coef0=0.0, tol=0.001, \n",
        "          C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, \n",
        "          max_iter=-1)\n",
        "\n",
        "# Using the normalized inputs\n",
        "start_time = timeit.default_timer()\n",
        "y_pred = svr.fit(X_train_scaled, y_train)\n",
        "end_time = timeit.default_timer()\n",
        "print(\"Run time: {}\".format(end_time - start_time))\n",
        "\n",
        "print(\"SVR Model Score: {}\\n\".format(svr.score(X_train_scaled, y_train)))\n",
        "print(\"SVR Model Params:\\n {}\\n\".format(svr.get_params))\n",
        "y_pred = svr.predict(X_test_scaled)\n",
        "print(\"y_pred: \\n{}\".format(y_pred))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYLGKWRBqfLQ",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion\n",
        "As we can expect from this high dimensional data modelling, we get a terrible R^2 coefficient of determination of the prediction error of 0.09891703260752771"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDqlyEnnYaje",
        "colab_type": "text"
      },
      "source": [
        "## Dev Branch 1a - Support Vector Regression with Different kernels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq-Ay9CeYXbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
        "svr_lin = SVR(kernel='linear', C=100, gamma='auto')\n",
        "svr_poly = SVR(kernel='poly', C=100, gamma='auto', degree=3, epsilon=.1,\n",
        "               coef0=1)\n",
        "\n",
        "lw = 2\n",
        "\n",
        "svrs = [svr_rbf, svr_lin, svr_poly]\n",
        "kernel_label = ['RBF', 'Linear', 'Polynomial']\n",
        "model_color = ['m', 'c', 'g']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQVc93oEvdNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_scaled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32_XEagzYlSj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the results\n",
        "# ig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 10), sharey=True)\n",
        "# for ix, svr in enumerate(svrs):\n",
        "#     axes[ix].plot(X_train_scaled, svr.fit(X_train_scaled, y_train_scaled).predict(X_test_scaled), color=model_color[ix], lw=lw,\n",
        "#                   label='{} model'.format(kernel_label[ix]))\n",
        "#     axes[ix].scatter(X_train_scaled[svr.support_], \n",
        "#                      y_train_scaled[svr.support_], \n",
        "#                      facecolor=\"none\", \n",
        "#                      edgecolor=model_color[ix], \n",
        "#                      s=50, \n",
        "#                      label='{} support vectors'.format(kernel_label[ix]))\n",
        "#     axes[ix].scatter(X_train_scaled[np.setdiff1d(np.arange(len(X_train_scaled)), svr.support_)], \n",
        "#                      y_train_scaled[np.setdiff1d(np.arange(len(X_train_scaled)), svr.support_)],\n",
        "#                      facecolor=\"none\", \n",
        "#                      edgecolor=\"k\", s=50,\n",
        "#                      label='other training data')\n",
        "#     axes[ix].legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
        "#                     ncol=1, fancybox=True, shadow=True)\n",
        "\n",
        "# fig.text(0.5, 0.04, 'data', ha='center', va='center')\n",
        "# fig.text(0.06, 0.5, 'target', ha='center', va='center', rotation='vertical')\n",
        "# fig.suptitle(\"Support Vector Regression\", fontsize=14)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uovtpBXaxkgm"
      },
      "source": [
        "# 1b - Using Feature Extraction and Factor Analysis\n",
        "\n",
        "We run multiple null models, after having reduced the number of dimensions and exploring the components of maximum variance from our data.\n",
        "\n",
        "Assumptions for Factor Analysis\n",
        "\n",
        "Assumptions:\n",
        "\n",
        "1. There are no outliers in data.\n",
        "2. Sample size should be greater than the factor.\n",
        "3. There should not be perfect multicollinearity.\n",
        "4. There should not be homoscedasticity between the variables.\n",
        "\n",
        "\n",
        "Types of Factor Analysis\n",
        "\n",
        "* Exploratory Factor Analysis: It is the most popular factor analysis approach among social and management researchers. Its basic assumption is that any observed variable is directly associated with any factor.\n",
        "\n",
        "* Confirmatory Factor Analysis (CFA): Its basic assumption is that each factor is associated with a particular set of observed variables. CFA confirms what is expected on the basic.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LQm04n3Kxkgu"
      },
      "source": [
        "## Dev Branch 1b - Simple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LZsUYhkdxkgx",
        "colab": {}
      },
      "source": [
        "# Simple Linear Model\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# normalization of your features is not advised here because it makes it hard to interpret \n",
        "# the coefficients and they don't normalize well.\n",
        "\n",
        "lm = LinearRegression(fit_intercept=True, normalize=True, copy_X=True, n_jobs=None)\n",
        "lm.fit(X_train, y_train)\n",
        "\n",
        "print(\"Linear Model Score: {}\\n\".format(lm.score(X_train, y_train)))\n",
        "print(\"Linear Model Coefficient:\\n {}\\n\".format(lm.coef_))\n",
        "print(\"Linear Model Intercept: {}\\n\".format(lm.intercept_ ))\n",
        "y_pred = lm.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GJUmAHCBxkg_"
      },
      "source": [
        "## Plot SLR model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "95QecFkUxkhB",
        "colab": {}
      },
      "source": [
        "# plt.scatter(X_train, y_train)\n",
        "# plt.plot(np.sort(X_test, axis=0),y_pred)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J85swW5txkhH"
      },
      "source": [
        "## Dev Branch 1b -  Support Vector Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xM-HcU6hxkhI",
        "colab": {}
      },
      "source": [
        "# Support Vector Machine for Regression\n",
        "from sklearn.svm import SVR\n",
        "import timeit\n",
        "\n",
        "svr = SVR(kernel=\"rbf\", degree=3, gamma=\"auto_deprecated\", coef0=0.0, tol=0.001, \n",
        "          C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, \n",
        "          max_iter=-1)\n",
        "\n",
        "# X_train_scaled\n",
        "start_time = timeit.default_timer()\n",
        "y_pred = svr.fit(X_train, y_train)\n",
        "end_time = timeit.default_timer()\n",
        "print(\"Run time: {}\".format(end_time - start_time))\n",
        "\n",
        "print(\"SVR Model Score: {}\\n\".format(svr.score(X_train, y_train)))\n",
        "print(\"SVR Model Params:\\n {}\\n\".format(svr.get_params))\n",
        "y_pred = svr.predict(X_test)\n",
        "print(\"y_pred: \\n{}\".format(y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "V8Uc1rc6xkhR"
      },
      "source": [
        "## Plot SVR model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Dmq7b6t6xkhS",
        "colab": {}
      },
      "source": [
        "fig = plt.figure()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLZf-3Z2RlZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install tpot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1G9C7IiCxkhY"
      },
      "source": [
        "## Dev Branch 1b -TPOT Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdLlrOs5V0TN",
        "colab_type": "text"
      },
      "source": [
        "Teapot does hyperparameter tuning, model selection and preprocessing all in one pipeline. It takes a while to train the say the least. We will select the best parameter from training on the null dataset (without any feature engineering) to see if we can get a functioning model from this exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjhIijPNXEnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import timeit\n",
        "from tpot import TPOTClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    precision_recall_fscore_support,\n",
        "    accuracy_score,\n",
        ")\n",
        "from pprint import pprint\n",
        "\n",
        "\n",
        "tpot = TPOTClassifier(generations=5, population_size=50, verbosity=2, n_jobs=-1)\n",
        "\n",
        "prec_rec_fsc_sup = [\"precision\", \"recall\", \"fscore\", \"support\"]\n",
        "\n",
        "start_time = timeit.default_timer()\n",
        "tpot.fit(X_train, y_train)\n",
        "y_pred = tpot.predict(X_test)\n",
        "end_time = timeit.default_timer()\n",
        "runtime = end_time - start_time\n",
        "print(f\"Total runtime for the {name} dataset: {runtime}s\")\n",
        "\n",
        "\n",
        "print(\"\\nConfusion Matrix for the {} dataset\\n{}\\n\".format(confusion_matrix(name, y_test, y_pred)))\n",
        "\n",
        "print(\"Precision/Recall/FScore/Support for the {} dataset\".format(name))\n",
        "for met, val in zip(prec_rec_fsc_sup, precision_recall_fscore_support(y_test, y_pred)):\n",
        "    pprint(\"{}: {}\".format(met, val))\n",
        "\n",
        "print(\"Accuracy score for the {} dataset: {}\".format(name, accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTfWeQOiXSSB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Best Performing Models\n",
        "1. LinearSVC\n",
        "Best pipeline: LinearSVC(PolynomialFeatures(input_matrix, degree=2, include_bias=False, interaction_only=False), C=20.0, dual=False, loss=squared_hinge, penalty=l2, tol=0.1)\n",
        "Total runtime: 45.1908969899996s\n",
        "Average Accuracy Score: 0.9666666666666667\n",
        "Best Accuracy Score: 0.9825757575757577\n",
        "\n",
        "2. \n",
        "\n",
        "# Wine Dataset\n",
        "1. GradientBoostingClassifier\n",
        "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.5, max_depth=3, max_features=0.1, min_samples_leaf=1, min_samples_split=4, n_estimators=100, subsample=0.6500000000000001)\n",
        "Total runtime: 63.685036884999136s\n",
        "Average Accuracy Score: 0.9722222222222222\n",
        "Best Accuracy Score: 0.9928571428571429\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQjp7HwPRlqa",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter Tuning\n",
        "\n",
        "After a while, you start getting an intuition of which hyperparameters are more important than others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9-TvxlyRgNJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid search, beam search, bayesian optimization, random search"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_lhLXO3ODHS",
        "colab_type": "text"
      },
      "source": [
        "The most successful people are the most effective communicators of results and your visualizations, and why your work matters and what you found"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ45fXy-SkH7",
        "colab_type": "text"
      },
      "source": [
        "# Things to do for next week\n",
        "\n",
        "combine all the models into a single classifier\n",
        "weighted stacking of models\n",
        "you can learn this weighting through meta weighting\n",
        "\n",
        "boosting is usually based on weak sequential classifiers\n",
        "this deals with hard edge cases with weak classifiers\n",
        "\n",
        "learn about about whether your model is over fitting\n",
        "to plot, save the RMSE, for each model, and then plot them on a line chart\n",
        "per epoch to see how the different models faired in terms of the number of \n",
        "accuracy vs epochs\n",
        "\n",
        "Also useful for plotting the effects of differnt settings fo different hyperparameters on performance using parallel coordinates\n",
        "\n",
        "experiment managers, such as Sacred, build your own tools for your own experiments. \n",
        "\n",
        "keep iterating model development\n",
        "\n",
        "Finally, think about how do you deploy this model.\n",
        "Deploy this with client facing user input through an app.\n",
        "\n",
        "How do you display this projec tot someone and make it look nice. \n",
        "\n",
        "Simple interface so that they can get predictions for the model. Think about the context , what the model does. \n",
        "Existing tools exist. Think about simple servers, where a user will serve a request, run the model, and then serve the prediction. Just in the http request. You don't even have an interface, you can just have a simple API\n",
        "\n",
        "read about how models get deployed at inference time. Look at AWS EC2 and lambda. How do you deal with data. do you persist those user requests, and things like.\n",
        "Read into flask.\n",
        "\n",
        "set up a siimple server that can handle requests. How to launch an ec2 (hosting servers) instqance and how to store data in an s3 bucket. Dynamo for databases. Lambda for inference that is adaptable.\n",
        "\n",
        "GCP, AWS. server.\n",
        "\n",
        "Think about presentation."
      ]
    }
  ]
}